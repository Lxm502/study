{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0eebefa-b8f8-4eb9-97a8-18a0d3c35da5",
   "metadata": {},
   "source": [
    "# ğŸ§© torch.nn é€ŸæŸ¥è¡¨\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ å®¹å™¨\n",
    "- `nn.Module` â†’ åŸºç±»\n",
    "- `nn.Sequential` â†’ é¡ºåºå®¹å™¨ï¼ˆæŒ‰é¡ºåºå †å å±‚ï¼‰\n",
    "\n",
    "- `nn.ModuleDict` â†’ æ¨¡å—å­—å…¸ï¼ˆkey-value å­˜å‚¨å­æ¨¡å—ï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ å¸¸è§å±‚\n",
    "| å±‚åç§° | ä¸»è¦å‚æ•° | ä½œç”¨ | ä½¿ç”¨åœºæ™¯æ¨è |\n",
    "|--------|----------|------|--------------|\n",
    "| `nn.Linear(in_features, out_features, bias=True)` | `in_features`: è¾“å…¥ç»´åº¦<br>`out_features`: è¾“å‡ºç»´åº¦<br>`bias`: æ˜¯å¦åŠ åç½® | å…¨è¿æ¥å±‚ï¼ˆçº¿æ€§å˜æ¢ï¼‰ | ç”¨äº MLPã€åˆ†ç±»å™¨æœ€åä¸€å±‚ã€ç‰¹å¾æ˜ å°„ |\n",
    "| `nn.Conv1d(in_c, out_c, kernel_size, stride=1, padding=0)` | `in_c`: è¾“å…¥é€šé“æ•°<br>`out_c`: è¾“å‡ºé€šé“æ•°<br>`kernel_size`: å·ç§¯æ ¸å¤§å°<br>`stride`: æ­¥é•¿<br>`padding`: å¡«å…… | ä¸€ç»´å·ç§¯ | å¸¸ç”¨äºæ–‡æœ¬/æ—¶é—´åºåˆ—ç‰¹å¾æå– |\n",
    "| `nn.Conv2d(in_c, out_c, kernel_size, stride=1, padding=0)` | åŒä¸Š | äºŒç»´å·ç§¯ | å¸¸ç”¨äºå›¾åƒç‰¹å¾æå– (CNN) |\n",
    "| `nn.Conv3d(in_c, out_c, kernel_size, stride=1, padding=0)` | åŒä¸Š | ä¸‰ç»´å·ç§¯ | è§†é¢‘ã€åŒ»å­¦å›¾åƒ (MRI/CT) |\n",
    "| `nn.ConvTranspose1d(in_c, out_c, kernel_size, stride=1, padding=0)` | å‚æ•°åŒ Conv1d | åå·ç§¯ (è½¬ç½®å·ç§¯) | å¸¸ç”¨äºç”Ÿæˆæ¨¡å‹ã€åºåˆ—è§£ç  |\n",
    "| `nn.ConvTranspose2d(in_c, out_c, kernel_size, stride=1, padding=0)` | å‚æ•°åŒ Conv2d | äºŒç»´è½¬ç½®å·ç§¯ | å›¾åƒä¸Šé‡‡æ · (GAN/Segmentation) |\n",
    "| `nn.ConvTranspose3d(in_c, out_c, kernel_size, stride=1, padding=0)` | å‚æ•°åŒ Conv3d | ä¸‰ç»´è½¬ç½®å·ç§¯ | è§†é¢‘/3D é‡å»º |\n",
    "| `nn.RNN(input_size, hidden_size, num_layers=1, batch_first=True)` | `input_size`: è¾“å…¥ç‰¹å¾ç»´åº¦<br>`hidden_size`: éšè—å±‚å¤§å°<br>`num_layers`: å †å å±‚æ•° | å¾ªç¯ç¥ç»ç½‘ç»œ | å¤„ç†çŸ­åºåˆ—ï¼Œç®€å• NLP/æ—¶é—´åºåˆ— |\n",
    "| `nn.LSTM(input_size, hidden_size, num_layers=1, batch_first=True)` | åŒ RNNï¼Œå†…éƒ¨æœ‰ `cell state` | é•¿çŸ­æœŸè®°å¿†ç½‘ç»œ | NLP åºåˆ—å»ºæ¨¡ï¼Œé•¿ä¾èµ–ä»»åŠ¡ |\n",
    "| `nn.GRU(input_size, hidden_size, num_layers=1, batch_first=True)` | åŒ RNNï¼Œç®€åŒ–ç‰ˆ LSTM | é—¨æ§å¾ªç¯å•å…ƒ | NLPï¼Œæ¨èæ¯” RNN æ›´ä¼˜å…ˆ |\n",
    "| `nn.BatchNorm1d(num_features)` | `num_features`: é€šé“æ•° | ä¸€ç»´æ‰¹å½’ä¸€åŒ– | åºåˆ—/è¡¨æ ¼ç‰¹å¾ |\n",
    "| `nn.BatchNorm2d(num_features)` | `num_features`: é€šé“æ•° | äºŒç»´æ‰¹å½’ä¸€åŒ– | CNN å›¾åƒå·ç§¯è¾“å‡º |\n",
    "| `nn.BatchNorm3d(num_features)` | `num_features`: é€šé“æ•° | ä¸‰ç»´æ‰¹å½’ä¸€åŒ– | è§†é¢‘ã€3D å›¾åƒ |\n",
    "| `nn.LayerNorm(normalized_shape)` | `normalized_shape`: è¦å½’ä¸€åŒ–çš„ç»´åº¦ | å±‚å½’ä¸€åŒ– | NLP Transformerï¼ŒRNNï¼Œç¨³å®šè®­ç»ƒ |\n",
    "| `nn.GroupNorm(num_groups, num_channels)` | `num_groups`: åˆ†ç»„æ•°<br>`num_channels`: æ€»é€šé“æ•° | åˆ†ç»„å½’ä¸€åŒ– | é€‚åˆå° batch çš„å›¾åƒä»»åŠ¡ |\n",
    "| `nn.InstanceNorm(num_features)` | `num_features`: é€šé“æ•° | å®ä¾‹å½’ä¸€åŒ– | é£æ ¼è¿ç§»ï¼Œå›¾åƒç”Ÿæˆ |\n",
    "| `nn.Dropout(p=0.5)` | `p`: ä¸¢å¼ƒæ¦‚ç‡ | éšæœºä¸¢å¼ƒç¥ç»å…ƒ | å…¨è¿æ¥å±‚é˜²è¿‡æ‹Ÿåˆ |\n",
    "| `nn.Dropout2d(p=0.5)` | `p`: ä¸¢å¼ƒæ¦‚ç‡ | ä¸¢å¼ƒæ•´å¼  feature map | CNN æ¨¡å‹é˜²è¿‡æ‹Ÿåˆ |\n",
    "| `nn.Dropout3d(p=0.5)` | `p`: ä¸¢å¼ƒæ¦‚ç‡ | ä¸¢å¼ƒ 3D ç‰¹å¾å— | è§†é¢‘/3D CNN |\n",
    "| `nn.Embedding(num_embeddings, embedding_dim)` | `num_embeddings`: è¯è¡¨å¤§å°<br>`embedding_dim`: å‘é‡ç»´åº¦ | åµŒå…¥å±‚ï¼ˆç´¢å¼• â†’ å‘é‡ï¼‰ | NLP è¯å‘é‡ï¼ŒID ç‰¹å¾ç¼–ç  |\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4af5cf2-45b8-4426-897c-4c61a94be914",
   "metadata": {},
   "source": [
    "## ğŸ”¹ 1ï¸âƒ£æ¿€æ´»å‡½æ•°\n",
    "| æ¿€æ´»å‡½æ•°             | æ•°å­¦å…¬å¼                                      | è¾“å‡ºèŒƒå›´       | ç‰¹ç‚¹           | ä¼˜ç‚¹                            | ç¼ºç‚¹              | å¸¸ç”¨åœºæ™¯            |\n",
    "| ---------------- | ----------------------------------------- | ---------- | ------------ | ----------------------------- | --------------- | --------------- |\n",
    "| **ReLU**         | $f(x) = \\max(0, x)$                       | \\[0, âˆ)    | ç¨€ç–æ¿€æ´»ï¼Œç®€å•é«˜æ•ˆ    | æ”¶æ•›å¿«ï¼Œæ¢¯åº¦ä¼ é€’å¥½                     | è´Ÿå€¼æ­»åŒºï¼ˆDead ReLUï¼‰ | CNNã€å…¨è¿æ¥ç½‘ç»œ       |\n",
    "| **LeakyReLU**    | $f(x) = x$ if $x>0$, $\\alpha x$ if $x<=0$ | (-âˆ, âˆ)    | æ”¹è¿› ReLU æ­»åŒºé—®é¢˜ | é¿å…æ¢¯åº¦æ¶ˆå¤±                        | éœ€è°ƒ Î± å‚æ•°         | CNNã€æ·±å±‚ç½‘ç»œ        |\n",
    "| **PReLU**        | ç±»ä¼¼ LeakyReLUï¼Œä½† Î± å¯è®­ç»ƒ                      | (-âˆ, âˆ)    | è‡ªé€‚åº”è´ŸåŒºé—´       | è‡ªåŠ¨å­¦ä¹ æœ€ä¼˜è´Ÿæ–œç‡                     | å¢åŠ å‚æ•°            | CNNã€ResNet ç­‰    |\n",
    "| **ELU**          | $x$ if $x>0$, $\\alpha(e^x-1)$ if $x<=0$   | (-Î±, âˆ)    | å¹³æ»‘ï¼Œè´Ÿå€¼æ”¶æ•›      | å‡å°‘åç§»ï¼Œæ¢¯åº¦æµå¥½                     | ç¨æ…¢ï¼Œéœ€è°ƒ Î±         | æ·±å±‚ç½‘ç»œ            |\n",
    "| **SiLU / Swish** | $x \\cdot sigmoid(x)$                      | (-âˆ, âˆ)    | å¹³æ»‘ï¼Œå¯å¾®        | æ”¶æ•›ç¨³å®šï¼ŒTransformerã€EfficientNet | è®¡ç®—ç•¥æ…¢            | CNNã€Transformer |\n",
    "| **GELU**         | $x \\cdot Î¦(x)$                            | (-âˆ, âˆ)    | å¹³æ»‘ï¼Œæ¦‚ç‡ä¿ç•™      | Transformer/NLP é«˜æ•ˆ            | è®¡ç®—ç¨æ…¢            | BERT, GPT, ViT  |\n",
    "| **Sigmoid**      | $1 / (1+e^{-x})$                          | (0, 1)     | éçº¿æ€§ï¼Œå¹³æ»‘       | è¾“å‡ºæ¦‚ç‡ï¼Œæ˜“è§£é‡Š                      | æ¢¯åº¦æ¶ˆå¤±ï¼Œé¥±å’Œæ…¢        | äºŒåˆ†ç±»è¾“å‡ºå±‚          |\n",
    "| **Tanh**         | $(e^x - e^{-x}) / (e^x + e^{-x})$         | (-1, 1)    | å¹³æ»‘ï¼Œå¯¹ç§°        | å½’ä¸€åŒ–è¾“å…¥                         | æ¢¯åº¦æ¶ˆå¤±            | RNN, ä¸­é—´å±‚éçº¿æ€§     |\n",
    "| **Softmax**      | $\\sigma(x_i) = e^{x_i}/\\sum e^{x_j}$      | (0,1), Î£=1 | å¤šåˆ†ç±»æ¦‚ç‡è¾“å‡º      | è¾“å‡ºå¯ç›´æ¥æ¦‚ç‡åŒ–                      | åªç”¨äºæœ€ååˆ†ç±»å±‚        | å¤šåˆ†ç±»ä»»åŠ¡è¾“å‡ºå±‚        |\n",
    "\n",
    "---\n",
    "## 2ï¸âƒ£ æ¿€æ´»å‡½æ•°é€‰æ‹©æŒ‡å—\n",
    "### (1) éšè—å±‚æ¿€æ´»å‡½æ•°\n",
    "| åœºæ™¯                      | æ¨èå‡½æ•°                            | åŸå›                      |\n",
    "| ----------------------- | ------------------------------- | ---------------------- |\n",
    "| CNN å·ç§¯å±‚                 | ReLU / LeakyReLU / PReLU / GELU | ç®€å•é«˜æ•ˆï¼Œæ¢¯åº¦æµå¥½              |\n",
    "| æ·±å±‚ç½‘ç»œ                    | ELU / GELU / SiLU               | å¹³æ»‘ï¼Œå¯ç¼“è§£æ¢¯åº¦æ¶ˆå¤±ï¼Œè®­ç»ƒç¨³å®š        |\n",
    "| RNN / LSTM ä¸­é—´å±‚          | Tanh / ReLU                     | ä¿æŒè¾“å…¥å‡å€¼å±…ä¸­ï¼Œç¨³å®šè®­ç»ƒ          |\n",
    "| Transformer / Attention | GELU / SiLU                     | å¹³æ»‘æ¿€æ´»ï¼Œè®­ç»ƒç¨³å®šï¼ŒNLP/ViT ç»å…¸é€‰æ‹© |\n",
    "\n",
    "### (2) è¾“å‡ºå±‚æ¿€æ´»å‡½æ•°\n",
    "| ä»»åŠ¡ç±»å‹  | æ¨èå‡½æ•°               | åŸå›           |\n",
    "| ----- | ------------------ | ----------- |\n",
    "| äºŒåˆ†ç±»   | Sigmoid            | è¾“å‡ºæ¦‚ç‡ (0\\~1) |\n",
    "| å¤šåˆ†ç±»   | Softmax            | è¾“å‡ºç±»åˆ«æ¦‚ç‡ï¼Œäº’æ–¥   |\n",
    "| å›å½’    | None / ReLU / Tanh | æ ¹æ®ç›®æ ‡èŒƒå›´è°ƒæ•´    |\n",
    "| å¤šæ ‡ç­¾åˆ†ç±» | Sigmoid            | æ¯ä¸ªæ ‡ç­¾ç‹¬ç«‹æ¦‚ç‡    |\n",
    "\n",
    "---\n",
    "### 3ï¸âƒ£ é€‰æ‹©å»ºè®®\n",
    "\n",
    "1ã€é»˜è®¤é€‰æ‹©\n",
    "\n",
    "- éšè—å±‚ï¼šReLUï¼ˆç®€å•é«˜æ•ˆï¼‰\n",
    "\n",
    "- Transformer / NLPï¼šGELU\n",
    "\n",
    "- è¾“å‡ºå±‚ï¼šæ ¹æ®ä»»åŠ¡ç±»å‹é€‰æ‹© Sigmoid / Softmax\n",
    "\n",
    "2ã€è€ƒè™‘æ¢¯åº¦æ¶ˆå¤±é—®é¢˜\n",
    "\n",
    "- å¦‚æœç½‘ç»œæ·±å±‚æˆ–è´Ÿå€¼å¯èƒ½è¿‡å¤š â†’ ä½¿ç”¨ LeakyReLU, ELU, GELU\n",
    "\n",
    "3ã€è®¡ç®—æ•ˆç‡ vs å¹³æ»‘æ€§\n",
    "\n",
    "- CNNã€ç§»åŠ¨ç«¯å¯ä¼˜å…ˆ ReLU\n",
    "\n",
    "- NLP / Transformer æ›´æ³¨é‡è®­ç»ƒç¨³å®šæ€§ â†’ GELU / SiLU\n",
    "\n",
    "4ã€å®éªŒéªŒè¯\n",
    "\n",
    "- å¯¹æ–°æ¨¡å‹ï¼Œæœ€å¥½å°è¯•ä¸¤ä¸‰ç§æ¿€æ´»å‡½æ•°å¯¹æ¯”æ”¶æ•›é€Ÿåº¦å’Œæœ€ç»ˆæ€§èƒ½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3318e3-c6e2-43cd-9e63-f60028abec99",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### ğŸ“Œ **è§£é‡Š**ï¼š\n",
    "- **éšè—å±‚æ¨è**ï¼š  \n",
    "  - é»˜è®¤ â†’ `ReLU`  \n",
    "  - æƒ³é¿å…â€œç¥ç»å…ƒæ­»äº¡â€ â†’ `LeakyReLU` / `ELU`  \n",
    "  - NLP / Transformer ç³»åˆ— â†’ `GELU` / `SiLU`  \n",
    "  - ç‰¹æ®Šæƒ…å†µï¼ˆè‡ªå½’ä¸€åŒ–ç½‘ç»œï¼‰ â†’ `SELU`  \n",
    "\n",
    "- **è¾“å‡ºå±‚æ¨è**ï¼š  \n",
    "  - äºŒåˆ†ç±» â†’ `Sigmoid`  \n",
    "  - å¤šåˆ†ç±» â†’ `Softmax`ï¼ˆä¸€èˆ¬ç›´æ¥ç”¨ `nn.CrossEntropyLoss()`ï¼Œå†…éƒ¨ä¼šå¤„ç†ï¼‰  \n",
    "  - å¤šåˆ†ç±» + éœ€è¦ log æ¦‚ç‡ â†’ `LogSoftmax` + `NLLLoss`  \n",
    "  - å›å½’ â†’ **ä¸åŠ æ¿€æ´»å‡½æ•°**ï¼ˆçº¿æ€§è¾“å‡ºï¼‰ï¼Œå¦‚æœè¦é™åˆ¶èŒƒå›´ï¼Œå¯ä»¥ç”¨ `Tanh`  \n",
    "\n",
    "---\n",
    "![æ¿€æ´»å‡½æ•°è¾“å‡ºå€¼ç¤ºæ„å›¾](æ¿€æ´»å‡½æ•°è¾“å‡ºå€¼ç¤ºæ„å›¾.png)\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ æŸå¤±å‡½æ•°\n",
    "| æŸå¤±å‡½æ•° | è§£é‡Š |\n",
    "|----------|------|\n",
    "| `nn.MSELoss()` | **å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰**ï¼Œå¸¸ç”¨äºå›å½’ã€‚ |\n",
    "| `nn.L1Loss()` | **å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰**ï¼Œæ¯” MSE å¯¹å¼‚å¸¸å€¼æ›´é²æ£’|\n",
    "| `nn.CrossEntropyLoss()` | **äº¤å‰ç†µæŸå¤±**ï¼Œå¤šåˆ†ç±»å¸¸ç”¨ï¼Œå†…éƒ¨åŒ…å« `LogSoftmax + NLLLoss`ï¼Œè¾“å…¥åº”ä¸º logitsï¼ˆæœªè¿‡ softmax çš„å€¼ï¼‰ã€‚ |\n",
    "| `nn.NLLLoss()` | **è´Ÿå¯¹æ•°ä¼¼ç„¶æŸå¤±**ï¼Œè¾“å…¥å¿…é¡»æ˜¯ log softmax æ¦‚ç‡ï¼Œé€šå¸¸å’Œ `nn.LogSoftmax` æ­é…ä½¿ç”¨ã€‚ |\n",
    "| `nn.BCELoss()` | **äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±**ï¼Œè¾“å…¥å¿…é¡»æ˜¯ [0,1] æ¦‚ç‡ï¼ˆé€šå¸¸å…ˆè¿‡ sigmoidï¼‰ã€‚ |\n",
    "| `nn.BCEWithLogitsLoss()` | **å¸¦ Logits çš„äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±**ï¼Œå†…éƒ¨é›†æˆ sigmoidï¼Œæ›´ç¨³å®šï¼Œæ¨èæ›¿ä»£ `BCELoss`ã€‚ |\n",
    "| `nn.HingeEmbeddingLoss()` | **åˆé¡µåµŒå…¥æŸå¤±**ï¼Œç”¨äºç›¸ä¼¼åº¦å­¦ä¹ ï¼Œè¡¡é‡æ ·æœ¬å¯¹æ˜¯å¦ç›¸ä¼¼ï¼ˆ+1ï¼‰æˆ–ä¸ç›¸ä¼¼ï¼ˆ-1ï¼‰ã€‚ |\n",
    "| `nn.MarginRankingLoss()` | **æ’åºè¾¹ç•ŒæŸå¤±**ï¼Œç”¨äºæ’åºä»»åŠ¡ï¼Œçº¦æŸï¼š\\(\\max(0, -y \\cdot (x1 - x2) + margin)\\)ã€‚ |\n",
    "| `nn.TripletMarginLoss()` | **ä¸‰å…ƒç»„æŸå¤±**ï¼Œå¸¸ç”¨äºäººè„¸è¯†åˆ«/åº¦é‡å­¦ä¹ ï¼Œçº¦æŸï¼š\\( d(anchor, positive) + margin < d(anchor, negative)\\)ã€‚ |\n",
    "| `nn.KLDivLoss()` | **KL æ•£åº¦æŸå¤±**ï¼Œåº¦é‡ä¸¤ä¸ªæ¦‚ç‡åˆ†å¸ƒå·®å¼‚ï¼Œå¸¸ç”¨äºçŸ¥è¯†è’¸é¦ã€æ¦‚ç‡å»ºæ¨¡ã€‚ |\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ æ± åŒ–\n",
    "- `nn.MaxPool1d/2d/3d`\n",
    "- `nn.AvgPool1d/2d/3d`\n",
    "- `nn.AdaptiveAvgPool2d`\n",
    "- `nn.AdaptiveMaxPool2d`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcffa3c8-56fb-48fc-bfce-e9faab7ec00d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0e58f71c-ae45-4073-a2ab-57fd5887230f",
   "metadata": {},
   "source": [
    "# 1. å®¹å™¨ï¼ˆContainersï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5e4122-7789-409c-989a-c22535cd69a4",
   "metadata": {},
   "source": [
    "## ğŸ”¹ 1. nn.Module æ¦‚å¿µ\n",
    "\n",
    "nn.Module = ç¥ç»ç½‘ç»œç»„ä»¶çš„åŸºç±»ã€‚\n",
    "\n",
    "å¯ä»¥è¡¨ç¤º å•ä¸ªå±‚ï¼ˆå¦‚çº¿æ€§å±‚ã€å·ç§¯å±‚ï¼‰ï¼Œä¹Ÿå¯ä»¥è¡¨ç¤º æ•´ä¸ªç½‘ç»œï¼ˆç”±å¾ˆå¤šå­å±‚ç»„åˆï¼‰ã€‚\n",
    "\n",
    "æ‰€æœ‰ torch.nn çš„å±‚å’ŒæŸå¤±å‡½æ•°ï¼Œéƒ½æ˜¯ nn.Module çš„å­ç±»ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ 2. nn.Module çš„æ ¸å¿ƒæ–¹æ³• & å±æ€§\n",
    "| æ–¹æ³•/å±æ€§                          | ä½œç”¨                          |\n",
    "| ------------------------------ | --------------------------- |\n",
    "| `__init__()`                   | æ„é€ å‡½æ•°ï¼Œç”¨äºå®šä¹‰å±‚å’Œå‚æ•°               |\n",
    "| `forward(input)`               | å‰å‘ä¼ æ’­é€»è¾‘ï¼Œå®šä¹‰è¾“å…¥å¦‚ä½•è®¡ç®—è¾“å‡º           |\n",
    "| `.parameters()`                | è¿”å›æ‰€æœ‰éœ€è¦æ¢¯åº¦çš„å‚æ•°ï¼ˆ`nn.Parameter`ï¼‰ |\n",
    "| `.named_parameters()`          | å¸¦åå­—çš„å‚æ•°è¿­ä»£å™¨                   |\n",
    "| `.children()`                  | è¿­ä»£ç›´æ¥å­æ¨¡å—                     |\n",
    "| `.modules()`                   | é€’å½’è¿­ä»£æ‰€æœ‰å­æ¨¡å—ï¼ˆåŒ…å«è‡ªèº«ï¼‰             |\n",
    "| `.state_dict()`                | è¿”å›æ¨¡å‹å‚æ•°å­—å…¸ï¼ˆç”¨äºä¿å­˜/åŠ è½½ï¼‰           |\n",
    "| `.load_state_dict(state_dict)` | åŠ è½½å‚æ•°å­—å…¸                      |\n",
    "| `.to(device)`                  | æŠŠæ¨¡å‹è½¬ç§»åˆ° CPU/GPU              |\n",
    "| `.train()`                     | åˆ‡æ¢åˆ°è®­ç»ƒæ¨¡å¼ï¼ˆå¯ç”¨ Dropout/BNï¼‰      |\n",
    "| `.eval()`                      | åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­ Dropout/BNï¼‰      |\n",
    "\n",
    "### âš ï¸ æ³¨æ„ï¼š\n",
    "\n",
    "å¿…é¡»å®ç° __init__() å’Œ forward()\n",
    "\n",
    "ä¸è¦æ‰‹åŠ¨è°ƒç”¨ forward()ï¼Œè€Œæ˜¯ç”¨ model(input)ï¼Œå†…éƒ¨ä¼šè‡ªåŠ¨è°ƒç”¨ forward\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ 3. nn.Module å·¥ä½œæµç¨‹\n",
    "\n",
    "1ã€å®šä¹‰å±‚ï¼ˆåœ¨ __init__ ä¸­ï¼‰ï¼šæŠŠéœ€è¦çš„å±‚å®šä¹‰æˆæˆå‘˜å˜é‡ï¼ˆå¦‚ self.fc1 = nn.Linear(...)ï¼‰\n",
    "\n",
    "2ã€å®šä¹‰è®¡ç®—é€»è¾‘ï¼ˆåœ¨ forward ä¸­ï¼‰ï¼šè¾“å…¥å¦‚ä½•æµè¿‡è¿™äº›å±‚ï¼Œè¿”å›è¾“å‡º\n",
    "\n",
    "3ã€å®ä¾‹åŒ–æ¨¡å‹å¹¶è°ƒç”¨ï¼š\\\n",
    "model = MyNet() \\\n",
    "output = model(x)ï¼ˆå†…éƒ¨ä¼šè‡ªåŠ¨è°ƒç”¨ forwardï¼‰\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¹ 4. ç¤ºä¾‹ä»£ç "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d594d5-8d97-41d1-a4d5-83b19ed64aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# è‡ªå®šä¹‰ç½‘ç»œ\n",
    "class MyNet(nn.Module):\n",
    "    # æ„é€ å„ä¸ªå±‚\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()  # ç»§æ‰¿ nn.Module\n",
    "        self.fc1 = nn.Linear(10, 20)   # ç¬¬ä¸€å±‚ï¼Œå…¨è¿æ¥\n",
    "        self.fc2 = nn.Linear(20, 1)    # ç¬¬äºŒå±‚ï¼Œå…¨è¿æ¥\n",
    "\n",
    "    # è®¡ç®—è¿‡ç¨‹\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))   # ç»è¿‡ç¬¬ä¸€å±‚ + ReLU\n",
    "        x = torch.sigmoid(self.fc2(x)) # ç»è¿‡ç¬¬äºŒå±‚ + Sigmoid\n",
    "        return x\n",
    "\n",
    "# ä½¿ç”¨æ¨¡å‹\n",
    "model = MyNet()\n",
    "x = torch.randn(5, 10)    # batch_size=5, è¾“å…¥ç‰¹å¾=10\n",
    "output = model(x)\n",
    "print(output.shape)       # [5, 1]\n",
    "\n",
    "# æŸ¥çœ‹å‚æ•°\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)\n",
    "\n",
    "\"\"\"\n",
    "è¾“å‡ºï¼š\n",
    "fc1.weight torch.Size([20, 10])\n",
    "fc1.bias   torch.Size([20])\n",
    "fc2.weight torch.Size([1, 20])\n",
    "fc2.bias   torch.Size([1])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5dd72d1-125f-4432-92d1-01bf68d1f271",
   "metadata": {},
   "source": [
    "## ğŸ”¹ 5. å¸¸è§å‘\n",
    "\n",
    "1ã€ä¸è¦æ‰‹åŠ¨è°ƒç”¨ forward\n",
    "\n",
    "- `y = model(x)   # æ­£ç¡®` \n",
    "- `y = model.forward(x)  # âŒ ä¸æ¨è  â†’ ç›´æ¥è°ƒç”¨ forward ä¼šç»•è¿‡ hooks ç­‰æœºåˆ¶ã€‚`\n",
    "\n",
    "2ã€parameters() åªè¿”å›éœ€è¦æ¢¯åº¦çš„å‚æ•°,å¦‚æœä½ æœ‰ä¸€äº› bufferï¼ˆæ¯”å¦‚ç»Ÿè®¡é‡ï¼‰ï¼Œå¯ä»¥ç”¨ register_bufferã€‚\n",
    "\n",
    "3ã€è®­ç»ƒ / è¯„ä¼°æ¨¡å¼è¦åˆ‡æ¢\n",
    "\n",
    "model.train()  # å¯ç”¨ dropout, BN \\\n",
    "model.eval()   # å…³é—­ dropout, BN\n",
    "\n",
    "\n",
    "4ã€ä¿å­˜/åŠ è½½å‚æ•°è¦ç”¨ state_dict()\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")\\\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… æ€»ç»“ï¼š\n",
    "nn.Module å°±åƒ ä¹é«˜ç§¯æœ¨çš„åŸºç±» â€”â€” ä½ å®šä¹‰çš„æ¯ä¸ªç§¯æœ¨ï¼ˆå±‚/ç½‘ç»œï¼‰éƒ½è¦ç»§æ‰¿å®ƒï¼ŒæŠŠå±‚åœ¨ __init__ é‡Œæ­å¥½ï¼ŒæŠŠè®¡ç®—è¿‡ç¨‹å†™åœ¨ forward é‡Œï¼Œç„¶å PyTorch ä¼šå¸®ä½ è‡ªåŠ¨å¤„ç†å‚æ•°ç®¡ç†ã€æ¢¯åº¦è®¡ç®—ã€ä¿å­˜åŠ è½½ç­‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab23451c-4cef-4acc-b7c4-06e968982898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50de1ca-db5f-4c7a-86c4-45c274d9a26e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0e4e63a-3772-439e-af9b-40dbacbf96ff",
   "metadata": {},
   "source": [
    "# ğŸ”¹å®Œæ•´ç¤ºä¾‹ï¼šMNIST åˆ†ç±»\n",
    "### 1ã€MLPå½¢å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df85b09-35c6-4770-b81e-bf69d094d01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# 1. æ•°æ®é¢„å¤„ç†\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # è½¬æ¢ä¸ºTensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # æ ‡å‡†åŒ–åˆ° [-1, 1]\n",
    "])\n",
    "\n",
    "# 2. ä¸‹è½½ MNIST æ•°æ®é›†\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# æ‹†åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 3. å®šä¹‰æ¨¡å‹\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)  # å±•å¹³\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  # æœ€åä¸€å±‚ä¸ç”¨æ¿€æ´»ï¼Œäº¤ç»™CrossEntropyLoss\n",
    "        return x\n",
    "\n",
    "model = SimpleNN()\n",
    "\n",
    "# 4. å®šä¹‰æŸå¤±å‡½æ•° & ä¼˜åŒ–å™¨\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 5. è®­ç»ƒ + éªŒè¯è¿‡ç¨‹\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, epochs=5):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        # ----è®­ç»ƒ----\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # ----éªŒè¯----\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹\n",
    "train(model, train_loader, val_loader, criterion, optimizer, epochs=5)\n",
    "\n",
    "# 6. æµ‹è¯•è¿‡ç¨‹\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "# æµ‹è¯•æ¨¡å‹\n",
    "test(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94895c3-54b0-4cad-b1ab-279437f523c6",
   "metadata": {},
   "source": [
    "### 2ã€CNNå·ç§¯æ ¼å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec535226-7ce2-4dc7-97de-2c0fc732874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# 1. æ•°æ®é¢„å¤„ç†\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # æ ‡å‡†åŒ–åˆ° [-1,1]\n",
    "])\n",
    "\n",
    "# 2. ä¸‹è½½ MNIST æ•°æ®é›†\n",
    "train_dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root=\"./data\", train=False, download=True, transform=transform)\n",
    "\n",
    "# æ‹†åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 3. å®šä¹‰ CNN æ¨¡å‹\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # å·ç§¯å±‚ï¼šè¾“å…¥ 1x28x28\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # è¾“å‡º 32x28x28\n",
    "        self.pool = nn.MaxPool2d(2, 2)                           # è¾“å‡º 32x14x14\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # è¾“å‡º 64x14x14 -> pool -> 64x7x7\n",
    "\n",
    "        # å…¨è¿æ¥å±‚\n",
    "        self.fc1 = nn.Linear(64*7*7, 128)   # ç»è¿‡2æ¬¡çš„ pool\n",
    "        self.fc2 = nn.Linear(128, 10)       # è¾“å‡º10ä¸ªç±»åˆ«\n",
    "        \n",
    "        # å±•å¹³å±‚\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # conv1 + relu + pool\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # conv2 + relu + pool\n",
    "        x = self.flatten(x)                   # å±•å¹³\n",
    "        x = F.relu(self.fc1(x))               # \n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "\n",
    "# 4. å®šä¹‰æŸå¤±å‡½æ•° & ä¼˜åŒ–å™¨\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 5. è®­ç»ƒ + éªŒè¯è¿‡ç¨‹\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, epochs=5):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        # ----è®­ç»ƒ----\n",
    "        for images, labels in train_loader:\n",
    "            optimizer.zero_grad()      # æ¸…é›¶æ¢¯åº¦\n",
    "            outputs = model(images)    # å‰å‘ä¼ æ’­ï¼ˆé¢„æµ‹ï¼‰ \n",
    "            loss = criterion(outputs, labels)  # è®¡ç®—æŸå¤±\n",
    "            loss.backward()            # åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦\n",
    "            optimizer.step()           # ä¼˜åŒ–å™¨æ ¹æ®æ¢¯åº¦æ›´æ–°æƒé‡\n",
    "\n",
    "            running_loss += loss.item() # å°† PyTorch ä¸­çš„å¼ é‡è½¬æ¢ä¸º Python çš„æ ‡é‡æ•°å€¼\n",
    "            \n",
    "            # æ²¿ç€ç»´åº¦1ï¼ˆç±»åˆ«ç»´åº¦ï¼‰å¯»æ‰¾æœ€å¤§å€¼ï¼Œ predictedæ˜¯æœ€å¤§å€¼çš„ç´¢å¼•ï¼Œä¹Ÿå°±æ˜¯é¢„æµ‹çš„ç±»åˆ«ç¼–å·\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()  # é¢„æµ‹æ­£ç¡®çš„ä¸ªæ•°\n",
    "            total += labels.size(0)  # é€šè¿‡è®¡ç®—æ¯ä¸ªbatchçš„å¤§å°ï¼Œå¾—åˆ°æ€»æ•°\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # ----éªŒè¯----\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% | \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "# è®­ç»ƒæ¨¡å‹\n",
    "train(model, train_loader, val_loader, criterion, optimizer, epochs=5)\n",
    "\n",
    "# 6. æµ‹è¯•è¿‡ç¨‹\n",
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "# æµ‹è¯•æ¨¡å‹\n",
    "test(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eb7d95-958d-4495-88f4-cda1845664a1",
   "metadata": {},
   "source": [
    "### ğŸ” æ¶µç›–å†…å®¹\n",
    "\n",
    "ç¥ç»ç½‘ç»œå±‚ï¼šnn.Linear\n",
    "\n",
    "æ¿€æ´»å‡½æ•°ï¼šnn.ReLU\n",
    "\n",
    "æ­£åˆ™åŒ–ï¼šnn.Dropout\n",
    "\n",
    "æŸå¤±å‡½æ•°ï¼šnn.CrossEntropyLossï¼ˆå†…éƒ¨åŒ…å« LogSoftmax + NLLLossï¼‰\n",
    "\n",
    "è¯„ä¼°æŒ‡æ ‡ï¼šå‡†ç¡®ç‡ï¼ˆAccuracyï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb933cd-ca1e-4232-84fd-9e43751258ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ac2d5-6aea-4a4d-a43b-4cbd1d223e40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c4b3dd-badf-467b-9672-ef0cc07e82ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d3791-da09-4893-9563-d6828c60e713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3e86934-0cd6-4009-a96e-004d6c45abc6",
   "metadata": {},
   "source": [
    "# nn.Sequentialã€‚\n",
    "\n",
    "## æ ¸å¿ƒæ¦‚å¿µï¼šnn.Sequential æ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "`nn.Sequential` æ˜¯ä¸€ä¸ªæœ‰åºçš„å®¹å™¨ (Ordered Container)ã€‚ä½ å¯ä»¥æŠŠå®ƒæƒ³è±¡æˆä¸€æ¡**`â€œç¥ç»ç½‘ç»œæµæ°´çº¿â€`**ã€‚ä½ å°†ä¸€ç³»åˆ—çš„ç¥ç»ç½‘ç»œå±‚ï¼ˆå¦‚å·ç§¯å±‚ã€æ¿€æ´»å‡½æ•°ã€çº¿æ€§å±‚ç­‰ï¼‰æŒ‰ç…§ä½ å¸Œæœ›æ•°æ®æµåŠ¨çš„é¡ºåºï¼Œä¸€ä¸ªä¸ªåœ°æ”¾å…¥è¿™ä¸ªå®¹å™¨ä¸­ã€‚\n",
    "\n",
    "å½“ä½ å°†æ•°æ®è¾“å…¥åˆ°è¿™ä¸ª `Sequential` å®¹å™¨æ—¶ï¼Œæ•°æ®ä¼šè‡ªåŠ¨åœ°ã€ä¸¥æ ¼åœ°æŒ‰ç…§ä½ æ·»åŠ çš„é¡ºåºï¼Œä¾æ¬¡æµè¿‡æ¯ä¸€ä¸ªå±‚ï¼Œå‰ä¸€å±‚çš„è¾“å‡ºå°±æ˜¯åä¸€å±‚çš„è¾“å…¥ã€‚\n",
    "\n",
    "å®ƒæœ¬èº«ä¹Ÿæ˜¯ä¸€ä¸ª `nn.Module`ï¼Œè¿™æ„å‘³ç€ä½ å¯ä»¥å°†ä¸€ä¸ª `Sequential` å®¹å™¨ä½œä¸ºä¸€ä¸ªå•ç‹¬çš„â€œå±‚â€ï¼ŒåµŒå¥—åœ¨å¦ä¸€ä¸ªæ›´å¤æ‚çš„è‡ªå®šä¹‰æ¨¡å‹ä¸­ã€‚\n",
    "\n",
    "---\n",
    "## ä¸ºä»€ä¹ˆéœ€è¦ nn.Sequentialï¼Ÿ\n",
    "å¯¹äºè®¸å¤šç¥ç»ç½‘ç»œç»“æ„ï¼Œå°¤å…¶æ˜¯é‚£äº›â€œç›´ä¸Šç›´ä¸‹â€ã€æ²¡æœ‰åˆ†æ”¯æˆ–è·³è·ƒè¿æ¥çš„ç®€å•ç½‘ç»œï¼ˆå¦‚å¤šå±‚æ„ŸçŸ¥æœº MLPã€VGGç½‘ç»œä¸­çš„å·ç§¯å—ï¼‰ï¼Œ`nn.Sequential` å¯ä»¥æå¤§åœ°ç®€åŒ–ä»£ç ã€‚\n",
    "\n",
    "å¯¹æ¯”ä¸€ä¸‹ä½ å°±æ˜ç™½äº†ï¼š\n",
    "\n",
    "ä¸ä½¿ç”¨ `nn.Sequential` çš„å†™æ³• \n",
    "- ä½ éœ€è¦ï¼š\n",
    "\n",
    "    - 1.åœ¨` __init__ `ä¸­åˆ†åˆ«å®šä¹‰æ¯ä¸€ä¸ªå±‚ã€‚\n",
    "\n",
    "    - 2.åœ¨` forward `æ–¹æ³•ä¸­ï¼Œæ‰‹åŠ¨åœ°ã€ä¸€æ­¥æ­¥åœ°è°ƒç”¨æ¯ä¸€ä¸ªå±‚ï¼Œå°†æ•°æ®â€œæ¥åŠ›â€ä¸‹å»ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46052a99-c3f5-4abe-bfae-b11570607772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MyMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(784, 256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(256, 128)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "\n",
    "model_custom = MyMLP()\n",
    "print(model_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686e6bcf-dac1-454e-b013-63554c567f40",
   "metadata": {},
   "source": [
    "### ä½¿ç”¨ nn.Sequential çš„å†™æ³•\n",
    "ä½ åªéœ€è¦å°†æ‰€æœ‰å±‚æŒ‰é¡ºåºæ”¾å…¥ `nn.Sequential` å®¹å™¨å³å¯ï¼ŒPyTorch ä¼šè‡ªåŠ¨ä¸ºä½ å¤„ç† `forward` çš„é€»è¾‘ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8726f26d-6c54-4329-9389-a83631816776",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "model_sequential = nn.Sequential(\n",
    "    nn.Linear(784, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    ")\n",
    "\n",
    "print(model_sequential)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5de53b-e7c5-465b-a5c1-814a5409be98",
   "metadata": {},
   "source": [
    "- ä¼˜ç‚¹æ˜¾è€Œæ˜“è§ï¼šä»£ç æ›´ç®€æ´ã€æ›´ç´§å‡‘ã€å¯è¯»æ€§æ›´é«˜ï¼Œå‡å°‘äº†æ ·æ¿ä»£ç ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## åˆ›å»º nn.Sequential çš„ä¸‰ç§æ–¹å¼\n",
    "### 1. ç›´æ¥ä¼ å…¥æ¨¡å—ä½œä¸ºå‚æ•°\n",
    "è¿™æ˜¯æœ€å¸¸ç”¨ã€æœ€ç›´æ¥çš„æ–¹å¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a982a43-a018-4b8c-b3de-4b202b960c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 20, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(20, 64, 5),\n",
    "    nn.ReLU()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a321175-919d-4fb7-8798-e6a4ba8fc81f",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. ä½¿ç”¨æœ‰åºå­—å…¸ (collections.OrderedDict)\n",
    "è¿™ç§æ–¹å¼çš„å¥½å¤„æ˜¯ï¼Œä½ å¯ä»¥ä¸ºå®¹å™¨ä¸­çš„æ¯ä¸€ä¸ªæ¨¡å—è‡ªå®šä¹‰ä¸€ä¸ªåå­—ã€‚è¿™åœ¨åç»­è®¿é—®ç‰¹å®šå±‚æˆ–è°ƒè¯•æ—¶éå¸¸æœ‰ç”¨ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a3445b-268c-490f-a35e-bca9ef00c286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torch.nn as nn\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('conv1', nn.Conv2d(1, 20, 5)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('conv2', nn.Conv2d(20, 64, 5)),\n",
    "    ('relu2', nn.ReLU())\n",
    "]))\n",
    "\n",
    "print(model)\n",
    "\n",
    "è¾“å‡ºä¼šå¸¦æœ‰ä½ å®šä¹‰çš„åå­—ï¼š\n",
    "Sequential(\n",
    "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (relu1): ReLU()\n",
    "  (conv2): Conv2d(20, 64, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (relu2): ReLU()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1a313f-d32d-494b-a3a8-92fc0e6c78b8",
   "metadata": {},
   "source": [
    "### 3. ä½¿ç”¨ add_module() æ–¹æ³•\n",
    "ä½ å¯ä»¥å…ˆåˆ›å»ºä¸€ä¸ªç©ºçš„ `Sequential` å®¹å™¨ï¼Œç„¶ååŠ¨æ€åœ°å‘å…¶ä¸­æ·»åŠ æ¨¡å—ã€‚è¿™åœ¨æ¨¡å‹ç»“æ„éœ€è¦é€šè¿‡å¾ªç¯ç­‰ç¼–ç¨‹æ–¹å¼ç”Ÿæˆæ—¶éå¸¸æ–¹ä¾¿ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5de646-317c-4024-8e55-131c94d97dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module('conv1', nn.Conv2d(1, 20, 5))\n",
    "model.add_module('relu1', nn.ReLU())\n",
    "model.add_module('conv2', nn.Conv2d(20, 64, 5))\n",
    "model.add_module('relu2', nn.ReLU())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b3fccd-a276-40d6-9370-9efbc024f979",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a31ec27-35f0-40bc-96ad-0bd85903a2e0",
   "metadata": {},
   "source": [
    "## å¦‚ä½•è®¿é—®å­æ¨¡å—\n",
    "ä» `nn.Sequential` å®¹å™¨ä¸­è®¿é—®ç‰¹å®šçš„å±‚ä¹Ÿå¾ˆç®€å•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd2c796-fa30-4ee0-8778-ce6b366d8d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‡è®¾ model æ˜¯ç”¨ä¸Šé¢ OrderedDict åˆ›å»ºçš„\n",
    "# 1. é€šè¿‡ç´¢å¼•è®¿é—® (æ‰€æœ‰åˆ›å»ºæ–¹å¼éƒ½æ”¯æŒ)\n",
    "first_layer = model[0]       # è·å–ç¬¬ä¸€ä¸ª Conv2d\n",
    "first_relu = model[1]      # è·å–ç¬¬ä¸€ä¸ª ReLU\n",
    "print(first_layer)\n",
    "\n",
    "# 2. é€šè¿‡è‡ªå®šä¹‰çš„åç§°è®¿é—® (ä»…é™ä½¿ç”¨ OrderedDict æˆ– add_module åˆ›å»ºæ—¶)\n",
    "conv1_layer = model.conv1    # ä½¿ç”¨ç‚¹è®°æ³•\n",
    "# æˆ–è€…\n",
    "conv2_layer = model['conv2'] # ä½¿ç”¨å­—å…¸é”®è®°æ³•\n",
    "\n",
    "print(conv2_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98c1ee4-5ad7-4329-b3d0-45eb8cae2151",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beff65c-a789-4732-a9ab-af878a2c269b",
   "metadata": {},
   "source": [
    "## `nn.Sequential` çš„å±€é™æ€§ï¼ˆä½•æ—¶ä¸è¯¥ç”¨å®ƒï¼‰\n",
    "`nn.Sequential` è™½ç„¶æ–¹ä¾¿ï¼Œä½†å®ƒåªé€‚ç”¨äº**â€œ`ä¸€æ¡è·¯èµ°åˆ°é»‘`â€çš„çº¿æ€§ç»“æ„ã€‚å¦‚æœä½ çš„æ¨¡å‹ç»“æ„åŒ…å«ä»¥ä¸‹ä»»ä½•ä¸€ç§æƒ…å†µï¼Œå°±ä¸èƒ½**å•ç‹¬ä½¿ç”¨ `nn.Sequential`ï¼š\n",
    "\n",
    " -  1ã€`å¤šè¾“å…¥æˆ–å¤šè¾“å‡º`: `Sequential` åªèƒ½å¤„ç†å•è¾“å…¥ã€å•è¾“å‡ºçš„æµç¨‹ã€‚\n",
    "\n",
    " -  2ã€`è·³è·ƒ/æ®‹å·®è¿æ¥` (`Skip`/`Residual Connections`): åƒ `ResNet` ä¸­é‚£æ ·ï¼Œéœ€è¦å°†å‰é¢å±‚çš„è¾“å…¥ x ä¸åé¢å±‚çš„è¾“å‡ºç›¸åŠ ã€‚\n",
    "\n",
    " -  3ã€`åˆ†æ”¯ç»“æ„`: æ•°æ®æµéœ€è¦åˆ†å‰ï¼Œç»è¿‡ä¸åŒçš„å¤„ç†åå†åˆå¹¶ã€‚\n",
    "\n",
    "### ç¤ºä¾‹ï¼šä¸€ä¸ª `nn.Sequential` æ— æ³•å®ç°çš„æ®‹å·®å—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092f8e3c-1537-4d7e-a0df-59295d5e4d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        # self.main_path å¯ä»¥æ˜¯ Sequentialï¼Œå› ä¸ºå®ƒå†…éƒ¨æ˜¯çº¿æ€§çš„\n",
    "        self.main_path = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv_skip = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # æ•°æ®åœ¨ä¸»è·¯å¾„ä¸ŠæµåŠ¨\n",
    "        main_output = self.main_path(x)\n",
    "        \n",
    "        # æ•°æ®åœ¨è·³è·ƒè¿æ¥è·¯å¾„ä¸ŠæµåŠ¨\n",
    "        skip_output = self.conv_skip(x)\n",
    "        \n",
    "        # ä¸¤æ¡è·¯å¾„çš„ç»“æœéœ€è¦ç›¸åŠ ï¼Œè¿™æ˜¯ nn.Sequential æ— æ³•è‡ªåŠ¨å¤„ç†çš„\n",
    "        return main_output + skip_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fda45b-b1db-4e60-9c17-73fa50191dae",
   "metadata": {},
   "source": [
    "åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œ`forward` å‡½æ•°ä¸­åŒ…å«äº† `main_output` + `skip_output` è¿™æ ·çš„éçº¿æ€§æ“ä½œï¼Œå› æ­¤å¿…é¡»è‡ªå®šä¹‰ `nn.Module`ã€‚ä¸è¿‡ï¼Œä½ å¯ä»¥çœ‹åˆ° `Sequential` ä¾ç„¶å¯ä»¥ç”¨æ¥`æ„å»ºå…¶ä¸­çº¿æ€§çš„éƒ¨åˆ†`ï¼ˆå¦‚ `self.main_path`ï¼‰ï¼Œè¿™ä½“ç°äº†å®ƒçš„ç»„åˆæ€§ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## æ€»ç»“\n",
    " - `nn.Sequential` æ˜¯ä¸€ä¸ªç”¨äºå¿«é€Ÿæ­å»º`çº¿æ€§å±‚å `æ¨¡å‹çš„ä¾¿æ·å®¹å™¨ã€‚\n",
    "\n",
    " - å®ƒé€šè¿‡è‡ªåŠ¨å¤„ç† `forward` ä¼ é€’ï¼Œæå¤§åœ°ç®€åŒ–äº†ä»£ç ã€‚\n",
    "\n",
    " - ä½ å¯ä»¥ä½¿ç”¨`æœ‰åºå­—å…¸`æˆ– `add_module` ä¸ºå±‚å‘½åï¼Œæ–¹ä¾¿åç»­è®¿é—®å’Œè°ƒè¯•ã€‚\n",
    "\n",
    " - å½“æ¨¡å‹æ¶‰åŠè·³è·ƒè¿æ¥ã€åˆ†æ”¯ã€å¤šè¾“å…¥/è¾“å‡ºç­‰å¤æ‚ç»“æ„æ—¶ï¼Œä½ å¿…é¡»å›å½’åˆ°ç»§æ‰¿ `nn.Module` å¹¶æ‰‹åŠ¨ç¼–å†™ `forward` æ–¹æ³•çš„ä¼ ç»Ÿæ–¹å¼ã€‚\n",
    "\n",
    " - å³ä½¿åœ¨å¤æ‚çš„æ¨¡å‹ä¸­ï¼Œ`nn.Sequential` ä¾ç„¶æ˜¯æ„å»ºæ¨¡å‹å±€éƒ¨çº¿æ€§å—çš„ç»ä½³å·¥å…·ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d0dfb3-7d34-45d2-ba84-a9e201c0410a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc33da1-e782-4bdb-afe1-137321f2eead",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepseek_env]",
   "language": "python",
   "name": "conda-env-deepseek_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
