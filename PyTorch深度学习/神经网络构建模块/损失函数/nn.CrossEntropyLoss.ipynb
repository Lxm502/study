{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472f77e3-2ab0-4a53-b753-6b161d9d645e",
   "metadata": {},
   "source": [
    "# 1. 背景：为什么用交叉熵损失`nn.CrossEntropyLoss`？\n",
    "\n",
    "分类任务的目标是让模型预测的类别分布接近真实标签。\n",
    "\n",
    "- 真实标签：通常是一个类别编号（比如 0, 1, 2,...）。\n",
    "\n",
    "- 预测结果：模型输出的往往是未归一化的分数（logits）。\n",
    "\n",
    "交叉熵损失（`Cross Entropy Loss`）能度量 预测分布与真实分布之间的差异，预测越准确，损失越小。\n",
    "\n",
    "# 2. 定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3869ff7-7e40-4fd7-a6ef-bdd7d4f864a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.CrossEntropyLoss(\n",
    "    weight=None,\n",
    "    size_average=None,\n",
    "    ignore_index=-100,\n",
    "    reduce=None,\n",
    "    reduction='mean',\n",
    "    label_smoothing=0.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e7dda0-a908-4d1a-84ba-bfcbd7505e26",
   "metadata": {},
   "source": [
    "| 参数                   | 作用                                                                               |\n",
    "| -------------------- | -------------------------------------------------------------------------------- |\n",
    "| **weight**           | 各类别的损失权重（Tensor，形状 = `[num_classes]`）。用于类别不均衡。                                   |\n",
    "| **ignore\\_index**    | 忽略某个类别的损失计算（比如在 NLP 任务里，填充 `PAD` 的标签）。                                           |\n",
    "| **reduction**        | 指定如何聚合 batch 内损失：<br> - `'mean'`：取平均（默认）<br> - `'sum'`：求和<br> - `'none'`：返回逐样本损失 |\n",
    "| **label\\_smoothing** | 标签平滑，减少过拟合。比如 `0.1` 表示把 10% 的概率分散给其它类别。                                          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e80f14d-2416-4a16-aaf7-e2207e782aa9",
   "metadata": {},
   "source": [
    "## 使用示例\n",
    "### (1) 单一样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc8ea9-b9b3-4b9d-bb70-a7de276c79a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 假设类别数=3，模型输出 logits（未经过 softmax）\n",
    "logits = torch.tensor([[1.5, 0.5, -1.0]])  # shape = [1, 3]\n",
    "target = torch.tensor([0])  # 真实类别是第0类\n",
    "\n",
    "loss = loss_fn(logits, target)\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da62bb9f-cafe-41b9-9664-1d19be296db5",
   "metadata": {},
   "source": [
    "- 注意：输入 `logits`，不要提前做` softmax`(模型中不需要定义softmax层，直接输出`logits`（逻辑值）)，因为 `nn.CrossEntropyLoss` 内部已经包含了 `LogSoftmax` + `NLLLoss`。\n",
    "\n",
    "### (2) 批量输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b8bc79-ce6d-40a1-a322-ab53213268e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch=4, 类别数=3\n",
    "logits = torch.tensor([\n",
    "    [2.0, 1.0, 0.1],   # 预测类别 0\n",
    "    [0.5, 2.5, 0.3],   # 预测类别 1\n",
    "    [0.1, 0.2, 3.0],   # 预测类别 2\n",
    "    [1.2, 0.7, 1.0]    # 预测类别 0\n",
    "])  # shape = [4, 3]\n",
    "\n",
    "targets = torch.tensor([0, 1, 2, 0])  # 真实标签\n",
    "\n",
    "loss = loss_fn(logits, targets)\n",
    "print(loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251e71fa-2486-4e9c-aa84-046adeab4397",
   "metadata": {},
   "source": [
    "## 常见误区\n",
    "\n",
    "1、不要对 `logits` 先做 `softmax`，否则会导致梯度消失或结果错误。\n",
    "\n",
    "-   模型输出 → 直接传入 `CrossEntropyLoss`。\n",
    "\n",
    "2、`target` 必须是类别索引（整型 `Tensor`），不是` one-hot`。\n",
    "\n",
    "-   比如` target=[2]`，而不是 [0,0,1]。\n",
    "\n",
    "3、在 `二分类` 时，也推荐用 `CrossEntropyLoss`（而不是 BCE），因为它更数值稳定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6be44e-f8d0-484c-a436-e9d36b0ef41a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
