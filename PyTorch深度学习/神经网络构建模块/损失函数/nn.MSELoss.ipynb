{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "731cf89f-376c-41d9-85b0-fd6b1b34f116",
   "metadata": {},
   "source": [
    "# 1. 背景：为什么用 MSE Loss？\n",
    "\n",
    "在回归问题（预测一个连续值，比如房价、气温）中，我们希望预测值 y^尽可能接近真实值 𝑦\n",
    "\n",
    "- 均方误差 (`Mean Squared Error`, `MSE`) 是最常见的度量方法：\n",
    "\n",
    "    - 计算预测值和真实值的差（误差）；\n",
    "    \n",
    "    - 平方后取平均，保证误差为正，且放大大误差。\n",
    "\n",
    "# 2. 定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09fcf0d-8355-49d0-b29f-59ae4b338d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.MSELoss(\n",
    "    size_average=None,\n",
    "    reduce=None,\n",
    "    reduction='mean'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7616fc83-1339-4372-9038-5c41063ec306",
   "metadata": {},
   "source": [
    "| 参数                         | 作用                                                                                       |\n",
    "| -------------------------- | ---------------------------------------------------------------------------------------- |\n",
    "| **reduction**              | 控制损失的聚合方式：<br> - `'mean'`（默认）：求所有样本的平均损失<br> - `'sum'`：把所有样本损失相加<br> - `'none'`：逐元素返回损失值 |\n",
    "| **size\\_average / reduce** | 已废弃，统一用 `reduction` 参数控制。                                                                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c488e60d-a0b0-4976-bf13-7cd0d36d1936",
   "metadata": {},
   "source": [
    "## 使用示例\n",
    "### (1) 单一样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db3e2516-6be8-424e-a3ff-f013d2fdf0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# 预测值和真实值\n",
    "y_pred = torch.tensor([2.5])\n",
    "y_true = torch.tensor([3.0])\n",
    "\n",
    "loss = loss_fn(y_pred, y_true)\n",
    "print(loss.item())  # 输出 0.25 = (2.5 - 3.0)^2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc86c63-f90e-4fb7-9ae2-39d67561dd12",
   "metadata": {},
   "source": [
    "### (2) 多个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b194efa-b937-4f37-87bf-2de524b70a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "y_pred = torch.tensor([2.5, 0.0, 2.1, 7.8])\n",
    "y_true = torch.tensor([3.0, -0.5, 2.0, 7.0])\n",
    "\n",
    "loss = loss_fn(y_pred, y_true)\n",
    "print(loss.item())\n",
    "# 计算过程:\n",
    "# ((2.5-3.0)^2 + (0.0-(-0.5))^2 + (2.1-2.0)^2 + (7.8-7.0)^2) / 4\n",
    "# = (0.25 + 0.25 + 0.01 + 0.64) / 4 = 0.2875\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50eecb1-5db1-4c5c-9ebd-043404d1643f",
   "metadata": {},
   "source": [
    "### (3) 控制 reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226476b1-70d7-49ca-97e7-02912fd65939",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_sum = nn.MSELoss(reduction='sum')\n",
    "loss_fn_none = nn.MSELoss(reduction='none')\n",
    "\n",
    "y_pred = torch.tensor([1.0, 2.0, 3.0])\n",
    "y_true = torch.tensor([2.0, 2.0, 2.0])\n",
    "\n",
    "print(loss_fn_sum(y_pred, y_true))   # 2.0 (平方和)\n",
    "print(loss_fn_none(y_pred, y_true))  # tensor([1., 0., 1.]) (逐元素损失)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d62bfec-d879-44a0-a1e5-853cded39006",
   "metadata": {},
   "source": [
    "## 特点\n",
    "\n",
    "✅ 优点：\n",
    "\n",
    "- 简单直观，常用于回归。\n",
    "\n",
    "- 对较大误差更敏感（因为平方）。\n",
    "\n",
    "⚠️ 缺点：\n",
    "\n",
    "- 对异常值（`outliers`）非常敏感（大误差平方后会主导损失）。\n",
    "\n",
    "- 有时会收敛慢，可以考虑 `MA`（`L1Loss`） 或 `HuberLoss`。\n",
    "\n",
    "---\n",
    "## 应用场景\n",
    "\n",
    "- 回归问题（房价预测、股票预测）\n",
    "\n",
    "- 自编码器（重建误差）\n",
    "\n",
    "- GAN 判别器的某些变体\n",
    "\n",
    "- 强化学习中的 Q 值回归"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a50cd04-6a3f-4617-a65f-7ced915611b4",
   "metadata": {},
   "source": [
    "# 📊 损失函数对比表\n",
    "\n",
    "| 损失函数             | 特点          | 优点                    | 缺点                         | 适用场景                  |                          |                  |\n",
    "| ---------------- | ----------- | --------------------- | -------------------------- | --------------------- | ------------------------ | ---------------- |\n",
    "| **MSE (均方误差)**   | 误差平方后再平均    | - 对大误差敏感<br>- 常见且易于优化 | - 对异常值非常敏感（outliers 会主导损失） | 普通回归、图像重建、自编码器        |                          |                  |\n",
    "| **MAE (平均绝对误差)** | 直接取绝对值                     | - 对异常值鲁棒<br>- 反映中位数趋势 | - 不可导点在 0 处<br>- 收敛速度可能慢 | 对异常值敏感的数据（金融、医疗） |\n",
    "| **Huber Loss**   | 结合 MSE（对小误差）和 MAE（对大误差）| - 对异常值不敏感（比MSE稳健）<br>- 处处可导（比MAE利于优化）<br>- 平衡精度与鲁棒性| - 需手动调参（δ 阈值）<br>- 计算稍复杂于 MSE/MAE|- 回归任务含少量异常值<br>- 需兼顾准确性和鲁棒性（如目标检测、金融预测、机器人控制）|                          |                  |\n",
    "\n",
    "\n",
    "- 直观理解\n",
    "\n",
    "    - MSE：大误差会被放大 🚨\n",
    "    - MAE：所有误差一视同仁 ⚖️\n",
    "    - Huber：小误差用平方（收敛快），大误差用绝对值（抗异常） 🔧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc22428-a40c-4eb5-bdd3-e0cd6ac0892f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
