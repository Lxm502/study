{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d83253b8-b322-423c-824c-f0562111dfd3",
   "metadata": {},
   "source": [
    "# 1.为什么要用 Batch Normalization？\n",
    "\n",
    "在神经网络训练中，隐藏层的输入分布会随着训练过程不断变化（叫做 Internal Covariate Shift，`内部协变量偏移`），这会导致训练变慢甚至不稳定。\n",
    "\n",
    "- `Batch Normalization` (BN) 的作用就是：\n",
    "\n",
    "    - 将每一层的输入标准化（均值为 0，方差为 1），保证分布稳定。\n",
    "    \n",
    "    - 同时引入可学习的缩放因子 γ（weight）和偏移因子 β（bias），以保留模型表达能力。\n",
    "    \n",
    "    - 可以加速收敛，减轻梯度消失/爆炸。\n",
    "\n",
    "# 2. nn.BatchNorm2d 的定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb3083b-9e8b-459c-ad69-fdcae4c72c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.BatchNorm2d(\n",
    "    num_features, \n",
    "    eps=1e-5, \n",
    "    momentum=0.1, \n",
    "    affine=True, \n",
    "    track_running_stats=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0651b246-a25b-423a-b141-575e86b2b7ed",
   "metadata": {},
   "source": [
    "| 参数                        | 作用                                                 |\n",
    "| ------------------------- | -------------------------------------------------- |\n",
    "| **num\\_features**         | 特征图的通道数（即 `Conv2d` 的输出通道数 `out_channels`）。         |\n",
    "| **eps**                   | 为了数值稳定性，在分母加上的一个小常数，防止除以 0。默认 `1e-5`。              |\n",
    "| **momentum**              | 动量参数，用于更新**全局均值和方差**的移动平均。默认 `0.1`。                |\n",
    "| **affine**                | 是否学习可训练的缩放参数 γ 和偏移参数 β。默认 `True`。                  |\n",
    "| **track\\_running\\_stats** | 是否跟踪全局均值和方差（用于推理阶段）。训练时会计算 batch 内均值/方差，推理时用全局统计量。 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c95b5e5-4e70-4dd4-88b9-14a34bb91ad6",
   "metadata": {},
   "source": [
    "### 使用示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c32f97-14e2-4a96-a654-d6bb6d84b2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# 假设输入是 (Batch, 3, 32, 32)\n",
    "conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1) # 输出通道是 64\n",
    "bn1 = nn.BatchNorm2d(64) # 必须指定为 64，匹配 conv1 的输出\n",
    "relu1 = nn.ReLU()\n",
    "\n",
    "# ... 后续层\n",
    "conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # 输出通道是 128\n",
    "bn2 = nn.BatchNorm2d(128) # 必须指定为 128，匹配 conv2 的输出\n",
    "relu2 = nn.ReLU()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a76218-dded-472c-912d-845d29524741",
   "metadata": {},
   "source": [
    "## 小细节\n",
    "\n",
    "- 训练 vs 推理\n",
    "\n",
    "    - 训练时：用 `batch` 内统计量。\n",
    "    \n",
    "    - 推理时：用整个训练过程中累计的“滑动平均统计量”。\n",
    "\n",
    "- `num_features` 必须等于通道数，否则会报错。\n",
    "\n",
    "- 如果 `batch size` 很小，`BN` 效果可能不好（因为均值/方差估计不准），这时可考虑 `GroupNorm `/ `LayerNorm` / `InstanceNorm`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a525a15b-e207-443e-bb84-022203edc457",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
