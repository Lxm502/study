{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caa5efd2-1e59-44e0-b317-af524a6bb7f4",
   "metadata": {},
   "source": [
    "# `torch.backends` \n",
    "——它是 PyTorch 的底层计算库控制接口。\n",
    "\n",
    "- 在 PyTorch 中，很多数值计算（特别是矩阵运算、卷积等）并不是由 `PyTorch` 自己实现的，而是调用了 `高性能的第三方库`，比如：\n",
    "\n",
    "    - `cuDNN`（NVIDIA 提供的 GPU 深度学习加速库）\n",
    "    \n",
    "    - `MKL` / `OpenBLAS`（CPU 数学库）\n",
    "    \n",
    "    - `CUDA`（NVIDIA GPU 通用计算平台）\n",
    "\n",
    "而` torch.backends `就是一个 `开关/配置入口`，让我们能够 控制这些底层库的行为，在 `性能` 和 `精度` 之间做平衡。\n",
    "\n",
    "---\n",
    "## 1. 模块结构\n",
    "\n",
    "- `torch.backends` 下有几个子模块，常用的是：\n",
    "\n",
    "- `torch.backends.cudnn` → 控制` cuDNN `库（GPU 加速）\n",
    "\n",
    "- `torch.backends.mkl` → 控制` MKL `库（Intel CPU 加速）\n",
    "\n",
    "- `torch.backends.openmp`→ 控制` OpenMP`（多线程并行计算）\n",
    "\n",
    "- `torch.backends.cuda `→ 一些` CUDA `相关选项（较少用）\n",
    "\n",
    "---\n",
    "## 2. 重点：`torch.backends.cudnn`\n",
    "\n",
    "这是`最常用的部分`，因为` cuDNN `对`卷积`、`RNN` 等 `GPU` 操作有重大加速作用。\n",
    "\n",
    "常见属性:\n",
    "| 属性                                   | 类型   | 作用                                      |\n",
    "| ------------------------------------ | ---- | --------------------------------------- |\n",
    "| `torch.backends.cudnn.enabled`       | bool | 是否启用 cuDNN（默认 True，有 GPU 时建议开启）         |\n",
    "| `torch.backends.cudnn.benchmark`     | bool | 让 cuDNN 自动寻找最优卷积算法（适合输入尺寸固定的情况）         |\n",
    "| `torch.backends.cudnn.deterministic` | bool | 强制使用确定性算法（结果可复现，但可能降低性能）                |\n",
    "| `torch.backends.cudnn.allow_tf32`    | bool | 是否允许使用 TensorFloat-32（在支持的 GPU 上提高训练速度） |\n",
    "\n",
    "---\n",
    "使用示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b49a37-9fb9-40eb-b96b-54b82746ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 启用 cuDNN\n",
    "torch.backends.cudnn.enabled = True  \n",
    "\n",
    "# 适合固定输入大小（如图像分类），提升性能\n",
    "torch.backends.cudnn.benchmark = True  \n",
    "\n",
    "# 为了保证结果可复现\n",
    "torch.backends.cudnn.deterministic = True  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8057b70-2960-493d-953a-8e8b6f4ccecd",
   "metadata": {},
   "source": [
    "⚠️ 注意：\n",
    "\n",
    "`benchmark`=True 会尝试不同的卷积算法并选择最快的，但输入 shape 改变时会重新搜索，可能拖慢速度。\n",
    "\n",
    "`deterministic`=True 会关闭某些非确定性算法，保证实验可复现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3e0b11-a293-41a3-aee3-e887aae07460",
   "metadata": {},
   "source": [
    "## 3. 其他子模块\n",
    "### （1）torch.backends.mkl\n",
    "\n",
    "针对 Intel MKL 库（CPU 数学库）。\n",
    "常见："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878414ef-c8a3-4827-a88b-7bb07851961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.mkl.is_available()   # 是否支持 MKL\n",
    "torch.backends.mkl.is_enabled()     # 是否启用 MKL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875f2cc6-78cc-4f6d-9e25-0bf3b43246a7",
   "metadata": {},
   "source": [
    "### （2）torch.backends.openmp\n",
    "\n",
    "控制 OpenMP（多线程 CPU 并行）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dace83-29d1-4202-96cc-2fc6274eed6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.openmp.is_available()  # 是否支持 OpenMP\n",
    "torch.backends.openmp.is_enabled()    # 是否启用 OpenMP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae95a3de-ddef-4a8d-976c-a5be737a60d9",
   "metadata": {},
   "source": [
    "### （3）torch.backends.cuda\n",
    "\n",
    "一般很少直接用，但里面有一些低级配置。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1b27eb-4d0a-4c28-a112-0fb3e48b18f0",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. 常见使用场景\n",
    "\n",
    "1、加速训练（benchmark 模式）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bf31b5-5f65-4be6-a351-bb9908237af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077810af-37b3-4636-865f-1387b31639f1",
   "metadata": {},
   "source": [
    "适合 输入大小固定（如 ImageNet 分类）。\n",
    "\n",
    "---\n",
    "2、结果可复现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3401bdd3-9793-490f-b047-f118586698d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479e91eb-1084-4c4c-b702-01cbc7e60711",
   "metadata": {},
   "source": [
    "适合科研/实验，保证每次运行结果一致。\n",
    "\n",
    "---\n",
    "3、兼容性调试 \\\n",
    "如果遇到某些 cuDNN 算法导致 NaN 或不收敛，可以直接禁用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e212183-39c7-417a-8c5c-d2451696c0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f80488c-b849-4a48-aa15-b8592998f156",
   "metadata": {},
   "source": [
    "## ✅ 总结：\n",
    "torch.backends 是 PyTorch 提供的 底层性能/兼容性开关，常用于：\n",
    "\n",
    "- cudnn.enabled → 是否用 cuDNN\n",
    "\n",
    "- cudnn.benchmark → 动态选择最优算法（快但不稳定）\n",
    "\n",
    "- cudnn.deterministic → 强制确定性计算（可复现但慢）\n",
    "\n",
    "- mkl / openmp → CPU 底层库支持"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65f35ab-de92-4e66-a8a9-1b80d44a6277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
