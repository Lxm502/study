{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e47d584-a32d-42cd-afea-46a83bc67b8a",
   "metadata": {},
   "source": [
    "# 4、torchvision.transforms。\n",
    "在` Dataset `负责`定位和读取`原始数据、`DataLoader `负责`打包`和`加载数据`之后，`transforms `则负责在数据送入模型前，对原始数据（通常是 PIL Image 对象）进行一系列的“加工处理”。\n",
    "\n",
    "---\n",
    "## ⚡ 核心概念：transforms 是什么？\n",
    "`torchvision.transforms` 模块包含了一系列常见的图像变换操作。这些操作可以被串联起来，形成一个处理流水线。它的核心作用主要有两个：\n",
    "\n",
    "### 1、数据预处理 (Data Preprocessing)：\n",
    "\n",
    "- 神经网络要求输入的数据具有固定的尺寸、格式和数据范围。例如，一个预训练模型可能要求所有输入图片都是 224x224 像素，并且是 `torch.Tensor `类型，像素值也需要经过`归一化`。`transforms` 就是用来完成这些标准化工作的。\n",
    "\n",
    "- ⚠️`关键步骤：尺寸调整、转换成张量 (Tensor)、数据归一化。`\n",
    "\n",
    "### 2、数据增强 (Data Augmentation)：\n",
    "\n",
    "- 这是提升模型性能和泛化能力的关键技术。通过对训练图像进行一系列`随机的变换`（如随机翻转、旋转、裁剪、色彩抖动等），我们可以凭空创造出更多样化的训练样本。\n",
    "\n",
    "- 这相当于`扩充了训练集`，让模型在训练时看到“千变万化”的图像，从而学习到更本质、更鲁棒的特征，有效防止过拟合。\n",
    "\n",
    "- 重要原则：`数据增强只应在训练集` (`training set`) 上使用。在验证集 (validation set) 和测试集 (test set) 上，我们只需要进行必要的预处理，以确保评估结果的一致性和可复现性。`\n",
    "\n",
    "---\n",
    "\n",
    "## 如何使用：transforms.Compose\n",
    "`transforms `模块中最常用的一个类是 `transforms.Compose`。它的作用就像一个容器，可以将多个变换操作串联成一个序列。当你调用这个` Compose `对象时，它会按照`你定义的顺序`，依次对输入的图像执行每一个变换。\n",
    "\n",
    "### 基本用法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b892c0-345f-42a2-bbe6-a9c95c49b8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# 定义一个变换序列\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(256),             # 1. 先把图片尺寸缩放到 256x256\n",
    "    transforms.CenterCrop(224),         # 2. 然后从中心裁剪出 224x224 的区域\n",
    "    transforms.ToTensor(),              # 3. 转换为 Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 4. 进行归一化\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 使用\n",
    "# from PIL import Image\n",
    "# image = Image.open(\"path/to/your/image.jpg\")\n",
    "# transformed_image = data_transform(image) # 应用变换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee162b5-2446-465b-b0ae-ef06adf7cc11",
   "metadata": {},
   "source": [
    "## 常用 transforms 分类详解\n",
    "下面我们分类介绍一些最常用的变换功能。\n",
    "\n",
    "- 1. 尺寸与裁剪 (Sizing and Cropping)\n",
    "    - `transforms.Resize(size)`: 将输入图像的尺寸调整为指定大小。`size `可以是一个整数（短边缩放到该尺寸，长边等比缩放）或一个`元组 (h, w)`。\n",
    "    \n",
    "    - `transforms.CenterCrop(size)`: 从图像`中心裁剪`出指定大小的区域。\n",
    "    \n",
    "    - `transforms.RandomCrop(size, padding=None)`: 从一个`随机位置裁剪`出指定大小的区域。常用于数据增强。\n",
    "    \n",
    "    - `transforms.RandomResizedCrop(size, scale=(0.08, 1.0))`: 这是训练时非常常用且强大的一个变换。它会`随机裁剪原始图像`的一个区域（裁剪`面积和长宽比都是随机`的），然后将这个区域缩放到指定大小。这模拟了物体在不同尺度和位置出现的情况。`\n",
    "\n",
    "- 2. 翻转与旋转 (Flipping and Rotation)\n",
    "    - `transforms.RandomHorizontalFlip(p=0.5)`: 以` p 的概率`（默认为 0.5）对图像进行`水平翻转`。\n",
    "    \n",
    "    - `transforms.RandomVerticalFlip(p=0.5)`: 以` p 的概率`对图像进行`垂直翻转`。\n",
    "    \n",
    "    - `transforms.RandomRotation(degrees)`: 在 (-degrees, +degrees) `范围内随机旋转图像`。\n",
    "\n",
    "- 3. 类型转换与归一化 (Crucial Steps)\n",
    "    - `transforms.ToTensor(): 这是至关重要的一步，它做了三件事：`\n",
    "\n",
    "        - 1、将输入的` PIL Image `或` numpy.ndarray` 转换成` torch.Tensor`。\n",
    "        \n",
    "        - 2、将像素值从` [0, 255] `的范围`缩放`到` [0.0, 1.0] `的范围。\n",
    "        \n",
    "        - 3、将图像的维度顺序从` (H, W, C)` `(高, 宽, 通道)` 改变为` (C, H, W)` `(通道, 高, 宽)`，这是 PyTorch 模型期望的输入格式。\n",
    "\n",
    "    - `transforms.Normalize`(mean, std): 用给定的`均值` (mean) 和`标准差` (std) 对张量图像进行归一化。\n",
    "\n",
    "公式：output=(input−mean)/std\n",
    "\n",
    "- 作用：使不同通道的像素值分布在相似的范围内，这有助于加速模型收敛。\n",
    "\n",
    "- mean 和 std 都是一个包含 C 个元素（对应 C 个通道）的序列。对于在 ImageNet 数据集上预训练的模型，通常使用以下值：\n",
    "\n",
    "- `mean=[0.485, 0.456, 0.406]`\n",
    "\n",
    "- `std=[0.229, 0.224, 0.225]`\n",
    "\n",
    "- 4. 色彩与亮度 (Color Augmentation)\n",
    "    - `transforms.ColorJitter`(brightness=0, contrast=0, saturation=0, hue=0): 随机改变图像的`亮度`、`对比度`、`饱和度`和`色调`。这是非常有效的`颜色数据增强方法`。\n",
    "    \n",
    "    - `transforms.Grayscale`(num_output_channels=1): 将图像转换为灰度图。\n",
    "\n",
    "---\n",
    "\n",
    "## 实战：为训练集和验证集构建不同的处理流\n",
    "这是一个最佳实践，展示了如何为训练和验证/测试阶段定义不同的 transforms 管道。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a350892e-dd5a-4eec-b6ef-7f9dfb478464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "# 假设我们有之前定义的 CatsAndDogsDataset\n",
    "\n",
    "# 1. 为训练集定义变换：包含数据增强\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),  # 随机裁剪和缩放\n",
    "    transforms.RandomHorizontalFlip(),    # 随机水平翻转\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # 随机颜色抖动\n",
    "    transforms.ToTensor(),                # 转换为 Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 归一化\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 2. 为验证集/测试集定义变换：只做必要的预处理\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),             # 缩放\n",
    "    transforms.CenterCrop(224),         # 中心裁剪\n",
    "    transforms.ToTensor(),                # 转换为 Tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], # 归一化\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# 3. 在创建 Dataset 实例时传入对应的 transforms\n",
    "dataset_path = 'data/'\n",
    "\n",
    "# 训练集使用带数据增强的变换\n",
    "train_dataset = CatsAndDogsDataset(root_dir=dataset_path, transform=train_transforms)\n",
    "\n",
    "# 验证集使用固定的预处理变换\n",
    "val_dataset = CatsAndDogsDataset(root_dir=dataset_path, transform=val_test_transforms)\n",
    "\n",
    "\n",
    "# 4. 创建 DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4) # 验证集不需要 shuffle\n",
    "\n",
    "# 现在，从 train_loader 中取出的每个批次都是经过随机增强的，而 val_loader 中的数据则是确定性的。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03651f23-0d0e-4d66-b1ad-f5f90ee53e38",
   "metadata": {},
   "source": [
    "---\n",
    "# 总结\n",
    "`torchvision.transforms `是构建计算机视觉数据管道的核心组件。\n",
    "\n",
    "它的两大职责是`数据预处理`（使数据符合模型输入要求）和`数据增强`（提升模型泛化能力）。\n",
    "\n",
    "使用 `transforms.Compose `可以方便地将多个操作链接成一个处理流水线。\n",
    "\n",
    "`ToTensor() `和` Normalize() `是几乎所有图像预处理流程中都必不可少的步骤。\n",
    "\n",
    "## ⚠️务必记住：\n",
    "为训练集和验证/测试集设置不同的变换流程，`数据增强只用于训练集`。这套 Dataset + DataLoader + transforms \n",
    "的组合拳是所有 PyTorch 视觉任务的标准起点。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d11522c-3ff9-4fc2-bcff-43159c874e72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
