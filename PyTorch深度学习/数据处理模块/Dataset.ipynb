{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b567e54-c25f-4f9f-8cf3-04d9a792b925",
   "metadata": {},
   "source": [
    "# 1、torch.utils.data.Dataset：定义自定义数据集\n",
    "## ⚠️ 核心概念：Dataset 是什么？\n",
    "`torch.utils.data.Dataset` 是一个 `抽象类` (abstract class)，它代表了一个数据集。在 `PyTorch` 中，所有自定义的数据集都应该继承这个类。\n",
    "\n",
    "它的核心思想是 将数据的`具体存储`、`访问方式`与`模型的训练`过程`解耦`。\n",
    "\n",
    "✅ 数据集 `(Dataset)`：\\\n",
    "负责回答两个最基本的问题：“我的数据集里一共有`多少个样本`？” (`__len__`) 和 “请`给我第 i 个样本`” (`__getitem__`)。它只关心单个数据样本的获取和预处理。\n",
    "\n",
    "✅ 数据加载器 (`DataLoader`)：\\\n",
    "负责从 `Dataset` 中取出数据，并把它们打包成一个个批次 (`batch`)，同时还可以进行`数据打乱` (`shuffle`) 和`多进程加载`等操作，高效地喂给模型进行训练。\n",
    "\n",
    "简单来说，`Dataset` 定义了数据的`来源`和`单一样本的处理方式`，而 `DataLoader` 则在此基础上`构建了高效的数据流`。\n",
    "\n",
    "---\n",
    "\n",
    "## 👉 如何使用 `Dataset`：三大要素\n",
    "要创建一个自定义的 `Dataset`，你只需要`继承` `torch.utils.data.Dataset` 并`重写` (`override`) 以下三个方法：\n",
    "\n",
    "### 🧭 `_ _init_ _`(self, ...): 构造函数。\n",
    "\n",
    "- 作用：执行数据集的初始化操作。这通常包括加载数据索引（比如`图片路径`和`对应的标签`）、定义数据变换 (`transform`) 等。\n",
    "\n",
    "- 建议：在这个阶段，`不要` 加载所有的数据到内存中（除非你的数据集非常小）。通常只加载元信息（metadata），比如文件路径列表，这样可以节省大量内存。\n",
    "\n",
    "### 🧭 `_ _len_ _`(self): 返回数据集的样本总数。\n",
    "\n",
    "- 作用：`DataLoader` 需要知道数据集的总大小，以便确定迭代的次数、如何进行索引以及如何生成批次。\n",
    "\n",
    "- 实现：通常是返回你在 `__init__` 中加载的`索引列表的长度`。\n",
    "\n",
    "### 🧭 `_ _getitem_ _`(self, index): 根据索引 `index`获取并返回一个数据样本。\n",
    " \n",
    "- 作用：这是 `Dataset` 的核心。`DataLoader` 会根据需要，传入一个索引 `index`，这个方法则需要根据这个索引定位到具体的数据文件，读取它，进行必要的预处理（如`图像缩放`、`裁剪`、`归一化`、转换成 `Tensor` 等），最后返回处理好的数据样本（通常是一个元组，例如 (`data_tensor`, `label_tensor`)）。\n",
    "\n",
    "- 关键：真正的数据加载和转换（I/O 操作和计算）发生在这里，实现了`“按需加载”`，非常高效。\n",
    "\n",
    "---\n",
    "\n",
    "### 代码示例：自定义一个图像数据集\n",
    "假设我们有如下的文件夹结构，用于一个简单的猫狗分类任务：\n",
    "\n",
    "```\n",
    "data/\n",
    "├── cats/\n",
    "│   ├── cat.0.jpg\n",
    "│   ├── cat.1.jpg\n",
    "│   └── ...\n",
    "└── dogs/\n",
    "    ├── dog.0.jpg\n",
    "    ├── dog.1.jpg\n",
    "    └── ...\n",
    "```\n",
    "### 现在，我们来创建一个自定义的 `Dataset` 来加载这些数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6081138a-0ab1-4a82-924f-b37ef87acf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image # 用于读取图片\n",
    "\n",
    "class CatsAndDogsDataset(Dataset):\n",
    "    \"\"\"自定义猫狗分类数据集\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): 包含 'cats' 和 'dogs' 文件夹的根目录。\n",
    "            transform (callable, optional): 应用于样本的可选变换。\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []  # 用于存储 (图片路径, 标签) 的列表\n",
    "\n",
    "        # 为猫和狗分配标签\n",
    "        # cats -> 0, dogs -> 1\n",
    "        for label, class_name in enumerate(['cats', 'dogs']):\n",
    "            class_dir = os.path.join(self.root_dir, class_name)\n",
    "            for file_name in os.listdir(class_dir):\n",
    "                if file_name.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                    img_path = os.path.join(class_dir, file_name)\n",
    "                    self.samples.append((img_path, label))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        返回数据集中样本的总数。\n",
    "        \"\"\"\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        根据索引 index 获取一个样本。\n",
    "        \"\"\"\n",
    "        # 1. 从 self.samples 中获取图片路径和标签\n",
    "        img_path, label = self.samples[index]\n",
    "\n",
    "        # 2. 读取图片\n",
    "        # 使用 'L' 转换为灰度图，'RGB' 转换为彩色图\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        # 3. 如果定义了变换，则对图片进行变换\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        # 4. 将标签也转换为 Tensor (可选，但推荐)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "        # 5. 返回处理好的图片 Tensor 和标签 Tensor\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f7a616-81fe-4404-b99b-1ce4680bdce4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ⚠️ Dataset 与 DataLoader 的协同工作\n",
    "`Dataset `本身只是一个`数据访问的接口`，它一次只能通过 [] 索引返回一个样本。要实现高效的训练，我们需要` DataLoader`。\n",
    "\n",
    "- `DataLoader` 会从 `Dataset` 中自动拉取数据，并完成以下关键工作：\n",
    "\n",
    "    - `批量处理` (Batching)：将多个样本打包成一个批次 (batch)。\n",
    "    \n",
    "    - `数据打乱` (Shuffling)：在每个` epoch `开始时，随机打乱数据顺序，以增强模型的泛化能力。\n",
    "    \n",
    "    - `并行加载` (Parallel Loading)：使用多个子进程 (num_workers) 同步加载数据，避免数据加载成为 GPU 计算的瓶颈。\n",
    "\n",
    "---\n",
    "\n",
    "### 使用示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b832660-62e5-4f18-8e65-d4b7a85cbc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. 定义数据变换\n",
    "# 这里我们定义了一个简单的变换：将图片缩放到 224x224，然后转换为 Tensor\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # 标准化\n",
    "])\n",
    "\n",
    "# 2. 实例化我们自定义的 Dataset\n",
    "dataset_path = 'data/'\n",
    "custom_dataset = CatsAndDogsDataset(root_dir=dataset_path, transform=data_transform)\n",
    "print(f\"数据集大小: {len(custom_dataset)}\")\n",
    "\n",
    "# 3. 实例化 DataLoader\n",
    "# - dataset: 我们创建的数据集实例\n",
    "# - batch_size: 每个批次包含的样本数\n",
    "# - shuffle: 是否在每个 epoch 开始时打乱数据\n",
    "# - num_workers: 用于数据加载的子进程数量\n",
    "data_loader = DataLoader(dataset=custom_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "# 4. 在训练循环中使用 DataLoader\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    # DataLoader 是一个可迭代对象\n",
    "    for batch_images, batch_labels in data_loader:\n",
    "        # 在这里，batch_images 的形状通常是 (batch_size, channels, height, width)\n",
    "        # batch_labels 的形状通常是 (batch_size)\n",
    "        \n",
    "        # 接下来就可以将这些批次数据送入模型进行训练\n",
    "        # model(batch_images) ...\n",
    "        \n",
    "        print(f\"  - 批次图像形状: {batch_images.shape}\")\n",
    "        print(f\"  - 批次标签形状: {batch_labels.shape}\")\n",
    "        break # 这里只演示一个批次"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdadb4c-0968-4e17-8574-637dd470d403",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ⚠️ 两种类型的 Dataset\n",
    "PyTorch 提供了两种主要类型的 Dataset：\n",
    "\n",
    "1、Map-style Datasets:\n",
    "\n",
    "- 我们上面实现的就属于这种。\n",
    "- 它实现了` __getitem__() `和` __len__() `方法。\n",
    "- 它代表了从索引` (integer)`到数据样本的映射` (map)`。\n",
    "这是最常用的一种。\n",
    "\n",
    "2、Iterable-style Datasets:\n",
    "\n",
    "- 它实现了` __iter__() `方法。\n",
    "- 它代表了数据样本的一个`可迭代对象` (iterable)，类似于 Python 的`生成器`。\n",
    "- 当你无法事先知道数据集的总长度，或者数据是从流中读取时（例如，`从数据库`或`远程服务器持续读取`），这种类型非常有用。\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 总结\n",
    "`torch.utils.data.Dataset` 是 PyTorch 中构建数据输入管道的基石，它定义了如何获取单个数据样本。\n",
    "\n",
    "- 通过继承它并实现` __init__`、`__len__ `和` __getitem__ `这三个核心方法，你可以为任何类型的数据创建自定义的加载逻辑。\n",
    "\n",
    "`Dataset` 必须与` DataLoader` 配合使用，`DataLoader` 在` Dataset `的基础上提供了批处理、数据打乱和并行加载等高级功能，是构建高效、可读性强的数据管道的标准做法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dcfc1a-837b-4c33-8d3f-21aa6c05d40f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
