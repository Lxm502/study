{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79186697-5f7a-4256-9554-73463081ffd9",
   "metadata": {},
   "source": [
    "# ğŸ”¹ 4. æ•°æ®å¤„ç†æ¨¡å—\n",
    "\n",
    "### 1ã€torch.utils.data.Datasetï¼šå®šä¹‰è‡ªå®šä¹‰æ•°æ®é›†\n",
    "\n",
    "### 2ã€torch.utils.data.DataLoaderï¼šæ‰¹é‡åŠ è½½æ•°æ®\n",
    "\n",
    "### 3ã€torchvision.datasetsï¼šå¸¸ç”¨æ•°æ®é›†ï¼ˆMNISTã€CIFARã€ImageNet ç­‰ï¼‰\n",
    "\n",
    "### 4ã€torchvision.transformsï¼šå›¾åƒé¢„å¤„ç†ï¼ˆè£å‰ªã€ç¼©æ”¾ã€å½’ä¸€åŒ–ã€å¢å¼ºç­‰ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e61512a-5015-43a8-8b9b-c7eee31ced68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecba0af9-9c83-4b96-9686-5e770cacb06a",
   "metadata": {},
   "source": [
    "# æ•°æ®åŠ è½½æ–¹å¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc467796-46f4-4564-828e-292850271234",
   "metadata": {},
   "source": [
    "## 1. ğŸ”¹ æœ€æ ¸å¿ƒå’ŒåŸºç¡€çš„æ–¹å¼ï¼š`Dataset` + `DataLoader`\n",
    "è¿™æ˜¯ `PyTorch` æ•°æ®åŠ è½½çš„åŸºçŸ³ï¼Œå‡ ä¹æ‰€æœ‰å…¶ä»–æ–¹å¼éƒ½æ˜¯åœ¨æ­¤åŸºç¡€ä¸Šæ„å»ºçš„ã€‚å®ƒé‡‡ç”¨äº†â€œ`ç»„åˆ`â€çš„è®¾è®¡æ¨¡å¼ï¼Œå°†æ•°æ®æ¥æº (`Dataset`) å’Œæ•°æ®è¯»å–ç­–ç•¥ (`DataLoader`) åˆ†ç¦»ã€‚\n",
    "\n",
    "### ğŸ”¹ ä¸€ã€è‡ªå®šä¹‰ `Dataset` (æœ€å¸¸ç”¨)\n",
    "è¿™æ˜¯æœ€çµæ´»çš„æ–¹å¼ï¼Œä½ éœ€è¦ç»§æ‰¿ `torch.utils.data.Dataset` ç±»å¹¶å®ç°ä¸‰ä¸ªæ–¹æ³•ï¼š\n",
    "\n",
    "- `__init__`: åˆå§‹åŒ–ï¼Œç”¨äºè¯»å–æ–‡ä»¶è·¯å¾„ã€æ ‡ç­¾ç­‰å…ƒä¿¡æ¯ã€‚\n",
    "\n",
    "- `__len__`: è¿”å›æ•°æ®é›†çš„æ€»å¤§å°ã€‚\n",
    "\n",
    "- `__getitem__`: æ ¹æ®ç´¢å¼• `index` è¿”å›ä¸€ä¸ªæ•°æ®æ ·æœ¬ï¼ˆå¦‚å›¾åƒå¼ é‡å’Œæ ‡ç­¾ï¼‰ã€‚\n",
    "\n",
    "ç¤ºä¾‹ï¼ˆåŠ è½½å›¾åƒåˆ†ç±»æ•°æ®é›†ï¼‰ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2475d8c4-5678-4ea3-b277-33204834f2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    è‡ªå®šä¹‰å›¾åƒæ•°æ®é›†ç±»ï¼Œç»§æ‰¿è‡ªPyTorchçš„Datasetç±»\n",
    "    ç”¨äºåŠ è½½æŒ‡å®šç›®å½•ä¸‹çš„å›¾åƒæ–‡ä»¶å¹¶æ”¯æŒæ•°æ®è½¬æ¢\n",
    "    \n",
    "    å‚æ•°:\n",
    "        img_dir (str): åŒ…å«å›¾åƒæ–‡ä»¶çš„ç›®å½•è·¯å¾„\n",
    "        transform (callable, optional): åº”ç”¨äºå›¾åƒçš„è½¬æ¢/å¢å¼ºæ“ä½œ\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–æ•°æ®é›†\n",
    "        \n",
    "        å‚æ•°:\n",
    "            img_dir: å›¾åƒç›®å½•è·¯å¾„\n",
    "            transform: å›¾åƒé¢„å¤„ç†/å¢å¼ºçš„è½¬æ¢å‡½æ•°\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir               # å­˜å‚¨å›¾åƒç›®å½•è·¯å¾„\n",
    "        self.img_names = os.listdir(img_dir) # è·å–ç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶å(å‡è®¾éƒ½æ˜¯å›¾ç‰‡)\n",
    "        self.transform = transform           # å­˜å‚¨è½¬æ¢å‡½æ•°\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"è¿”å›æ•°æ®é›†ä¸­çš„æ ·æœ¬æ•°é‡\"\"\"\n",
    "        return len(self.img_names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        è·å–å•ä¸ªæ ·æœ¬(å›¾åƒå’Œæ ‡ç­¾)\n",
    "        \n",
    "        å‚æ•°:\n",
    "            idx: æ ·æœ¬ç´¢å¼•\n",
    "            \n",
    "        è¿”å›:\n",
    "            å…ƒç»„(image, label): å¤„ç†åçš„å›¾åƒå’Œå¯¹åº”çš„æ ‡ç­¾\n",
    "        \"\"\"\n",
    "        img_path = os.path.join(self.img_dir, self.img_names[idx])  # æ„å»ºå®Œæ•´å›¾åƒè·¯å¾„\n",
    "        image = Image.open(img_path)  # ä½¿ç”¨PILæ‰“å¼€å›¾åƒæ–‡ä»¶\n",
    "        \n",
    "        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…æƒ…å†µå®ç°æ ‡ç­¾è·å–é€»è¾‘\n",
    "        # ä¾‹å¦‚: ä»æ–‡ä»¶åè§£æã€ä»å•ç‹¬æ ‡ç­¾æ–‡ä»¶è¯»å–ç­‰\n",
    "        label = ... # æ ¹æ®å›¾ç‰‡åæˆ–å…¶ä»–æ–¹å¼è·å–æ ‡ç­¾\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # åº”ç”¨è½¬æ¢(å¦‚å½’ä¸€åŒ–ã€è£å‰ªç­‰)\n",
    "            \n",
    "        return image, label  # è¿”å›å›¾åƒå’Œæ ‡ç­¾å¯¹\n",
    "\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹\n",
    "# åˆ›å»ºæ•°æ®é›†å®ä¾‹\n",
    "dataset = CustomImageDataset(\n",
    "    'path/to/images',       # å›¾åƒç›®å½•è·¯å¾„\n",
    "    transform=my_transform  # å›¾åƒè½¬æ¢æ“ä½œ(å¦‚torchvision.transformsä¸­çš„ç»„åˆ)                         \n",
    ")\n",
    "\n",
    "# åˆ›å»ºæ•°æ®åŠ è½½å™¨\n",
    "dataloader = DataLoader(\n",
    "    dataset,        # æ•°æ®é›†å¯¹è±¡\n",
    "    batch_size=32,  # æ¯æ‰¹åŠ è½½çš„æ ·æœ¬æ•°\n",
    "    shuffle=True,   # æ˜¯å¦æ‰“ä¹±æ•°æ®é¡ºåº\n",
    "    num_workers=4   # ä½¿ç”¨4ä¸ªå­è¿›ç¨‹åŠ è½½æ•°æ®\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa001ce-4b2e-431d-a93e-dd58234bc7e6",
   "metadata": {},
   "source": [
    "### ğŸ”¹äºŒã€å†…ç½®æ•°æ®é›†åŠ è½½\n",
    "\n",
    "`PyTorch` åœ¨ `torchvision.datasets`ã€`torchtext.datasets`ã€`torchaudio.datasets` ä¸­æä¾›äº†è®¸å¤šå¸¸è§çš„å…¬å…±æ•°æ®é›†ã€‚\n",
    "- ç‰¹ç‚¹ï¼šç›´æ¥è°ƒç”¨ï¼Œæ”¯æŒ `transforms`ï¼Œä¸€èˆ¬é…åˆ `DataLoader` ä½¿ç”¨ã€‚\n",
    "\n",
    "ç¤ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafafb03-2a08-4d17-8db7-a550928490dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "train_data = datasets.MNIST(root=\"./data\", \n",
    "                            train=True,  # æµ‹è¯•é›† å†™ False\n",
    "                            transform=transform, # æ•°æ®è½¬æ¢\n",
    "                            download=True)\n",
    "train_loader = DataLoader(train_data,    # è¦åŠ è½½çš„æ•°æ®é›†\n",
    "                          batch_size=64, # æ‰¹é‡å¤§å°\n",
    "                          shuffle=True,  # æ˜¯å¦æ‰“ä¹±é¡ºåºï¼ŒéªŒè¯ã€æµ‹è¯•ä¸éœ€è¦ \n",
    "                          pin_memory= True, # æ˜¯å¦å°†æ•°æ®é”é¡µå†…å­˜ä¸­ï¼ŒåŠ é€Ÿ GPU æ•°æ®ä¼ è¾“ï¼ˆåœ¨ GPU è®­ç»ƒæ—¶é€šå¸¸è®¾ä¸º Trueï¼‰\n",
    "                          num_workers=2)  # ç”¨2ä¸ªå­è¿›ç¨‹æ¥åŠ è½½æ•°æ®ï¼ŒåŠ é€Ÿæ•°æ®è¯»å–çš„å…³é”®"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afceadfe-7fe6-40a0-821e-e88441ad56d0",
   "metadata": {},
   "source": [
    "### ğŸ”¹ ä¸‰ã€ImageFolder & DatasetFolder\n",
    "\n",
    "`ImageFolder`ï¼šé’ˆå¯¹æŒ‰ç±»åˆ«å­˜æ”¾çš„å›¾ç‰‡æ•°æ®é›†ï¼Œæ–‡ä»¶å¤¹åå³æ ‡ç­¾ã€‚\n",
    "\n",
    "`DatasetFolder`ï¼šæ›´é€šç”¨ï¼Œæ”¯æŒè‡ªå®šä¹‰æ–‡ä»¶æ ¼å¼ï¼ˆæ¯”å¦‚ .npyã€.wavï¼‰ã€‚\n",
    "\n",
    "ç¤ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee374c68-6388-430d-bc8e-0f9481885c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "dataset = ImageFolder(root=\"./data/train\", transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34441b57-8772-4489-a212-46fac7c0eb73",
   "metadata": {},
   "source": [
    "### ğŸ”¹ å››ã€`TensorDataset` & `ConcatDataset` & `Subset`\n",
    "\n",
    "- `TensorDataset`ï¼šç›´æ¥æŠŠ `Tensor` æ‰“åŒ…æˆæ•°æ®é›†ã€‚\n",
    "\n",
    "- `ConcatDataset`ï¼šå¤šä¸ªæ•°æ®é›†åˆå¹¶ã€‚\n",
    "\n",
    "- `Subset`ï¼šä»ä¸€ä¸ªæ•°æ®é›†ä¸­æŠ½å–éƒ¨åˆ†æ ·æœ¬ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0c1b65-5dd6-476b-b834-a51b4de011f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch\n",
    "\n",
    "x = torch.randn(100, 3, 28, 28)\n",
    "y = torch.randint(0, 10, (100,))\n",
    "dataset = TensorDataset(x, y)\n",
    "loader = DataLoader(dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7688b39b-48e9-4f9d-b7af-7369c5a3780b",
   "metadata": {},
   "source": [
    "### ğŸ”¹ äº”ã€DataLoader å‚æ•°æ–¹å¼\n",
    "\n",
    "`DataLoader` æä¾›äº†å¤šç§çµæ´»çš„åŠ è½½ç­–ç•¥ï¼š\n",
    "\n",
    "- `batch_size` æ‰¹å¤§å°\n",
    "\n",
    "- `shuffle` æ˜¯å¦æ‰“ä¹±\n",
    "\n",
    "- `num_workers` å¤šè¿›ç¨‹å¹¶è¡ŒåŠ è½½\n",
    "\n",
    "- `collate_fn` è‡ªå®šä¹‰ `batch` ç»„è£…æ–¹å¼ï¼ˆæ¯”å¦‚å¤„ç†ä¸åŒé•¿åº¦åºåˆ—ï¼‰\n",
    "\n",
    "- `pin_memory`ã€`persistent_workers` ç­‰æ€§èƒ½ä¼˜åŒ–å‚æ•°\n",
    "\n",
    "---\n",
    "\n",
    "### ğŸ”¹ å…­ã€Streaming / IterableDataset\n",
    "\n",
    "å¦‚æœæ•°æ®é‡ç‰¹åˆ«å¤§ï¼Œä¸èƒ½ä¸€æ¬¡æ€§å­˜åˆ°ç¡¬ç›˜æˆ–å†…å­˜ï¼Œå¯ä»¥ç”¨ `IterableDataset` æ¥æµå¼è¯»å–ï¼Œæ¯”å¦‚ä»ï¼š\n",
    "- æ•°æ®åº“\n",
    "- æ—¥å¿—æµ\n",
    "- åœ¨çº¿æ•°æ®ç”Ÿæˆå™¨\n",
    "\n",
    "ç¤ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864dc14e-85b1-4ae4-a52f-c634b7f1bb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import IterableDataset\n",
    "\n",
    "class MyIterableDataset(IterableDataset):\n",
    "    def __iter__(self):\n",
    "        for i in range(1000):\n",
    "            yield i\n",
    "\n",
    "dataset = MyIterableDataset()\n",
    "for data in dataset:\n",
    "    print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac772b10-2d25-464e-8359-c710b088cb87",
   "metadata": {},
   "source": [
    "### ğŸ”¹ ä¸ƒã€å…¶ä»–å¸¸è§æ–¹å¼\n",
    "\n",
    "1.ç›´æ¥åŠ è½½åˆ° Tensorï¼ˆå°æ•°æ®é›†å¸¸ç”¨ï¼Œç›´æ¥ torch.tensor(data)ï¼‰ã€‚\n",
    "\n",
    "2.HDF5 / LMDB / Parquet ç­‰æ ¼å¼ï¼Œé€šå¸¸é…åˆ Dataset è‡ªå®šä¹‰è¯»å–ã€‚\n",
    "\n",
    "3.WebDatasetï¼ˆtar åˆ†ç‰‡å­˜å‚¨ï¼Œå¸¸ç”¨äºå¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒï¼‰ã€‚\n",
    "\n",
    "4.ç¬¬ä¸‰æ–¹åº“ï¼ˆHugging Face Datasetsã€TorchDataã€Petastorm ç­‰ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6377336-0ce2-4df3-81fe-16457bd5d70c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b0d69b9-33c3-4d21-8dfe-fcc86424e32b",
   "metadata": {},
   "source": [
    "## 2. åŸºäºç´¢å¼•ä¸å¯è¿­ä»£çš„é£æ ¼ï¼š`MapStyleDataset` vs `IterableDataset`\n",
    "ä¸Šè¿°çš„è‡ªå®šä¹‰ `Dataset` å±äº `Map-style Dataset`ã€‚`PyTorch` è¿˜æä¾›äº†å¦ä¸€ç§é£æ ¼ï¼š\n",
    "\n",
    "a)` Map-style Dataset` (ä¸»æµ):\\\n",
    "å®ç°äº† `__getitem__` å’Œ `__len__` æ–¹æ³•ã€‚å®ƒå‡è®¾æ•°æ®é›†æ˜¯ä¸€ä¸ªæ˜ å°„ï¼ˆ`Map`ï¼‰ï¼Œå¯ä»¥é€šè¿‡ç´¢å¼•ï¼ˆå¦‚ 0, 1, 2...ï¼‰éšæœºè®¿é—®ä»»ä½•æ ·æœ¬ã€‚è¿™å¯¹äºå­˜å‚¨åœ¨ç£ç›˜æˆ–å†…å­˜ä¸­çš„æ ‡å‡†æ•°æ®é›†éå¸¸æœ‰æ•ˆã€‚\n",
    "\n",
    "b) `Iterable-style Dataset`:\\\n",
    "éœ€è¦ç»§æ‰¿ `torch.utils.data.IterableDataset` å¹¶å®ç° `__iter__` æ–¹æ³•ã€‚å®ƒè¿”å›ä¸€ä¸ªæ•°æ®æµçš„è¿­ä»£å™¨ã€‚é€‚ç”¨äºï¼š\n",
    "\n",
    "- æ•°æ®æµï¼šæ•°æ®æ˜¯å®æ—¶ç”Ÿæˆçš„ï¼ˆå¦‚ä¼ æ„Ÿå™¨æ•°æ®ï¼‰æˆ–æ¥è‡ªç½‘ç»œæµã€‚\n",
    "\n",
    "- æ— æ³•éšæœºè®¿é—®ï¼šæ•°æ®å­˜å‚¨åœ¨æ— æ³•ç®€å•ç´¢å¼•çš„æ ¼å¼ä¸­ï¼ˆå¦‚å·¨å¤§çš„äºŒè¿›åˆ¶æ–‡ä»¶ï¼Œæ•°æ®åº“æŸ¥è¯¢ç»“æœï¼‰ã€‚\n",
    "\n",
    "- é¿å…éšæœºè¯»å–ï¼šé¡ºåºè¯»å–æ¯”éšæœºè¯»å–å¿«å¾—å¤šçš„æ—¶å€™ï¼ˆå¦‚è¯»å–ç£å¸¦ï¼‰ã€‚\n",
    "\n",
    "ç¤ºä¾‹ï¼ˆè¯»å–ä¸€ä¸ªå·¨å¤§çš„äºŒè¿›åˆ¶æ–‡ä»¶æµï¼‰ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b947762c-f9ca-4636-bed5-fabfe701c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import IterableDataset, DataLoader\n",
    "\n",
    "class BinaryIterableDataset(IterableDataset):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "\n",
    "    def __iter__(self):\n",
    "        with open(self.filename, â€˜rbâ€™) as f:\n",
    "            while True:\n",
    "                data = f.read(1024) # æ¯æ¬¡è¯»å–1024å­—èŠ‚\n",
    "                if not data:\n",
    "                    break\n",
    "                # å°†æ•°æ®è½¬æ¢ä¸ºå¼ é‡\n",
    "                yield torch.frombuffer(data, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e64be1d-b797-40cb-8619-c8fc91d10fb1",
   "metadata": {},
   "source": [
    "## 3. é«˜é˜¶å’Œæ‰©å±•åº“\n",
    "å¯¹äºæ›´å¤æ‚æˆ–å¤§è§„æ¨¡çš„åœºæ™¯ï¼Œç¤¾åŒºå’Œå®˜æ–¹ä¹Ÿæä¾›äº†æ›´å¼ºå¤§çš„å·¥å…·ã€‚\n",
    "\n",
    "a) `DataPipe` (PyTorch 1.10+ å®˜æ–¹æ–°ç‰¹æ€§)\\\n",
    "è¿™æ˜¯ `PyTorch` å®˜æ–¹æ¨èçš„ç”¨äºæ›¿ä»£ä¹‹å‰ `Dataset` çš„æ–° `API`ï¼Œæ—¨åœ¨æä¾›æ›´æ¨¡å—åŒ–ã€å¯ç»„åˆã€å¯æ‰©å±•çš„æ•°æ®å¤„ç†æµç¨‹ã€‚å®ƒä¸ `DataLoader` å…¼å®¹ã€‚\n",
    "\n",
    "- æ ¸å¿ƒæ€æƒ³ï¼šå°†æ•°æ®åŠ è½½å’Œé¢„å¤„ç†æ­¥éª¤åˆ†è§£æˆå¤šä¸ªå°çš„ã€å¯é‡ç”¨çš„ `DataPipe`ï¼Œç„¶ååƒæ­ç§¯æœ¨ä¸€æ ·å°†å®ƒä»¬è¿æ¥èµ·æ¥ã€‚\n",
    "\n",
    "ç¤ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c2fa0a-3c4a-4ed1-bc22-1827894d568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdata.datapipes.iter import IterableWrapper, FileOpener\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªç®€å•çš„æ•°æ®å¤„ç†æµç¨‹\n",
    "datapipe = IterableWrapper([â€˜data_file_1.txtâ€™, â€˜data_file_2.txtâ€™])\n",
    "datapipe = FileOpener(datapipe, mode=â€˜râ€™)\n",
    "datapipe = datapipe.parse_csv(delimiter=â€˜,â€™)\n",
    "\n",
    "dataloader = DataLoader(datapipe, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b574197-2544-42e0-ad6a-199c6b2d9431",
   "metadata": {},
   "source": [
    "b) `torchdistx` å’Œ `DataLoader2` (å®éªŒæ€§) \\\n",
    "ä¸ºäº†åº”å¯¹æ›´æç«¯çš„åˆ†å¸ƒå¼å’Œæ•°æ®åŠ è½½éœ€æ±‚ï¼Œ`PyTorch` æ­£åœ¨å¼€å‘ä¸‹ä¸€ä»£æ•°æ®åŠ è½½å™¨ (`DataLoader2`) å’Œ `torchdistx `åº“ï¼Œç”¨äºåœ¨æ•°æ®åŠ è½½æ—¶è¿›è¡Œå»¶è¿Ÿå¼ é‡åˆå§‹åŒ–ï¼Œå¯ä»¥æå¤§å‡å°‘å†…å­˜å ç”¨ã€‚\n",
    "\n",
    "c) ç¬¬ä¸‰æ–¹åº“ \n",
    "- `WebDataset`: éå¸¸æµè¡Œç”¨äºè¶…å¤§è§„æ¨¡æ•°æ®é›†ï¼Œå®ƒå°†æ•°æ®é›†å­˜å‚¨ä¸º `tar` æ–‡ä»¶ï¼Œæ¯ä¸ªæ ·æœ¬æ˜¯ `tar` å†…çš„ä¸€ä¸ªæ–‡ä»¶ã€‚å¯ä»¥åƒå¤„ç†æ™®é€š`Dataset` ä¸€æ ·é«˜æ•ˆåœ°æµå¼è¯»å–ï¼Œéå¸¸é€‚åˆäº‘å­˜å‚¨ã€‚\n",
    "\n",
    "- `NVIDIA DALI `(Data Loading Library): ä¸€ä¸ªç”¨äºæ•°æ®åŠ è½½å’Œé¢„å¤„ç†çš„ `GPU` åŠ é€Ÿåº“ã€‚å®ƒå°†æ•´ä¸ªæ•°æ®é¢„å¤„ç†ç®¡é“ï¼ˆè§£ç ã€è£å‰ªã€å½’ä¸€åŒ–ç­‰ï¼‰æ”¾åˆ° `GPU` ä¸Šæ‰§è¡Œï¼Œæå¤§å‡å°‘äº† CPU çš„ç“¶é¢ˆã€‚\n",
    "\n",
    "- `PyTorch Geometric` (PyG) / `Deep Graph Library` (DGL): å›¾ç¥ç»ç½‘ç»œåº“ï¼Œå®ƒä»¬æä¾›äº†è‡ªå·±ä¸“ç”¨çš„ `DataLoader `æ¥å¤„ç†å›¾æ•°æ®ï¼Œå¯ä»¥å¤„ç†å¯å˜å¤§å°çš„å›¾å¹¶ç»„æˆæ‰¹å¤„ç†ã€‚\n",
    "\n",
    "---\n",
    "### æ€»ç»“ä¸é€‰æ‹©æŒ‡å—\n",
    "| æ–¹å¼                         | é€‚ç”¨åœºæ™¯                               | ä¼˜ç‚¹                         | ç¼ºç‚¹                             |\n",
    "|------------------------------|----------------------------------------|------------------------------|----------------------------------|\n",
    "| è‡ªå®šä¹‰ Dataset + DataLoader  | ç»å¤§å¤šæ•°æƒ…å†µï¼Œä¸­å°è§„æ¨¡æ•°æ®é›†           | æåº¦çµæ´»ï¼Œå®Œå…¨æ§åˆ¶           | éœ€è¦è‡ªå·±å†™ä»£ç                    |\n",
    "| å†…ç½® Dataset                 | å¿«é€Ÿå¼€å§‹ï¼ŒåŸºå‡†æµ‹è¯•                     | æç®€ï¼Œå¼€ç®±å³ç”¨               | åªé€‚ç”¨äºç‰¹å®šæ•°æ®é›†               |\n",
    "| IterableDataset              | æ•°æ®æµã€æ•°æ®åº“ã€é¡ºåºè¯»å–ä¼˜åŠ¿å¤§         | èŠ‚çœå†…å­˜ï¼Œå¤„ç†æ— é™æ•°æ®æµ     | æ— æ³•éšæœºæ‰“ä¹±ï¼ˆæˆ–å¾ˆéš¾ï¼‰ï¼Œæ— æ³•ç›´æ¥è·å–é•¿åº¦ |\n",
    "| DataPipe                     | æ„å»ºå¤æ‚ã€å¯å¤ç”¨çš„æ•°æ®ç®¡é“             | æ¨¡å—åŒ–ï¼Œå®˜æ–¹æœªæ¥æ–¹å‘         | ç›¸å¯¹è¾ƒæ–°ï¼Œç”Ÿæ€è¿˜åœ¨å‘å±•ä¸­         |\n",
    "| WebDataset                   | è¶…å¤§è§„æ¨¡æ•°æ®é›†ï¼ˆTB/PBçº§ï¼‰ï¼Œäº‘å­˜å‚¨      | é«˜æ•ˆæµå¼è¯»å–ï¼Œæ ¼å¼ç®€å•       | éœ€è¦å°†æ•°æ®æ‰“åŒ…æˆ tar æ ¼å¼        |\n",
    "| NVIDIA DALI                  | æ•°æ®é¢„å¤„ç†æ˜¯æ€§èƒ½ç“¶é¢ˆæ—¶                 | GPU åŠ é€Ÿé¢„å¤„ç†ï¼Œæ€§èƒ½æé«˜     | å¢åŠ ç³»ç»Ÿå¤æ‚æ€§ï¼Œéœ€è¦å­¦ä¹ æ–° API   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4d64af-8fd9-4b26-bf06-653ce7754b97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfa6823-f668-40bf-b1f0-d8196421050b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04ebc3b8-42b5-4cc7-9aad-f1d97f9ae2ef",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcebf012-b5fc-4f61-86db-72a6161af304",
   "metadata": {},
   "source": [
    "# torchvision.datasets.ImageFolder\n",
    "è¿™æ˜¯ `PyTorch` é‡Œæœ€å¸¸è§çš„ å›¾åƒåˆ†ç±»æ•°æ®é›†`è¯»å–æ–¹å¼`ï¼Œå°¤å…¶é€‚åˆå­˜æ”¾åœ¨ `æ–‡ä»¶å¤¹` é‡Œçš„å›¾ç‰‡æ•°æ®ã€‚\n",
    "\n",
    "## 1. åŸºæœ¬ä½œç”¨\n",
    "\n",
    "`ImageFolder` å‡è®¾ä½ çš„æ•°æ®æŒ‰ç…§ä¸‹é¢çš„ç›®å½•ç»“æ„å­˜æ”¾ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da89e7c-a81e-4572-995b-add44744b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "root/          # æ ¹ç›®å½•\n",
    "  â”œâ”€â”€ class1/  # ç±»åˆ«1\n",
    "  â”‚     â”œâ”€â”€ img001.png\n",
    "  â”‚     â”œâ”€â”€ img002.png\n",
    "  â”‚     â””â”€â”€ ...\n",
    "  â”œâ”€â”€ class2/  # ç±»åˆ«2\n",
    "  â”‚     â”œâ”€â”€ img003.png\n",
    "  â”‚     â”œâ”€â”€ img004.png\n",
    "  â”‚     â””â”€â”€ ...\n",
    "  â””â”€â”€ ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac588c7c-e73e-4f7a-a332-1f6cbdfe9fab",
   "metadata": {},
   "source": [
    "- æ¯ä¸ªå­æ–‡ä»¶å¤¹çš„åå­—ï¼ˆ`class1`, `class2`ï¼‰å°±æ˜¯ç±»åˆ«æ ‡ç­¾ã€‚\n",
    "\n",
    "- `ImageFolder` ä¼šè‡ªåŠ¨ç»™ç±»åˆ«åˆ†é… ç´¢å¼• (`int`)ï¼Œæ¯”å¦‚ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb6d592-320e-49f7-a291-86c611011905",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.classes   # ['class1', 'class2']\n",
    "dataset.class_to_idx   # {'class1': 0, 'class2': 1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db658d33-5455-4899-b70a-b447997747d4",
   "metadata": {},
   "source": [
    "## 2. ä¸»è¦å‚æ•°è®²è§£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdf7259-0bb8-45de-81f4-3d4e5f235bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchvision.datasets.ImageFolder(\n",
    "    root: str,\n",
    "    transform: Optional[Callable] = None,\n",
    "    target_transform: Optional[Callable] = None,\n",
    "    loader: Callable[[str], Any] = default_loader,\n",
    "    is_valid_file: Optional[Callable[[str], bool]] = None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70045fd5-3245-4d26-94be-78badf42cc5d",
   "metadata": {},
   "source": [
    "| å‚æ•°                     | ä½œç”¨                                                     |\n",
    "| ---------------------- | ------------------------------------------------------ |\n",
    "| **`root`**             | æ•°æ®é›†çš„æ ¹ç›®å½•ï¼ˆå¿…é¡»ï¼‰ï¼Œå­æ–‡ä»¶å¤¹çš„åå­—å°±æ˜¯ç±»åˆ«ã€‚                               |\n",
    "| **`transform`**        | ä½œç”¨åœ¨ **å›¾ç‰‡** ä¸Šçš„é¢„å¤„ç†æ“ä½œï¼ˆå¦‚ `Resize`ã€`ToTensor`ã€`Normalize`ï¼‰ã€‚ |\n",
    "| **`target_transform`** | ä½œç”¨åœ¨ **æ ‡ç­¾** ä¸Šçš„é¢„å¤„ç†ï¼ˆæ¯”å¦‚æ ‡ç­¾ç¼–ç æˆ– one-hot è½¬æ¢ï¼‰ã€‚                  |\n",
    "| **`loader`**           | æŒ‡å®šå¦‚ä½•è¯»å–å›¾ç‰‡ï¼Œé»˜è®¤æ˜¯ç”¨ `PIL.Image.open` æ‰“å¼€ã€‚                     |\n",
    "| **`is_valid_file`**    | è¿‡æ»¤å™¨å‡½æ•°ï¼Œè¿”å› `True/False`ï¼Œå†³å®šæ–‡ä»¶æ˜¯å¦æœ‰æ•ˆã€‚ä¾‹å¦‚ï¼šåªä¿ç•™ `.jpg` æ–‡ä»¶ã€‚       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f3ad00-b159-4acf-9b9c-fae272bbd49a",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. ä½¿ç”¨ç¤ºä¾‹\n",
    "### ï¼ˆ1ï¼‰æœ€åŸºç¡€çš„ç”¨æ³•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1919dfe2-7c3e-44cd-bad8-26b9967ae3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# å®šä¹‰å›¾åƒé¢„å¤„ç†\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # è°ƒæ•´å¤§å°\n",
    "    transforms.ToTensor(),          # è½¬æ¢ä¸º Tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                         std=[0.5, 0.5, 0.5])  # æ ‡å‡†åŒ–\n",
    "])\n",
    "\n",
    "# åŠ è½½æ•°æ®é›†\n",
    "dataset = datasets.ImageFolder(root=\"./data/train\", transform=transform)\n",
    "\n",
    "print(dataset.classes)        # ç±»åˆ«åå­—\n",
    "print(dataset.class_to_idx)   # ç±»åˆ« -> ç´¢å¼•æ˜ å°„\n",
    "\n",
    "img, label = dataset[0]       # å–ç¬¬ä¸€å¼ å›¾ç‰‡å’Œå¯¹åº”æ ‡ç­¾\n",
    "print(img.shape, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3fad69-8768-42ee-afdb-a15438b7e26e",
   "metadata": {},
   "source": [
    "### ï¼ˆ2ï¼‰ç»“åˆ DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7419eb-fb8a-4d05-989c-1c5810765ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for images, labels in dataloader:\n",
    "    print(images.shape, labels.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040958ce-6edc-4e01-be5b-76a50c45a915",
   "metadata": {},
   "source": [
    "### ï¼ˆ3ï¼‰åªè¯»å–ç‰¹å®šæ ¼å¼çš„æ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25390de0-b17c-4231-a11f-e7919b5a2bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.ImageFolder(\n",
    "    root=\"./data/train\",\n",
    "    transform=transform,\n",
    "    is_valid_file=lambda path: path.endswith(\".jpg\")  # åªä¿ç•™ jpg æ–‡ä»¶\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33e6d76-b435-4243-a6ae-5a680fded8f6",
   "metadata": {},
   "source": [
    "### ï¼ˆ4ï¼‰è‡ªå®šä¹‰æ ‡ç­¾å¤„ç†\n",
    "\n",
    "æ¯”å¦‚ï¼šæŠŠæ•°å­—æ ‡ç­¾è½¬æˆ `one-hot`ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc584c4-51d1-4369-8a80-6dfec0cf6a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "target_transform = lambda y: torch.nn.functional.one_hot(torch.tensor(y), num_classes=2)\n",
    "\n",
    "dataset = datasets.ImageFolder(\n",
    "    root=\"./data/train\",\n",
    "    transform=transform,\n",
    "    target_transform=target_transform\n",
    ")\n",
    "\n",
    "img, label = dataset[0]\n",
    "print(label)  # one-hot å‘é‡\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3286a532-2f79-4dc7-9fc4-e210bcf7b285",
   "metadata": {},
   "source": [
    "## âœ… æ€»ç»“ï¼š\n",
    "\n",
    "- `ImageFolder` é€‚åˆç›®å½•ç»“æ„æ•´é½çš„æ•°æ®é›†ã€‚\n",
    "\n",
    "- å¸¸ç”¨å‚æ•°æ˜¯ `root`ã€`transform`ã€`target_transform`ã€‚\n",
    "\n",
    "- æ­é… `DataLoader` å°±èƒ½æ‰¹é‡åŠ è½½è®­ç»ƒæ•°æ®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff82c8f5-6c4d-4049-9c8b-04107a1e70e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepseek_env]",
   "language": "python",
   "name": "conda-env-deepseek_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
