{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1cdd689-e31a-4535-96f6-a8c480de7e73",
   "metadata": {},
   "source": [
    "# ğŸ”¹ 3. è®­ç»ƒä¸ä¼˜åŒ–\n",
    "\n",
    "## 3.1ã€ä¼˜åŒ–å™¨ (torch.optim)\n",
    "\n",
    "optim.SGD\n",
    "\n",
    "optim.Adam\n",
    "\n",
    "optim.AdamW\n",
    "\n",
    "optim.RMSprop\n",
    "\n",
    "optim.Adagrad\n",
    "\n",
    "## 3.2ã€å­¦ä¹ ç‡è°ƒåº¦å™¨ (torch.optim.lr_scheduler)\n",
    "\n",
    "StepLR\n",
    "\n",
    "ExponentialLR \n",
    "\n",
    "CosineAnnealingLR\n",
    "\n",
    "ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4ee62e-27e8-4cdc-85c3-d3ffe0e4a40a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67d80e5-3365-470e-83be-5117f3a821dd",
   "metadata": {},
   "source": [
    "# è®­ç»ƒ\n",
    "## æ­å»ºè®­ç»ƒå¾ªç¯\n",
    "- æ ¸å¿ƒæ€æƒ³ï¼š\n",
    "    - 1.å‰å‘ä¼ æ’­ (forward)\n",
    "    - 2.è®¡ç®—æŸå¤± (loss)\n",
    "    - 3.åå‘ä¼ æ’­ (backward)\n",
    "    - 4.å‚æ•°æ›´æ–° (optimizer.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f6ea90-85eb-4975-9a9f-0718586aa8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss, total_correct = 0, 0  # è®¾ç½®åˆå§‹å‚æ•°\n",
    "\n",
    "    for data, target in loader:\n",
    "        data, target = data.to(device), target.to(device) # ä¼ é€’åˆ° GPUä¸Šè¿ç®—\n",
    "\n",
    "        optimizer.zero_grad()         # æ¢¯åº¦æ¸…é›¶\n",
    "        output = model(data)          # å‰å‘ä¼ æ’­\n",
    "        loss = criterion(output, target)  # è®¡ç®—æŸå¤±\n",
    "        loss.backward()               # åå‘ä¼ æ’­\n",
    "        optimizer.step()              # æ›´æ–°å‚æ•°\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_correct += (output.argmax(1) == target).sum().item()\n",
    "\n",
    "    acc = total_correct / len(loader.dataset)\n",
    "    return total_loss / len(loader), acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a2bb2c-8987-466f-affb-635253fdb4a2",
   "metadata": {},
   "source": [
    "## é€šç”¨çš„æ¨¡å‹è®­ç»ƒå¾ªç¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7414a5-281c-474a-b214-6798eacb3f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def train_model(model, train_loader, val_loader, loss_fn, \n",
    "                optimizer, device, num_epochs=10, scheduler=None, \n",
    "                save_dir='path', early_stopping_patience=None):\n",
    "    \"\"\"\n",
    "    é€šç”¨çš„æ¨¡å‹è®­ç»ƒå¾ªç¯\n",
    "    \n",
    "    å‚æ•°:\n",
    "        model: è¦è®­ç»ƒçš„æ¨¡å‹\n",
    "        train_loader: è®­ç»ƒæ•°æ®åŠ è½½å™¨\n",
    "        val_loader: éªŒè¯æ•°æ®åŠ è½½å™¨\n",
    "        loss_fn: æŸå¤±å‡½æ•°\n",
    "        optimizer: ä¼˜åŒ–å™¨\n",
    "        device: è®¾å¤‡ (cpu/cuda)\n",
    "        num_epochs: è®­ç»ƒè½®æ•°\n",
    "        scheduler: å­¦ä¹ ç‡è°ƒåº¦å™¨ (å¯é€‰)\n",
    "        save_dir: æ£€æŸ¥ç‚¹ä¿å­˜ç›®å½•\n",
    "        early_stopping_patience: æ—©åœè€å¿ƒå€¼ (å¯é€‰)\n",
    "    \n",
    "    è¿”å›:\n",
    "        è®­ç»ƒå†å²è®°å½•ï¼ŒåŒ…å«æŸå¤±å’Œå‡†ç¡®ç‡\n",
    "    \"\"\"\n",
    "    # åˆ›å»ºä¿å­˜ç›®å½•\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # åˆå§‹åŒ–å†å²è®°å½•\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [],\n",
    "        'val_loss': [], 'val_acc': []\n",
    "    }\n",
    "    \n",
    "    # æ—©åœç›¸å…³å˜é‡\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    \n",
    "    # è®­ç»ƒå¾ªç¯\n",
    "    for epoch in range(num_epochs):\n",
    "        # è®­ç»ƒé˜¶æ®µ\n",
    "        model.train()\n",
    "        train_loss, train_correct = 0, 0 # åˆå§‹å‚æ•°\n",
    "        train_batches = 0\n",
    "        \n",
    "        # ä½¿ç”¨tqdmæ·»åŠ è¿›åº¦æ¡\n",
    "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')\n",
    "        for data, target in train_pbar:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_correct += (output.argmax(1) == target).sum().item()\n",
    "            train_batches += 1\n",
    "            \n",
    "            # æ›´æ–°è¿›åº¦æ¡\n",
    "            train_pbar.set_postfix({\n",
    "                'Loss': f'{train_loss/train_batches:.4f}',\n",
    "                'Acc': f'{100*train_correct/(train_batches * train_loader.batch_size):.2f}%'\n",
    "            })\n",
    "        \n",
    "        # è®¡ç®—è®­ç»ƒæŒ‡æ ‡\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_train_acc = train_correct / len(train_loader.dataset)\n",
    "        \n",
    "        # éªŒè¯é˜¶æ®µ\n",
    "        avg_val_loss, avg_val_acc = validate(model, val_loader, loss_fn, device)\n",
    "        \n",
    "        # æ›´æ–°å­¦ä¹ ç‡è°ƒåº¦å™¨\n",
    "        if scheduler:\n",
    "            if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "                scheduler.step(avg_val_loss)\n",
    "            else:\n",
    "                scheduler.step()\n",
    "        \n",
    "        # è®°å½•å†å²\n",
    "        history['train_loss'].append(avg_train_loss)\n",
    "        history['train_acc'].append(avg_train_acc)\n",
    "        history['val_loss'].append(avg_val_loss)\n",
    "        history['val_acc'].append(avg_val_acc)\n",
    "        \n",
    "        # æ‰“å°epochç»“æœ\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}: '\n",
    "              f'Train Loss: {avg_train_loss:.4f}, Train Acc: {100*avg_train_acc:.2f}% | '\n",
    "              f'Val Loss: {avg_val_loss:.4f}, Val Acc: {100*avg_val_acc:.2f}%')\n",
    "        \n",
    "        # ä¿å­˜æœ€ä½³æ¨¡å‹\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_val_loss,\n",
    "                'acc': avg_val_acc\n",
    "            }, os.path.join(save_dir, 'best_model.pth'))\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        \n",
    "        # æ—©åœæ£€æŸ¥\n",
    "        if early_stopping_patience and epochs_no_improve >= early_stopping_patience:\n",
    "            print(f'Early stopping triggered after {epoch+1} epochs!')\n",
    "            break\n",
    "    \n",
    "    # ä¿å­˜æœ€ç»ˆæ¨¡å‹\n",
    "    torch.save({\n",
    "        'epoch': num_epochs,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict()\n",
    "    }, os.path.join(save_dir, 'final_model.pth'))\n",
    "    \n",
    "    return history\n",
    "\n",
    "def validate(model, loader, loss_fn, device):\n",
    "    \"\"\"éªŒè¯å‡½æ•°\"\"\"\n",
    "    model.eval()\n",
    "    total_loss, total_correct = 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_correct += (output.argmax(1) == target).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    avg_acc = total_correct / len(loader.dataset)\n",
    "    \n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹\n",
    "if __name__ == \"__main__\":\n",
    "    # å‡è®¾å·²æœ‰ä»¥ä¸‹ç»„ä»¶\n",
    "    # model = YourModel()\n",
    "    # train_loader = DataLoader(...)\n",
    "    # val_loader = DataLoader(...)\n",
    "    # loss_fn = nn.CrossEntropyLoss()\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # è®­ç»ƒæ¨¡å‹\n",
    "    # history = train_model(\n",
    "    #     model=model,\n",
    "    #     train_loader=train_loader,\n",
    "    #     val_loader=val_loader,\n",
    "    #     loss_fn=loss_fn,\n",
    "    #     optimizer=optimizer,\n",
    "    #     device=device,\n",
    "    #     num_epochs=50,\n",
    "    #     scheduler=torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1),\n",
    "    #     save_dir='model_checkpoints',\n",
    "    #     early_stopping_patience=5\n",
    "    # )\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c727ec2-b29e-42b8-bd69-a3e29a436d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8757db1b-9c2f-4f79-aeba-db7406648afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7dde72-b740-428c-ae58-28c1156d4e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abc2befc-86ad-44dd-87d3-2bd5fa88a213",
   "metadata": {},
   "source": [
    "# 3.1ã€æ ¸å¿ƒæ¦‚å¿µï¼štorch.optim æ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "`torch.optim `æ˜¯ä¸€ä¸ªåŒ…å«äº†å¤šç§ä¼˜åŒ–ç®—æ³• (Optimization Algorithms) çš„åŒ…ã€‚\n",
    "\n",
    "åœ¨ç¥ç»ç½‘ç»œçš„è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬é€šè¿‡ä»¥ä¸‹æ­¥éª¤è¿›è¡Œï¼š\n",
    "- `1ã€å‰å‘ä¼ æ’­ (Forward Pass)`ï¼šå°†æ•°æ®è¾“å…¥æ¨¡å‹ï¼Œå¾—åˆ°é¢„æµ‹ç»“æœã€‚\n",
    "\n",
    "- `2ã€è®¡ç®—æŸå¤± (Compute Loss)`ï¼šå°†é¢„æµ‹ç»“æœä¸çœŸå®æ ‡ç­¾è¿›è¡Œæ¯”è¾ƒï¼Œè®¡ç®—å‡ºæŸå¤±å€¼ï¼ˆå³æ¨¡å‹çŠ¯äº†å¤šå¤§çš„é”™ï¼‰ã€‚\n",
    "\n",
    "- `3ã€åå‘ä¼ æ’­ (Backward Pass)`ï¼šæ ¹æ®æŸå¤±å€¼ï¼Œè®¡ç®—å‡ºæ¨¡å‹ä¸­æ¯ä¸ªå‚æ•°ï¼ˆæƒé‡å’Œåç½®ï¼‰çš„æ¢¯åº¦ (`gradient`)ã€‚æ¢¯åº¦æŒ‡æ˜äº†å‚æ•°åº”è¯¥æœå“ªä¸ªæ–¹å‘è°ƒæ•´æ‰èƒ½ä½¿æŸå¤±å˜å°ã€‚\n",
    "\n",
    "- `4ã€æ›´æ–°å‚æ•° (Update Parameters)`ï¼šè¿™å°±æ˜¯ `torch.optim` å‘æŒ¥ä½œç”¨çš„åœ°æ–¹ã€‚ä¼˜åŒ–å™¨æ ¹æ®è®¡ç®—å‡ºçš„æ¢¯åº¦ï¼Œä½¿ç”¨ç‰¹å®šçš„ä¼˜åŒ–ç®—æ³•ï¼ˆå¦‚ `SGD`, `Adam`ï¼‰æ¥æ›´æ–°æ¨¡å‹çš„æ¯ä¸€ä¸ªå‚æ•°ï¼Œä»è€Œä½¿æŸå¤±å‡½æ•°çš„å€¼é€æ¸å‡å°ã€‚\n",
    "\n",
    "ç®€å•æ¥è¯´ï¼Œå¦‚æœè¯´æŸå¤±å‡½æ•°æ˜¯â€œåœ°å›¾â€ï¼Œæ¢¯åº¦æ˜¯â€œæ–¹å‘ç›˜â€ï¼Œé‚£ä¹ˆ ä¼˜åŒ–å™¨å°±æ˜¯â€œå¼•æ“â€ï¼Œå®ƒå†³å®šäº†æˆ‘ä»¬å¦‚ä½•é©±åŠ¨æ¨¡å‹å‚æ•°è¿™è¾†â€œè½¦â€ï¼Œä¸€æ­¥æ­¥é©¶å‘åœ°å›¾ä¸Šçš„æœ€ä½ç‚¹ï¼ˆæŸå¤±æœ€å°åŒ–ï¼‰ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "## torch.optim çš„æ ¸å¿ƒä½¿ç”¨ä¸‰æ­¥æ³•\n",
    "åœ¨ä»»ä½• PyTorch è®­ç»ƒå¾ªç¯ä¸­ï¼Œä½¿ç”¨ä¼˜åŒ–å™¨çš„æ­¥éª¤éƒ½éµå¾ªä¸€ä¸ªå›ºå®šçš„â€œä¸‰æ­¥æ³•â€æ¨¡å¼ã€‚\n",
    "\n",
    "### 1. åˆå§‹åŒ–ä¼˜åŒ–å™¨ (Initialize the Optimizer)\n",
    "åœ¨è®­ç»ƒå¼€å§‹ä¹‹å‰ï¼Œä½ éœ€è¦åˆ›å»ºä¸€ä¸ªä¼˜åŒ–å™¨å®ä¾‹ã€‚åˆ›å»ºæ—¶ï¼Œä½ éœ€è¦å‘Šè¯‰å®ƒä¸¤ä»¶äº‹ï¼š\n",
    "\n",
    "- 1 `è¦ä¼˜åŒ–çš„å‚æ•°æ˜¯å“ªäº›ï¼Ÿ` é€šå¸¸æ˜¯æ¨¡å‹çš„æ‰€æœ‰å‚æ•°ï¼Œé€šè¿‡ `model.parameters()` æ¥è·å–ã€‚\n",
    "\n",
    "- 2 `ä½¿ç”¨ä»€ä¹ˆè¶…å‚æ•°ï¼Ÿ` æœ€é‡è¦çš„è¶…å‚æ•°æ˜¯å­¦ä¹ ç‡ (learning rate, `lr`)ï¼Œå®ƒæ§åˆ¶äº†æ¯æ¬¡å‚æ•°æ›´æ–°çš„æ­¥é•¿ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a97db19-0b41-4e16-9d5d-c614b7c9dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "\n",
    "# å‡è®¾ model æ˜¯ä¸€ä¸ªå·²ç»å®šä¹‰å¥½çš„ nn.Module å®ä¾‹\n",
    "model = nn.Linear(10, 2) \n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ª SGD ä¼˜åŒ–å™¨\n",
    "# ç¬¬ä¸€ä¸ªå‚æ•°ï¼šå‘Šè¯‰ä¼˜åŒ–å™¨éœ€è¦æ›´æ–°çš„å‚æ•°\n",
    "# lrï¼šè®¾ç½®å­¦ä¹ ç‡\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c299f09-66d0-49fb-b143-f9be18db8858",
   "metadata": {},
   "source": [
    "### 2. æ¢¯åº¦æ¸…é›¶ (optimizer.zero_grad())\n",
    "åœ¨è®¡ç®—æ–°ä¸€è½®æ¢¯åº¦ä¹‹å‰ï¼Œå¿…é¡»æ‰‹åŠ¨å°†ä¸Šä¸€æ­¥çš„æ¢¯åº¦æ¸…é›¶ã€‚\n",
    "\n",
    "- `ä¸ºä»€ä¹ˆéœ€è¦æ¸…é›¶ï¼Ÿ` å› ä¸º PyTorch çš„è®¾è®¡æ˜¯ï¼Œæ¯æ¬¡è°ƒç”¨ `loss.backward()` æ—¶ï¼Œè®¡ç®—å‡ºçš„æ¢¯åº¦ä¼šç´¯åŠ åˆ°ä¹‹å‰çš„æ¢¯åº¦ä¸Šã€‚å¦‚æœä¸æ¸…é›¶ï¼Œæ¢¯åº¦ä¼šè¶Šç§¯è¶Šå¤§ï¼Œå¯¼è‡´é”™è¯¯çš„æ›´æ–°æ–¹å‘ã€‚\n",
    "\n",
    "- `è°ƒç”¨æ—¶æœº`ï¼šé€šå¸¸åœ¨æ¯ä¸ªè®­ç»ƒè¿­ä»£ï¼ˆ`batch`ï¼‰çš„å¼€å§‹ã€‚\n",
    "\n",
    "---\n",
    "\n",
    "### 3. æ›´æ–°å‚æ•° (optimizer.step())\n",
    "å½“æ¢¯åº¦è®¡ç®—å®Œæ¯•ï¼ˆå³è°ƒç”¨ `loss.backward()` ä¹‹åï¼‰ï¼Œè°ƒç”¨ `optimizer.step()`ã€‚\n",
    "\n",
    "- `ä½œç”¨`ï¼šä¼˜åŒ–å™¨ä¼šéå†æ‰€æœ‰å®ƒç®¡ç†çš„å‚æ•°ï¼Œå¹¶æ ¹æ®å­˜å‚¨åœ¨è¿™äº›å‚æ•°` .grad` å±æ€§ä¸­çš„æ¢¯åº¦ï¼Œä½¿ç”¨å…¶å†…éƒ¨å®šä¹‰çš„ä¼˜åŒ–ç®—æ³•æ¥æ›´æ–°å‚æ•°çš„å€¼ã€‚\n",
    "#### è¿™ä¸‰æ­¥åœ¨è®­ç»ƒå¾ªç¯ä¸­çš„ä½ç½®å¦‚ä¸‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca01eaa3-48e5-4af8-b84f-0995b4f97e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‡è®¾ train_loader æ˜¯æˆ‘ä»¬çš„æ•°æ®åŠ è½½å™¨\n",
    "for inputs, labels in train_loader:\n",
    "    # 1. æ¢¯åº¦æ¸…é›¶\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # 2. å‰å‘ä¼ æ’­\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # 3. è®¡ç®—æŸå¤±\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # 4. åå‘ä¼ æ’­ï¼Œè®¡ç®—æ¢¯åº¦\n",
    "    loss.backward()\n",
    "    \n",
    "    # 5. æ›´æ–°å‚æ•°\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881d75e6-e418-4d6f-82c7-963eafba4646",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "---\n",
    "## å¸¸è§ä¼˜åŒ–å™¨è¯¦è§£\n",
    "torch.optim æä¾›äº†å¤šç§ä¼˜åŒ–å™¨ï¼Œæˆ‘ä»¬ä»‹ç»æœ€å¸¸ç”¨ä¹Ÿæ˜¯æœ€é‡è¦çš„å‡ ä¸ªã€‚\n",
    "\n",
    "---\n",
    "### 1. optim.SGD (éšæœºæ¢¯åº¦ä¸‹é™)\n",
    "æœ€åŸºç¡€ã€æœ€ç»å…¸çš„ä¼˜åŒ–å™¨ã€‚\n",
    "\n",
    "- `æ ¸å¿ƒæ€æƒ³`ï¼šå‚æ•°æ²¿ç€æ¢¯åº¦çš„åæ–¹å‘å‰è¿›ä¸€æ­¥ã€‚æ­¥å­çš„å¤§å°ç”±å­¦ä¹ ç‡ `lr` æ§åˆ¶ã€‚\n",
    "\n",
    "å…¬å¼ç®€åŒ–ç‰ˆ: weight=weightâˆ’learning_rate\n",
    "timesgradient\n",
    "\n",
    "- å¸¸ç”¨å‚æ•°:\n",
    "\n",
    "  - **`params`**: æ¨¡å‹å‚æ•°ã€‚\n",
    "\n",
    "  - **`lr`**: å­¦ä¹ ç‡ã€‚\n",
    "\n",
    "  - **`momentum`**: åŠ¨é‡ã€‚å¼•å…¥åŠ¨é‡å¯ä»¥å¸®åŠ©åŠ é€Ÿæ¢¯åº¦ä¸‹é™ï¼Œå¹¶å†²å‡ºå±€éƒ¨æœ€ä¼˜ã€‚å®ƒæ¨¡æ‹Ÿäº†ç‰©ç†ä¸–ç•Œä¸­ç‰©ä½“çš„æƒ¯æ€§ï¼Œä½¿å¾—æ›´æ–°æ–¹å‘ä¸ä»…å–å†³äºå½“å‰æ¢¯åº¦ï¼Œä¹Ÿå—ä¹‹å‰æ›´æ–°æ–¹å‘çš„å½±å“ã€‚`é€šå¸¸è®¾ä¸º 0.9`ã€‚\n",
    "\n",
    "  - **`weight_decay`**: æƒé‡è¡°å‡ï¼ˆ`L2` æ­£åˆ™åŒ–ï¼‰ã€‚ç”¨äºé˜²æ­¢è¿‡æ‹Ÿåˆï¼Œé€šè¿‡ç»™æŸå¤±å‡½æ•°å¢åŠ ä¸€ä¸ªæƒ©ç½šé¡¹æ¥é™åˆ¶æ¨¡å‹æƒé‡çš„å¤§å°ã€‚\n",
    "\n",
    "---\n",
    "### 2. optim.Adam (Adaptive Moment Estimation)\n",
    "ç›®å‰æœ€æµè¡Œã€æœ€å¸¸ç”¨çš„ä¼˜åŒ–å™¨ä¹‹ä¸€ï¼Œé€šå¸¸ä½œä¸ºå„ç§ä»»åŠ¡çš„é»˜è®¤é¦–é€‰ã€‚\n",
    "\n",
    "- `æ ¸å¿ƒæ€æƒ³`ï¼šå®ƒæ˜¯ä¸€ç§è‡ªé€‚åº”å­¦ä¹ ç‡ç®—æ³•ã€‚å®ƒä¸æ»¡è¶³äºæ‰€æœ‰å‚æ•°å…±äº«åŒä¸€ä¸ªå­¦ä¹ ç‡ï¼Œè€Œæ˜¯ä¸ºæ¯ä¸ªå‚æ•°è®¡ç®—è‡ªé€‚åº”çš„å­¦ä¹ ç‡ã€‚\n",
    "\n",
    "- `ä¼˜ç‚¹`ï¼šç»“åˆäº† `Momentum` å’Œ `RMSprop` ä¸¤ç§ç®—æ³•çš„æ€æƒ³ï¼Œèƒ½å¤Ÿå¿«é€Ÿæ”¶æ•›ï¼Œå¹¶ä¸”å¯¹è¶…å‚æ•°çš„é€‰æ‹©ä¸å¦‚ `SGD` é‚£ä¹ˆæ•æ„Ÿã€‚\n",
    "\n",
    "- å¸¸ç”¨å‚æ•°:\n",
    "\n",
    "  - **`lr`**: åˆå§‹å­¦ä¹ ç‡ã€‚\n",
    "\n",
    "  - **`betas`**: ç”¨äºè®¡ç®—æ¢¯åº¦çš„ä¸€é˜¶å’ŒäºŒé˜¶çŸ©ä¼°è®¡çš„ç³»æ•°ï¼Œé€šå¸¸ä¿æŒé»˜è®¤å€¼ `(0.9, 0.999)`ã€‚\n",
    "\n",
    "  - **`eps`**: ä¸ºäº†å¢åŠ æ•°å€¼ç¨³å®šæ€§è€ŒåŠ åˆ°åˆ†æ¯çš„ä¸€ä¸ªå°é¡¹ï¼Œé€šå¸¸ä¿æŒé»˜è®¤å€¼ `1e-8`ã€‚\n",
    "\n",
    "  - **`weight_decay`**: æƒé‡è¡°å‡ã€‚\n",
    "\n",
    "---\n",
    "### 3. optim.AdamW\n",
    "`AdamW` æ˜¯å¯¹ `Adam` ä¸­æƒé‡è¡°å‡å®ç°æ–¹å¼çš„æ”¹è¿›ç‰ˆæœ¬ã€‚åœ¨ `Adam` ä¸­ï¼Œæƒé‡è¡°å‡ä¸æ¢¯åº¦æ›´æ–°è€¦åˆåœ¨ä¸€èµ·ï¼Œæ•ˆæœæœ‰æ—¶å¹¶ä¸ç†æƒ³ã€‚`AdamW` å°†å…¶è§£è€¦ï¼Œåœ¨è®¸å¤šä»»åŠ¡ä¸­ï¼ˆå°¤å…¶æ˜¯ `NLP` é¢†åŸŸçš„ `Transformer` æ¨¡å‹ï¼‰è¡¨ç°å¾—æ¯” `Adam` æ›´å¥½ï¼Œæ­£åœ¨æˆä¸ºæ–°çš„æ ‡å‡†ã€‚\n",
    "\n",
    "---\n",
    "### 4. optim.Adagrad (Adaptive Gradient Algorithm)\n",
    "Adagrad æ˜¯æœ€æ—©æœŸçš„è‡ªé€‚åº”å­¦ä¹ ç‡ç®—æ³•ä¹‹ä¸€ã€‚\n",
    "\n",
    "- åç§°è§£è¯» \\\n",
    "Adaptive Gradientï¼šè‡ªé€‚åº”æ¢¯åº¦ã€‚\n",
    "\n",
    "- æ ¸å¿ƒæ€æƒ³ \\\n",
    "`Adagrad` çš„æ ¸å¿ƒåœ¨äºï¼Œå®ƒä¼šè®°å½•ä¸‹åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæ¯ä¸ªå‚æ•°æ‰€æœ‰æ¢¯åº¦å€¼çš„å¹³æ–¹å’Œã€‚åœ¨æ›´æ–°å‚æ•°æ—¶ï¼Œå­¦ä¹ ç‡ä¼šé™¤ä»¥è¿™ä¸ªç´¯ç§¯å€¼çš„å¹³æ–¹æ ¹ã€‚\n",
    "\n",
    "- ç›´è§‚ç†è§£ï¼š\n",
    "\n",
    "  - å¦‚æœä¸€ä¸ªå‚æ•°çš„æ¢¯åº¦ä¸€ç›´å¾ˆå¤§ï¼ˆç»å¸¸è¢«æ›´æ–°ï¼‰ï¼Œé‚£ä¹ˆå®ƒçš„æ¢¯åº¦å¹³æ–¹å’Œå°±ä¼šå¾ˆå¤§ï¼Œå¯¼è‡´åˆ†æ¯å¾ˆå¤§ï¼Œä»è€Œä½¿å¾—å®ƒçš„æœ‰æ•ˆå­¦ä¹ ç‡å˜å°ã€‚\n",
    "\n",
    "  - å¦‚æœä¸€ä¸ªå‚æ•°çš„æ¢¯åº¦ä¸€ç›´å¾ˆå°æˆ–å¾ˆç¨€ç–ï¼ˆå¶å°”è¢«æ›´æ–°ï¼‰ï¼Œé‚£ä¹ˆå®ƒçš„æ¢¯åº¦å¹³æ–¹å’Œå°±ä¼šå¾ˆå°ï¼Œå¯¼è‡´åˆ†æ¯å¾ˆå°ï¼Œä»è€Œä½¿å¾—å®ƒçš„æœ‰æ•ˆå­¦ä¹ ç‡å˜å¤§ã€‚\n",
    "\n",
    "`ä¼˜ç‚¹`\n",
    "   - è‡ªé€‚åº”å­¦ä¹ ç‡ï¼šèƒ½å¤Ÿè‡ªåŠ¨ä¸ºä¸åŒå‚æ•°è°ƒæ•´å­¦ä¹ ç‡ï¼Œæ— éœ€æ‰‹åŠ¨è°ƒæ•´ã€‚\n",
    "\n",
    "   - ç‰¹åˆ«é€‚åˆç¨€ç–æ•°æ®ï¼šåœ¨å¤„ç†åƒè¯åµŒå…¥ (word embeddings) æˆ–æ¨èç³»ç»Ÿè¿™ç±»ç¨€ç–ç‰¹å¾æ—¶éå¸¸æœ‰æ•ˆã€‚å› ä¸ºç¨€ç–ç‰¹å¾å¯¹åº”çš„å‚æ•°ä¸å¸¸è¢«æ›´æ–°ï¼ŒAdagrad ä¼šç»™äºˆå®ƒä»¬è¾ƒé«˜çš„å­¦ä¹ ç‡ã€‚\n",
    "\n",
    "`è‡´å‘½å¼±ç‚¹` \n",
    "   - `Adagrad` çš„ä¸»è¦é—®é¢˜åœ¨äºå…¶åˆ†æ¯ä¸­çš„æ¢¯åº¦å¹³æ–¹å’Œæ˜¯å•è°ƒé€’å¢çš„ã€‚éšç€è®­ç»ƒçš„è¿›è¡Œï¼Œè¿™ä¸ªç´¯ç§¯å€¼ä¼šè¶Šæ¥è¶Šå¤§ï¼Œæ°¸ä¸å‡å°ã€‚\n",
    "\n",
    "   - `åæœ`ï¼šè®­ç»ƒåæœŸï¼Œå‡ ä¹æ‰€æœ‰å‚æ•°çš„æœ‰æ•ˆå­¦ä¹ ç‡éƒ½ä¼šå˜å¾—æ— é™æ¥è¿‘äº 0ï¼Œå¯¼è‡´æ¨¡å‹è¿‡æ—©åœ°åœæ­¢å­¦ä¹ ï¼Œæ— æ³•è¾¾åˆ°æœ€ä¼˜è§£ã€‚è¿™å°±åƒä¸€è¾†è½¦ï¼Œå¼€ç€å¼€ç€æ²¹é—¨å°±è‡ªåŠ¨è¸©åˆ°åº•ï¼Œå†ä¹ŸåŠ ä¸ä¸Šé€Ÿäº†ã€‚\n",
    "\n",
    "`é€‚ç”¨åœºæ™¯`\n",
    " - ä¸»è¦ç”¨äºå¤„ç†ç¨€ç–æ•°æ®ï¼Œå¦‚è‡ªç„¶è¯­è¨€å¤„ç†ä¸­çš„è¯åµŒå…¥ä»»åŠ¡ã€‚\n",
    "\n",
    " - åœ¨ç°ä»£çš„æ·±åº¦å­¦ä¹ ä»»åŠ¡ä¸­ï¼ˆå¦‚è®¡ç®—æœºè§†è§‰ï¼‰ï¼Œç”±äºå…¶å­¦ä¹ ç‡ä¼šè¿‡æ—©è¡°å‡çš„é—®é¢˜ï¼Œç°åœ¨å·²ç»è¾ƒå°‘ä½¿ç”¨ã€‚\n",
    "\n",
    "\n",
    "---\n",
    "### optim.RMSprop (Root Mean Square Propagation)\n",
    "ä¸ºäº†è§£å†³ `Adagrad` å­¦ä¹ ç‡æ€¥å‰§ä¸‹é™çš„é—®é¢˜ï¼ŒGeoff Hinton æå‡ºäº† `RMSprop` ç®—æ³•ã€‚å®ƒæ˜¯ `Adam` ä¼˜åŒ–å™¨çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚\n",
    "\n",
    "`åç§°è§£è¯»` \\\n",
    "Root Mean Square Propagationï¼šå‡æ–¹æ ¹ä¼ æ’­ã€‚\n",
    "\n",
    "`æ ¸å¿ƒæ€æƒ³` \\\n",
    "`RMSprop` å¯¹ `Adagrad` åšäº†ä¸€ä¸ªç®€å•è€Œå·§å¦™çš„ä¿®æ”¹ï¼šå®ƒä¸å†ç´¯åŠ æ‰€æœ‰çš„å†å²æ¢¯åº¦å¹³æ–¹ï¼Œè€Œæ˜¯è®¡ç®—ä¸€ä¸ªæ¢¯åº¦çš„å¹³æ–¹çš„æŒ‡æ•°ç§»åŠ¨å¹³å‡å€¼ (Exponentially Moving Average)ã€‚\n",
    "\n",
    "`ç›´è§‚ç†è§£`ï¼š\n",
    "\n",
    "   - æŒ‡æ•°ç§»åŠ¨å¹³å‡å€¼ä¼šç»™äºˆæœ€è¿‘çš„æ¢¯åº¦æ›´é«˜çš„æƒé‡ï¼Œè€Œé€æ¸â€œå¿˜è®°â€ä¹…è¿œçš„æ¢¯åº¦ã€‚\n",
    "\n",
    "   - è¿™ä½¿å¾—åˆ†æ¯ä¸ä¼šæ— é™åœ°ã€å•è°ƒåœ°å¢é•¿ã€‚å®ƒä¼šæ ¹æ®æœ€è¿‘çš„æ¢¯åº¦æƒ…å†µè¿›è¡ŒåŠ¨æ€è°ƒæ•´ã€‚å¦‚æœæœ€è¿‘æ¢¯åº¦å¤§ï¼Œåˆ†æ¯å°±å¤§ï¼Œå­¦ä¹ ç‡å°±å°ï¼›å¦‚æœæœ€è¿‘æ¢¯åº¦å°ï¼Œåˆ†æ¯å°±å°ï¼Œå­¦ä¹ ç‡å°±å¤§ã€‚\n",
    "\n",
    "è¿™æ ·ä¸€æ¥ï¼ŒRMSprop è§£å†³äº† Adagrad å­¦ä¹ ç‡è¿‡æ—©æ¶ˆå¤±çš„é—®é¢˜ï¼Œè®©è®­ç»ƒå¯ä»¥æŒç»­è¿›è¡Œã€‚\n",
    "\n",
    "`ä¼˜ç‚¹` \\\n",
    "   - è§£å†³äº† `Adagrad` çš„å¼Šç«¯ï¼šé€šè¿‡ä½¿ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼Œé¿å…äº†å­¦ä¹ ç‡è¿‡æ—©è¡°å‡ï¼Œä½¿å¾—ç®—æ³•åœ¨éå‡¸ä¼˜åŒ–é—®é¢˜ä¸Šè¡¨ç°æ›´å¥½ã€‚\n",
    "\n",
    "   - æ”¶æ•›é€Ÿåº¦å¿«ï¼šä½œä¸ºä¸€ç§è‡ªé€‚åº”å­¦ä¹ ç‡ç®—æ³•ï¼Œé€šå¸¸æ¯” `SGD` æ”¶æ•›æ›´å¿«ã€‚\n",
    "\n",
    "   - è¶…å‚æ•°è¾ƒå°‘ï¼šé€šå¸¸åªéœ€è¦è°ƒæ•´å­¦ä¹ ç‡ lr å’Œ alpha (å¹³æ»‘å¸¸æ•°)ã€‚\n",
    "\n",
    "`ç¼ºç‚¹`  \\\n",
    "   - ä»ç„¶éœ€è¦è®¾ç½®ä¸€ä¸ªå…¨å±€çš„å­¦ä¹ ç‡ lrã€‚\n",
    "\n",
    "   - åœ¨æŸäº›æƒ…å†µä¸‹ï¼ŒAdam æˆ– AdamW å¯èƒ½ä¼šæä¾›æ›´ç¨³å®šå’Œæ›´å¥½çš„æ€§èƒ½ã€‚\n",
    "\n",
    "`é€‚ç”¨åœºæ™¯`  \\\n",
    " - ä¸€ä¸ªéå¸¸é€šç”¨å’Œå¼ºå¤§çš„ä¼˜åŒ–å™¨ï¼Œå°¤å…¶åœ¨å¾ªç¯ç¥ç»ç½‘ç»œ (RNNs) ç›¸å…³çš„ä»»åŠ¡ä¸Šè¡¨ç°å‡ºè‰²ã€‚\n",
    "\n",
    " - å½“ä½ å‘ç° Adam åœ¨ä½ çš„ä»»åŠ¡ä¸Šæ•ˆæœä¸ä½³æ—¶ï¼ŒRMSprop æ˜¯ä¸€ä¸ªéå¸¸å€¼å¾—å°è¯•çš„æ›¿ä»£æ–¹æ¡ˆã€‚\n",
    "\n",
    "`è¿›åŒ–ä¹‹è·¯`ï¼šä½ å¯ä»¥è¿™æ ·ç†è§£ä¼˜åŒ–å™¨çš„å‘å±•ï¼š \\\n",
    "`SGD` -> `SGD with Momentum` -> `Adagrad` (å¼•å…¥è‡ªé€‚åº”æ€æƒ³) -> `RMSprop` (ä¿®å¤ Adagrad ç¼ºé™·) -> `Adam` (ç»“åˆ RMSprop å’Œ Momentum) -> `AdamW` (æ”¹è¿› Adam çš„æƒé‡è¡°å‡)ã€‚\n",
    "\n",
    "---\n",
    "## ä¼˜åŒ–å™¨å¯¹æ¯”è¡¨\n",
    "\n",
    "| ä¼˜åŒ–å™¨ (Optimizer) | æ ¸å¿ƒæ€æƒ³ (Core Idea) | å­¦ä¹ ç‡ç‰¹ç‚¹ (Learning Rate) | ä¼˜ç‚¹ (Pros) | ç¼ºç‚¹ (Cons) | é€‚ç”¨åœºæ™¯ (Best Use Cases) |\n",
    "|--------------------|----------------------|----------------------------|------------|------------|----------------------------|\n",
    "| SGD | æ²¿ç€æ¢¯åº¦åæ–¹å‘æ›´æ–°å‚æ•°ã€‚å¯åŠ å…¥åŠ¨é‡ï¼ˆMomentumï¼‰æ¥å¢åŠ æƒ¯æ€§ã€‚ | å…¨å±€å›ºå®šï¼šæ‰€æœ‰å‚æ•°å…±äº«åŒä¸€ä¸ªå­¦ä¹ ç‡ã€‚ | ç®€å•å¯é ï¼Œç»è¿‡å……åˆ†è°ƒä¼˜åå¯èƒ½æ‰¾åˆ°æ³›åŒ–èƒ½åŠ›æ›´å¥½çš„è§£ã€‚ | å¯¹å­¦ä¹ ç‡æ•æ„Ÿï¼Œæ”¶æ•›æ…¢ï¼Œå®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜æˆ–éç‚¹ã€‚ | ä½œä¸ºç ”ç©¶åŸºçº¿ï¼›å½“ä½ æœ‰è¶³å¤Ÿçš„æ—¶é—´å’Œè®¡ç®—èµ„æºè¿›è¡Œç²¾ç»†è°ƒå‚æ—¶ã€‚ |\n",
    "| Adagrad | ä¸ºæ¯ä¸ªå‚æ•°ç´¯åŠ æ‰€æœ‰å†å²æ¢¯åº¦çš„å¹³æ–¹ï¼Œå¹¶ç”¨å®ƒæ¥è°ƒæ•´å­¦ä¹ ç‡ã€‚ | è‡ªé€‚åº”ï¼šæ¯ä¸ªå‚æ•°æœ‰ç‹¬ç«‹å­¦ä¹ ç‡ã€‚æ¢¯åº¦å¤§çš„å‚æ•°ï¼Œå­¦ä¹ ç‡è¡°å‡å¿«ã€‚ | å¯¹ç¨€ç–æ•°æ®éå¸¸æœ‰æ•ˆï¼ˆå¦‚NLPè¯åµŒå…¥ï¼‰ã€‚ | å­¦ä¹ ç‡å•è°ƒé€’å‡ï¼Œè®­ç»ƒåæœŸä¼šå˜å¾—æå°ï¼Œå¯¼è‡´è¿‡æ—©åœæ­¢å­¦ä¹ ã€‚ | ä¸»è¦ç”¨äºç¨€ç–æ•°æ®ä»»åŠ¡ï¼Œåœ¨æ·±åº¦å­¦ä¹ ä¸­å·²è¾ƒå°‘ä½¿ç”¨ã€‚ |\n",
    "| RMSprop | ä½¿ç”¨æ¢¯åº¦å¹³æ–¹çš„æŒ‡æ•°ç§»åŠ¨å¹³å‡æ¥è°ƒæ•´å­¦ä¹ ç‡ã€‚ | è‡ªé€‚åº”ï¼šæ¯ä¸ªå‚æ•°æœ‰ç‹¬ç«‹å­¦ä¹ ç‡ï¼Œä½†è§£å†³äº†å­¦ä¹ ç‡æ¶ˆå¤±é—®é¢˜ã€‚ | è§£å†³äº† Adagrad çš„å¼Šç«¯ï¼Œæ”¶æ•›é€Ÿåº¦å¿«ã€‚ | ä»ç„¶éœ€è¦æ‰‹åŠ¨è®¾ç½®å­¦ä¹ ç‡ã€‚ | åœ¨å¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰ä¸Šè¡¨ç°å‡ºè‰²ï¼›å¯ä½œä¸º Adam çš„æ›¿ä»£æ–¹æ¡ˆã€‚ |\n",
    "| `Adam` | ç»“åˆäº† Momentum å’Œ RMSpropã€‚åŒæ—¶ä½¿ç”¨æ¢¯åº¦çš„ä¸€é˜¶çŸ©ï¼ˆåŠ¨é‡ï¼‰å’ŒäºŒé˜¶çŸ©ï¼ˆè‡ªé€‚åº”å­¦ä¹ ç‡ï¼‰ã€‚ | è‡ªé€‚åº”ï¼šæ¯ä¸ªå‚æ•°æœ‰ç‹¬ç«‹å­¦ä¹ ç‡ï¼Œä¸”æ›´æ–°å¸¦æœ‰æƒ¯æ€§ã€‚ | æ”¶æ•›é€Ÿåº¦æå¿«ï¼Œå¯¹è¶…å‚æ•°ä¸æ•æ„Ÿï¼Œ`å‡ ä¹é€‚ç”¨äºæ‰€æœ‰ä»»åŠ¡`ã€‚ | æƒé‡è¡°å‡çš„å®ç°æ–¹å¼å­˜åœ¨é—®é¢˜ï¼›å¯èƒ½æ”¶æ•›åˆ°æ³›åŒ–èƒ½åŠ›è¾ƒå·®çš„â€œé”åˆ©â€æœ€å°å€¼ã€‚ | æ›¾ç»çš„é»˜è®¤é¦–é€‰ã€‚é€‚åˆå¿«é€ŸåŸå‹è®¾è®¡å’Œå¤§å¤šæ•°æ·±åº¦å­¦ä¹ ä»»åŠ¡ã€‚ |\n",
    "| `AdamW` | ä¿®å¤äº† Adam çš„æƒé‡è¡°å‡é—®é¢˜ï¼Œå°†å…¶ä¸æ¢¯åº¦æ›´æ–°è§£è€¦ã€‚ | è‡ªé€‚åº”ï¼šä¸ Adam ç›¸åŒï¼Œä½†æ­£åˆ™åŒ–æ•ˆæœæ›´å¥½ã€‚ | æ‹¥æœ‰ Adam çš„æ‰€æœ‰ä¼˜ç‚¹ï¼ŒåŒæ—¶é€šè¿‡ä¿®æ­£æƒé‡è¡°å‡ï¼Œé€šå¸¸èƒ½è·å¾—æ›´å¥½çš„æ³›åŒ–æ€§èƒ½å’Œæ›´ä½çš„è®­ç»ƒæŸå¤±ã€‚ | `å‡ ä¹æ²¡æœ‰æ˜æ˜¾ç¼ºç‚¹`ã€‚ | å½“å‰æ¨èçš„`é»˜è®¤é¦–é€‰`ã€‚å°¤å…¶åœ¨ Transformerã€BERT ç­‰å¤§å‹æ¨¡å‹ä¸Šè¡¨ç°ä¼˜å¼‚ã€‚ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d7be0d-d2da-4866-8ce1-db410add3709",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2e68ce-73c9-44a2-8449-2856bbcedd42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bf9087-b5b6-4501-b5a1-e711b0c50c17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "243cb312-972b-4474-bbca-a5ed943fc861",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# 3.2ã€å­¦ä¹ ç‡è°ƒæ•´ç­–ç•¥ (torch.optim.lr_scheduler)\n",
    "torch.optim.lr_schedulerã€‚\n",
    "\n",
    "- `æ ¸å¿ƒæ¦‚å¿µ`ï¼šä¸ºä»€ä¹ˆéœ€è¦å­¦ä¹ ç‡è°ƒæ•´ç­–ç•¥ï¼Ÿ \\\n",
    "åœ¨ä¹‹å‰çš„ `torch.optim` è®²è§£ä¸­ï¼Œæˆ‘ä»¬ä¸ºä¼˜åŒ–å™¨è®¾ç½®äº†ä¸€ä¸ªå›ºå®šçš„å­¦ä¹ ç‡ï¼ˆlearning rate, `lr`ï¼‰ã€‚ç„¶è€Œï¼Œåœ¨æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ä¸­ä½¿ç”¨ä¸€ä¸ªå›ºå®šçš„å­¦ä¹ ç‡å¹¶éæœ€ä¼˜é€‰æ‹©ã€‚\n",
    "\n",
    "- ä¸€ä¸ªç†æƒ³çš„å­¦ä¹ ç‡ç­–ç•¥åº”è¯¥æ˜¯è¿™æ ·ï¼š\n",
    "\n",
    "  - è®­ç»ƒåˆæœŸ: æ¨¡å‹å‚æ•°æ˜¯éšæœºåˆå§‹åŒ–çš„ï¼Œç¦»æœ€ä¼˜è§£å¾ˆè¿œã€‚æ­¤æ—¶ï¼Œæˆ‘ä»¬å¸Œæœ›ä½¿ç”¨ä¸€ä¸ªè¾ƒå¤§çš„å­¦ä¹ ç‡ï¼Œè®©æ¨¡å‹èƒ½å¤Ÿå¿«é€Ÿåœ°å‘æœ€ä¼˜è§£çš„æ–¹å‘æ”¶æ•›ï¼Œå°±åƒä¸‹å±±åˆæœŸå¤§æ­¥æµæ˜Ÿã€‚\n",
    "\n",
    "  - è®­ç»ƒä¸­æœŸ: å½“æ¨¡å‹æ¥è¿‘æœ€ä¼˜è§£æ—¶ï¼Œä¸€ä¸ªå¤§çš„å­¦ä¹ ç‡å¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹åœ¨æœ€ä¼˜è§£é™„è¿‘â€œæ¥å›éœ‡è¡â€ï¼Œæ— æ³•ç²¾ç¡®æ”¶æ•›ã€‚\n",
    "\n",
    "  - è®­ç»ƒåæœŸ: æˆ‘ä»¬éœ€è¦ä¸€ä¸ªè¾ƒå°çš„å­¦ä¹ ç‡ï¼Œè®©æ¨¡å‹èƒ½å¤Ÿâ€œå°å¿ƒç¿¼ç¿¼â€åœ°åœ¨æœ€ä¼˜è§£çš„â€œå±±è°·â€ä¸­è¿›è¡Œå¾®è°ƒï¼Œä»è€Œæ‰¾åˆ°é‚£ä¸ªæœ€ä½ç‚¹ã€‚\n",
    "\n",
    "`torch.optim.lr_scheduler` å°±æ˜¯ä¸ºäº†å®ç°è¿™ç§åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡çš„éœ€æ±‚è€Œè®¾è®¡çš„ã€‚å®ƒæä¾›äº†å¤šç§é¢„è®¾çš„ç­–ç•¥ï¼Œå¯ä»¥æ ¹æ®è®­ç»ƒçš„è¿›åº¦ï¼ˆå¦‚ epoch æ•°ï¼‰æˆ–å…¶ä»–æŒ‡æ ‡ï¼ˆå¦‚éªŒè¯é›†æŸå¤±ï¼‰æ¥è‡ªåŠ¨è°ƒæ•´ä¼˜åŒ–å™¨ä¸­çš„å­¦ä¹ ç‡ã€‚\n",
    "\n",
    "---\n",
    "### ä½¿ç”¨æ–¹æ³•:\n",
    "\n",
    "ä½¿ç”¨ä»»ä½• lr_scheduler éƒ½éµå¾ªä¸€ä¸ªç®€å•çš„ä¸‰æ­¥æµç¨‹ï¼š\n",
    "\n",
    "- 1 ã€`åˆ›å»ºä¼˜åŒ–å™¨ (Optimizer)`ï¼šé¦–å…ˆï¼Œåƒå¾€å¸¸ä¸€æ ·åˆ›å»ºä¸€ä¸ªä¼˜åŒ–å™¨ã€‚\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "- 2 ã€`åˆ›å»ºè°ƒåº¦å™¨ (Scheduler)`ï¼šç„¶åï¼Œç”¨åˆ›å»ºå¥½çš„ä¼˜åŒ–å™¨æ¥å®ä¾‹åŒ–ä¸€ä¸ªè°ƒåº¦å™¨ã€‚\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR  \n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "- 3 ã€`åœ¨è®­ç»ƒå¾ªç¯ä¸­æ›´æ–°è°ƒåº¦å™¨ (scheduler.step())`: åœ¨è®­ç»ƒå¾ªç¯çš„é€‚å½“ä½ç½®è°ƒç”¨ `scheduler.step()` æ¥æ›´æ–°å­¦ä¹ ç‡ã€‚\n",
    "\n",
    "- `step()` çš„è°ƒç”¨æ—¶æœºæ˜¯å…³é”®ï¼š\n",
    "\n",
    "  - å¤§å¤šæ•°è°ƒåº¦å™¨: éƒ½æ˜¯åŸºäº epoch è¿›è¡Œæ›´æ–°çš„ï¼Œæ‰€ä»¥ `scheduler.step()` åº”è¯¥åœ¨æ¯ä¸ª `epoch` çš„è®­ç»ƒå¾ªç¯ä¹‹åè°ƒç”¨ã€‚\n",
    "\n",
    "  - å°‘æ•°è°ƒåº¦å™¨: å¦‚ `CosineAnnealingLR`, `OneCycleLR` ç­‰ï¼Œå¯ä»¥åŸºäº `batch`/`iteration` è¿›è¡Œæ›´æ–°ï¼Œæ­¤æ—¶ `scheduler.step()` åº”è¯¥åœ¨æ¯ä¸ª `batch` çš„è®­ç»ƒæ­¥éª¤ä¹‹åè°ƒç”¨ã€‚\n",
    "\n",
    "  - ç‰¹æ®Šè°ƒåº¦å™¨: `ReduceLROnPlateau` æ˜¯åŸºäºéªŒè¯æŒ‡æ ‡æ›´æ–°çš„ï¼Œæ‰€ä»¥å®ƒçš„ `step()` éœ€è¦ä¼ å…¥è¯¥æŒ‡æ ‡çš„å€¼ï¼Œä¾‹å¦‚ scheduler.step(validation_loss)ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac752d-8917-47ca-8ac5-6c032ca898ff",
   "metadata": {},
   "source": [
    "---\n",
    "### å¸¸ç”¨ Scheduler:\n",
    "ä¸‹é¢æˆ‘ä»¬ä»‹ç»å‡ ç§æœ€å¸¸ç”¨ã€æœ€æœ‰ä»£è¡¨æ€§çš„è°ƒåº¦å™¨ã€‚\n",
    "\n",
    "## 1. StepLR (é˜¶æ¢¯å¼ä¸‹é™)\n",
    "- ä¸€å¥è¯è§£é‡Š: æ¯éš” `step_size` ä¸ª epochï¼Œå°±å°†å½“å‰å­¦ä¹ ç‡ä¹˜ä»¥ä¸€ä¸ª `gamma` å› å­ã€‚\n",
    "\n",
    "- `æ ¸å¿ƒå‚æ•°`:\n",
    "\n",
    "   - `optimizer`: å…³è”çš„ä¼˜åŒ–å™¨ã€‚\n",
    "\n",
    "   - `step_size (int)`: æ›´æ–°å­¦ä¹ ç‡çš„é—´éš” `epoch` æ•°ã€‚\n",
    "\n",
    "   - `gamma (float)`: å­¦ä¹ ç‡è¡°å‡çš„ä¹˜æ³•å› å­ï¼ˆä¾‹å¦‚ï¼Œ0.1 ä»£è¡¨è¡°å‡ä¸ºåŸæ¥çš„1/10ï¼‰ã€‚\n",
    "\n",
    "- å­¦ä¹ ç‡æ›²çº¿: å‘ˆé˜¶æ¢¯çŠ¶ä¸‹é™ã€‚\n",
    "\n",
    "- é€‚ç”¨åœºæ™¯: ç®€å•æœ‰æ•ˆï¼Œé€‚åˆä½œä¸ºå…¥é—¨å’ŒåŸºçº¿ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2708368e-2b51-4297-85d2-018b4776ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¯ 10 ä¸ª epochï¼Œå­¦ä¹ ç‡å˜ä¸ºåŸæ¥çš„ 0.5 å€\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65de94f-8c36-4399-be8d-35a39b0de571",
   "metadata": {},
   "source": [
    "## 2. MultiStepLR (å¤šé˜¶æ¢¯å¼ä¸‹é™)\n",
    "- ä¸€å¥è¯è§£é‡Š: åœ¨é¢„å…ˆè®¾å®šå¥½çš„ä¸€ç³»åˆ— `milestones` (é‡Œç¨‹ç¢‘) `epoch` å¤„ï¼Œå°†å­¦ä¹ ç‡ä¹˜ä»¥ `gamma`ã€‚\n",
    "\n",
    "- `æ ¸å¿ƒå‚æ•°`:\n",
    "\n",
    "    - `milestones (list of ints)`: ä¸€ä¸ªåŒ…å« epoch ç´¢å¼•çš„åˆ—è¡¨ï¼Œåœ¨è¿™äº› epoch å¤„è¿›è¡Œå­¦ä¹ ç‡è¡°å‡ã€‚\n",
    "\n",
    "    - `gamma (float)`: è¡°å‡å› å­ã€‚\n",
    "\n",
    "- å­¦ä¹ ç‡æ›²çº¿: ä¸è§„åˆ™çš„é˜¶æ¢¯çŠ¶ï¼Œæ›´å…·çµæ´»æ€§ã€‚\n",
    "\n",
    "- é€‚ç”¨åœºæ™¯: è®¸å¤šç»å…¸è®ºæ–‡ï¼ˆå¦‚ ResNetï¼‰ä¸­ä½¿ç”¨çš„æ ‡å‡†ç­–ç•¥ï¼Œå½“ä½ å¯¹è®­ç»ƒè¿‡ç¨‹æœ‰æ¯”è¾ƒæ˜ç¡®çš„é¢„æœŸæ—¶ï¼ˆä¾‹å¦‚ï¼Œä½ çŸ¥é“æ¨¡å‹å¤§æ¦‚åœ¨ç¬¬60å’Œç¬¬90ä¸ªepochä¼šé‡åˆ°ç“¶é¢ˆï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cd4cbb-1d5d-4cb2-8072-c0d85cf609bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ¨ç¬¬ 60, 90, 120 ä¸ª epoch æ—¶ï¼Œå­¦ä¹ ç‡åˆ†åˆ«è¡°å‡ä¸ºåŸæ¥çš„ 0.1 å€\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 90, 120], gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6cb454-4a59-4f22-a4b3-e89013e6f065",
   "metadata": {},
   "source": [
    "## 3. CosineAnnealingLR (ä½™å¼¦é€€ç«)\n",
    "- ä¸€å¥è¯è§£é‡Š: å­¦ä¹ ç‡åœ¨ä¸€ä¸ªå‘¨æœŸï¼ˆ`T_max` ä¸ª epochï¼‰å†…ï¼ŒæŒ‰ç…§ä½™å¼¦å‡½æ•°çš„å½¢å¼ä»åˆå§‹å€¼å¹³æ»‘åœ°ä¸‹é™åˆ°æœ€å°å€¼ `eta_min`ã€‚\n",
    "\n",
    "- `æ ¸å¿ƒå‚æ•°`:\n",
    "\n",
    "    - `T_max (int)`: ä¸€ä¸ªå­¦ä¹ ç‡å‘¨æœŸçš„é•¿åº¦ï¼ˆä»¥ `epoch`(å‘¨æœŸ) æˆ– `iteration`(è¿­ä»£æ¬¡æ•°) ä¸ºå•ä½ï¼‰ã€‚\n",
    "\n",
    "    - `eta_min (float)`: å­¦ä¹ ç‡çš„ä¸‹é™ï¼Œé»˜è®¤ä¸º 0ã€‚\n",
    "\n",
    "- å­¦ä¹ ç‡æ›²çº¿: å¹³æ»‘çš„ä½™å¼¦åŠå‘¨æœŸæ›²çº¿ã€‚\n",
    "\n",
    "`ç‰¹ç‚¹`: è¿™æ˜¯ä¸€ç§éå¸¸æµè¡Œä¸”é«˜æ•ˆçš„ç­–ç•¥ã€‚å®ƒåœ¨å‰æœŸä¿æŒè¾ƒé«˜çš„å­¦ä¹ ç‡ï¼Œç„¶åç¼“æ…¢ä¸‹é™ï¼Œåœ¨å‘¨æœŸæœ«æœŸå­¦ä¹ ç‡å˜å¾—éå¸¸å°ï¼Œæœ‰åŠ©äºæ¨¡å‹æ‰¾åˆ°æ›´ä¼˜çš„è§£ã€‚è¿˜å¯ä»¥é…åˆ`â€œçƒ­é‡å¯â€`ï¼ˆWarm Restartsï¼‰ä½¿ç”¨ï¼Œè®©æ¨¡å‹æœ‰æœºä¼šè·³å‡ºå±€éƒ¨æœ€ä¼˜ã€‚\n",
    "\n",
    "`é€‚ç”¨åœºæ™¯`: å½“å‰å„ç§æ·±åº¦å­¦ä¹ ä»»åŠ¡ä¸­çš„ `SOTA` (State-of-the-art) é€‰æ‹©ï¼Œå°¤å…¶åœ¨å¤§å‹æ¨¡å‹è®­ç»ƒä¸­è¡¨ç°ä¼˜å¼‚ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1873760-cadd-4473-91b4-3217450d04e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ¨ 100 ä¸ª epoch å†…ï¼Œå­¦ä¹ ç‡ä»åˆå§‹å€¼é€€ç«åˆ° 0\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5826da5-06e2-4e43-8618-5cf6a828fee0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## 4. ReduceLROnPlateau (åœ¨å¹³å°æœŸé™ä½å­¦ä¹ ç‡)\n",
    "- ä¸€å¥è¯è§£é‡Š: ç›‘æ§ä¸€ä¸ªæŒ‡å®šçš„æŒ‡æ ‡ï¼ˆå¦‚éªŒè¯é›†æŸå¤±ï¼‰ï¼Œå¦‚æœè¯¥æŒ‡æ ‡åœ¨ `patience` ä¸ª `epoch`abs å†…æ²¡æœ‰æ”¹å–„ï¼Œå°±é™ä½å­¦ä¹ ç‡ã€‚\n",
    "\n",
    "- `æ ¸å¿ƒå‚æ•°`:\n",
    "\n",
    "    - `mode (str)`: '`mi`' æˆ– '`max`'ã€‚ç›‘æ§æŒ‡æ ‡æ˜¯è¶Šå°è¶Šå¥½ ('min'ï¼Œå¦‚æŸå¤±) è¿˜æ˜¯è¶Šå¤§è¶Šå¥½ ('max'ï¼Œå¦‚å‡†ç¡®ç‡)ã€‚\n",
    "\n",
    "    - `factor (float)`: å­¦ä¹ ç‡è¡°å‡å› å­ (`new_lr` = `lr` * `factor`)ã€‚\n",
    "\n",
    "    - `patience (int)`: å®¹å¿å¤šå°‘ä¸ª `epoch` æŒ‡æ ‡æ²¡æœ‰æ”¹å–„ã€‚\n",
    "\n",
    "    - `verbose (bool)`: å¦‚æœä¸º `True`ï¼Œæ¯æ¬¡æ›´æ–°æ—¶ä¼šæ‰“å°ä¸€æ¡ä¿¡æ¯ã€‚\n",
    "\n",
    "`ç‰¹ç‚¹`: è¿™æ˜¯ä¸€ç§`â€œå“åº”å¼â€`ç­–ç•¥ï¼Œè€Œä¸æ˜¯é¢„è®¾çš„ã€‚å®ƒæ ¹æ®æ¨¡å‹çš„å®é™…è¡¨ç°æ¥è°ƒæ•´å­¦ä¹ ç‡ï¼Œéå¸¸æ™ºèƒ½ã€‚\n",
    "\n",
    "- `step()` è°ƒç”¨æ–¹å¼: ç‰¹åˆ«æ³¨æ„ï¼Œå®ƒéœ€è¦åœ¨éªŒè¯é˜¶æ®µåè°ƒç”¨ï¼Œå¹¶ä¼ å…¥ç›‘æ§çš„æŒ‡æ ‡å€¼ï¼š`scheduler.step(validation_loss)`ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a30f079-c1bc-4445-ba56-e12fbee738e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç›‘æ§éªŒè¯é›†æŸå¤±ï¼Œå¦‚æœè¿ç»­ 5 ä¸ª epoch æŸå¤±æ²¡æœ‰ä¸‹é™ï¼Œåˆ™å­¦ä¹ ç‡å˜ä¸ºåŸæ¥çš„ 0.2 å€\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.2, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428f74ac-97bd-4575-804e-7468e2098dce",
   "metadata": {},
   "source": [
    "## å®Œæ•´ä»£ç æ¼”ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00070e0-62a7-4831-9cc3-36c51502d097",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "\n",
    "# 1. è™šæ‹Ÿçš„æ¨¡å‹ã€æ•°æ®å’Œä¼˜åŒ–å™¨\n",
    "model = nn.Linear(10, 2)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# 2. åˆ›å»ºè°ƒåº¦å™¨ (é€‰æ‹©ä¸€ä¸ª)\n",
    "# scheduler = StepLR(optimizer, step_size=10, gamma=0.1) # æ–¹æ¡ˆä¸€ï¼šé˜¶æ¢¯ä¸‹é™\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=50, eta_min=0.001) # æ–¹æ¡ˆäºŒï¼šä½™å¼¦é€€ç«\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "print(\"å¼€å§‹è®­ç»ƒ...\")\n",
    "for epoch in range(num_epochs):\n",
    "    # ----- æ¨¡æ‹Ÿè®­ç»ƒå¾ªç¯ -----\n",
    "    for i in range(10): # å‡è®¾æœ‰ 10 ä¸ª batch\n",
    "        # ... your training steps ...\n",
    "        # optimizer.zero_grad()\n",
    "        # loss.backward()\n",
    "        # optimizer.step()\n",
    "        pass # æ­¤å¤„çœç•¥è®­ç»ƒç»†èŠ‚\n",
    "    # -----------------------\n",
    "    \n",
    "    # åœ¨æ¯ä¸ª epoch ç»“æŸåï¼Œæ›´æ–°å­¦ä¹ ç‡\n",
    "    scheduler.step()\n",
    "    \n",
    "    # æ‰“å°å½“å‰å­¦ä¹ ç‡ä»¥è§‚å¯Ÿå˜åŒ–\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, å½“å‰å­¦ä¹ ç‡: {current_lr:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8845a87-916c-4b48-a1e4-0cce43f91714",
   "metadata": {},
   "source": [
    "### å¦‚ä½•é€‰æ‹©ï¼Ÿ\n",
    "- `ç®€å•åŸºçº¿`: `StepLR` æˆ– `MultiStepLR` æ˜¯éå¸¸å¥½çš„èµ·ç‚¹ï¼Œç¨³å®šå¯é ã€‚\n",
    "\n",
    "- `è¿½æ±‚æ›´é«˜æ€§èƒ½`: `CosineAnnealingLR` æ˜¯ç›®å‰å†²å‡» `SOTA` æ€§èƒ½çš„é¦–é€‰ç­–ç•¥ä¹‹ä¸€ã€‚\n",
    "\n",
    "- `éœ€è¦è‡ªé€‚åº”è°ƒæ•´`: å½“ä½ ä¸ç¡®å®šè®­ç»ƒå¤šå°‘ä¸ª epoch ä¼šé‡åˆ°ç“¶é¢ˆæ—¶ï¼Œ`ReduceLROnPlateau` æ˜¯ä¸€ä¸ªéå¸¸æ™ºèƒ½å’Œæ–¹ä¾¿çš„é€‰æ‹©ï¼Œå®ƒè®©æ¨¡å‹è‡ªå·±å†³å®šä½•æ—¶é™ä½å­¦ä¹ ç‡ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e828db-a749-4d28-a0fe-4d3a76267b56",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb0462d-f4e7-4908-a308-a770185fc70f",
   "metadata": {},
   "source": [
    "## æ€»ç»“\n",
    "- `torch.optim` æ˜¯ PyTorch çš„ä¼˜åŒ–æ ¸å¿ƒï¼Œè´Ÿè´£æ ¹æ®æ¢¯åº¦æ›´æ–°æ¨¡å‹å‚æ•°ã€‚\n",
    "\n",
    "- æŒæ¡ `optimizer.zero_grad()` -> `loss.backward()` -> `optimizer.step()` çš„`â€œä¸‰æ­¥æ›²â€`æ˜¯ç¼–å†™ä»»ä½• PyTorch è®­ç»ƒä»£ç çš„åŸºç¡€ã€‚\n",
    "\n",
    "- `SGD` æ˜¯åŸºç¡€ï¼Œ`Adam` å’Œ `AdamW` æ˜¯å½“å‰æœ€å¸¸ç”¨ã€æ•ˆæœæœ€å¥½çš„ä¼˜åŒ–å™¨ä¹‹ä¸€ã€‚\n",
    "\n",
    "é…åˆä½¿ç”¨ `torch.optim.lr_scheduler` åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡æ˜¯æå‡æ¨¡å‹æœ€ç»ˆæ€§èƒ½çš„æ ‡å‡†å®è·µã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e83d40-36b1-43f8-a6b5-2d3acebdd71c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepseek_env]",
   "language": "python",
   "name": "conda-env-deepseek_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
