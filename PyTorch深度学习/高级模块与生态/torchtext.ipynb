{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92db7cf7-cac8-4f44-90e4-26e655611e55",
   "metadata": {},
   "source": [
    "# torchtext \n",
    "——这是` PyTorch `官方的 `自然语言处理`（NLP）工具包，和` torchvision `在计算机视觉领域的地位类似。\n",
    "\n",
    "## 1. torchtext 的作用\n",
    "\n",
    "`PyTorch `自身是一个 `深度学习框架`，不包含太多 NLP 任务专用工具。\n",
    "`torchtext `提供了常见的 文本处理功能，方便我们快速搭建 NLP 模型，主要包括：\n",
    "\n",
    "- 1.数据处理:\n",
    "\n",
    "    - 处理原始文本数据（分词、转小写、去除标点）\n",
    "    \n",
    "    - 将文本转为数字索引（token → id）\n",
    "    \n",
    "    - 构建 Vocab（词表）\n",
    "    \n",
    "    - 批处理 & 填充（padding、masking）\n",
    "\n",
    "- 2.数据集:\n",
    "\n",
    "    - 提供常用 NLP 数据集（IMDB、AG_NEWS、SST2、WikiText2 等）\n",
    "    \n",
    "    - 内置下载 & 预处理\n",
    "\n",
    "- 3.词向量\n",
    "\n",
    "    - 提供预训练的词向量（GloVe、FastText、CharNGram）\n",
    "    \n",
    "    - 可以直接加载并用于模型初始化\n",
    "\n",
    "- 4.与 PyTorch 无缝衔接\n",
    "\n",
    "    - 提供 `Dataset`、`DataLoader`、`Iterator`\n",
    "    \n",
    "    - 和 `torch.nn`、`torchtext.vocab`、`torchtext.transforms` 等模块配合使用\n",
    "\n",
    "---\n",
    "## 2. 主要模块结构\n",
    "\n",
    "`torchtext` 主要分为以下几个部分：\n",
    "\n",
    "### （1）torchtext.data（旧 API，`已逐渐被弃用`）\n",
    "\n",
    "- Field：定义如何处理数据（分词、数值化、padding 等）\n",
    "\n",
    "- Dataset：保存文本数据\n",
    "\n",
    "- Iterator：按 batch 迭代\n",
    "\n",
    "⚠️ 注意：新版本推荐用 `torchtext.datasets` 和 `torchtext.transforms`，但一些教程还在用旧 API。\n",
    "\n",
    "---\n",
    "### （2）`torchtext.datasets`\n",
    "\n",
    "提供开箱即用的 NLP 数据集，自动下载和处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e8a9c7-c9b3-4567-bdf6-d17d331d1ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import AG_NEWS\n",
    "\n",
    "train_iter = AG_NEWS(split='train')\n",
    "test_iter = AG_NEWS(split='test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd3dbb1-871d-485f-8376-b70bd64669b8",
   "metadata": {},
   "source": [
    "`train_iter` 就是一个迭代器，里面包含 `(label, text)`。\n",
    "\n",
    "---\n",
    "### （3）torchtext.vocab\n",
    "\n",
    "提供词表管理 & 预训练词向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084b51fd-bb32-40f5-b6d8-113decc504ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe\n",
    "\n",
    "glove = GloVe(name=\"6B\", dim=100)  # 加载 GloVe 100维词向量\n",
    "print(glove[\"computer\"])           # 直接取向量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60394d28-f04a-47c3-ab35-630e084b8bf4",
   "metadata": {},
   "source": [
    "也可以用` build_vocab_from_iterator() `来自己构建词表。\n",
    "\n",
    "---\n",
    "### （4）torchtext.transforms\n",
    "\n",
    "- 提供现代化的数据处理流水线（tokenize → numericalize → pad）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30db5bc-5e07-4544-9ea2-e3126ed2ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.transforms import BasicEnglishNormalize, VocabTransform, ToTensor\n",
    "\n",
    "# 基础预处理\n",
    "text_transform = BasicEnglishNormalize()\n",
    "tokens = text_transform(\"Hello, World!\")\n",
    "print(tokens)  # ['hello', 'world']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f511def5-e32d-40ae-92bf-7f7e533c3437",
   "metadata": {},
   "source": [
    "## BasicEnglishNormalize \n",
    "是一个非常实用的 `文本预处理工具`，主要用于 `英文文本的标准化处理`，让输入的文本更干净、统一，便于后续分词和建模。\n",
    "\n",
    "### 作用\n",
    "\n",
    "`BasicEnglishNormalize` 会对输入的字符串做以下操作：\n",
    "\n",
    "- 1.全部转小写\n",
    "\n",
    "\"Hello WORLD!\" → \"hello world !\"\n",
    "\n",
    "- 2.去掉不必要的符号\n",
    "\n",
    "把 \"、's、n't 等处理为标准化形式\n",
    "\n",
    "- 3.处理标点符号\n",
    "\n",
    "把标点和单词分开，例如：\n",
    "\"hello,world!\" → \"hello , world !\"\n",
    "\n",
    "- 4.标准化常见缩写\n",
    "\n",
    "\"I'm\" → \"i 'm\"\n",
    "\n",
    "\"don't\" → \"do n't\"\n",
    "\n",
    "⚠️ 注意：它 `不会分词`，只是把文本转换成 `标准化后`的` token `列表。\n",
    "\n",
    "---\n",
    "### 和 get_tokenizer(\"basic_english\") 的关系\n",
    "\n",
    "`BasicEnglishNormalize()` 是一个 `标准化器`，返回 `词元列表`\n",
    "\n",
    "`get_tokenizer(\"basic_english\")` 内部其实就是调用了` BasicEnglishNormalize`，效果差不多，但写法更简洁\n",
    "\n",
    "示例对比："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47bc1d-9b67-4e3f-892f-925e3ecbc057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.transforms import BasicEnglishNormalize\n",
    "\n",
    "normalizer = BasicEnglishNormalize()\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "text = \"I'm using TorchText, It's great!\"\n",
    "\n",
    "print(\"normalizer:\", normalizer(text))\n",
    "print(\"tokenizer :\", tokenizer(text))\n",
    "\n",
    "输出：\n",
    "normalizer: ['i', \"'m\", 'using', 'torchtext', ',', 'it', \"'s\", 'great', '!']\n",
    "tokenizer : ['i', \"'m\", 'using', 'torchtext', ',', 'it', \"'s\", 'great', '!']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870d20d-e88d-471c-8f0e-c7565963c3d3",
   "metadata": {},
   "source": [
    "### ✅ 总结：\n",
    "\n",
    "`BasicEnglishNormalize` = `基本英文规范化工具`\n",
    "\n",
    "- 功能：小写化、标点分离、缩写拆分\n",
    "\n",
    "- 常用于：数据清洗、词表构建、保持词向量一致性\n",
    "\n",
    "- 如果`只是想快速分词`，可以直接用` get_tokenizer(\"basic_english\")`。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73979165-1f86-42a8-a9b2-4df48ac816f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6711fec5-2371-4e58-8f57-3b7abfa41019",
   "metadata": {},
   "source": [
    "## VocabTransform \n",
    "是一个 `文本数值化工具`，主要作用就是：\n",
    "\n",
    "👉 把词（token）转为对应的整数索引（id），也就是所谓的 `numericalization`。\n",
    "这一步通常在 构建词表` Vocab `之后使用。\n",
    "\n",
    "## 1. 作用\n",
    "\n",
    "- 输入：一个 token 序列（如 [\"hello\", \"world\"]）\n",
    "\n",
    "- 输出：对应的索引序列（如 [42, 1337]）\n",
    "\n",
    "用于把文本转成 可以送进深度学习模型的数字形式。\n",
    "\n",
    "⚠️ `VocabTransform `依赖一个` Vocab `对象（词表），它只是一个`“映射层”`。\n",
    "\n",
    "## 2. 使用方法\n",
    "### （1）构建词表 Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ae2dec-32fa-4b31-932b-74494359c9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield text.split()\n",
    "\n",
    "# 假设我们有一些样本\n",
    "samples = [\"hello world\", \"hello pytorch\"]\n",
    "\n",
    "# 构建词表\n",
    "vocab = build_vocab_from_iterator(yield_tokens(samples), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "此时 vocab 的内容可能是：\n",
    "\n",
    "{'<unk>':0, 'hello':1, 'world':2, 'pytorch':3}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1ac4d3-b436-4c89-a62b-a5f2479d9c1d",
   "metadata": {},
   "source": [
    "### （2）创建 VocabTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69cc5ba-2ea4-4fec-bc48-417050055b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.transforms import VocabTransform\n",
    "\n",
    "# 创建 VocabTransform\n",
    "vocab_transform = VocabTransform(vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71953b4-c9c3-48a1-9645-e3398450f3d8",
   "metadata": {},
   "source": [
    "### （3）使用 VocabTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a146b683-9177-45d9-ac1a-4c4bfdda7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\"hello\", \"world\", \"torch\"]\n",
    "ids = vocab_transform(tokens)\n",
    "\n",
    "print(\"tokens:\", tokens)\n",
    "print(\"ids   :\", ids)\n",
    "\n",
    "输出：\n",
    "\n",
    "tokens: ['hello', 'world', 'torch']\n",
    "ids   : [1, 2, 0]\n",
    "\n",
    "👉 \"torch\" 不在词表里，变成 <unk> 的索引 0。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b166b2f8-2e91-44a6-99da-81af23241959",
   "metadata": {},
   "source": [
    "## 3. 常见场景\n",
    "\n",
    "文本预处理流水线`（Pipeline）`\n",
    "通常和 `BasicEnglishNormalize` 或 `get_tokenizer` 搭配，用来把原始文本转成` id `序列。\n",
    "\n",
    "示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1824a07-00f2-4041-a5d6-8fe1ce4bed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.transforms import Sequential, BasicEnglishNormalize, ToTensor\n",
    "\n",
    "text_pipeline = Sequential(\n",
    "    BasicEnglishNormalize(),   # 文本标准化\n",
    "    vocab_transform,           # token → id\n",
    "    ToTensor(padding_value=0)  # 转成张量，自动 padding\n",
    ")\n",
    "\n",
    "text = \"Hello TorchText world!\"\n",
    "print(text_pipeline(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5167fe73-e22f-4324-a799-edd0692eb784",
   "metadata": {},
   "source": [
    "## 4. 总结\n",
    "\n",
    "- 功能：`VocabTransform` = `token` → `id `的映射工具\n",
    "\n",
    "- 依赖：需要先构建好` Vocab`\n",
    "\n",
    "- 优势：能和其他 `transform `组合成流水线（`Sequential`）\n",
    "\n",
    "典型流程：\n",
    "\n",
    "原始文本 → `BasicEnglishNormalize` → `Token 列表` → `VocabTransform` → `索引序列` → `ToTensor` → `模型输入`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae00e33e-cebf-4cff-afa8-ab53e77dce0c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beda6d8-bbce-414a-abf1-678ce894e05a",
   "metadata": {},
   "source": [
    "## 3. 简单示例：文本分类（AG_NEWS）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51dba23-9bcc-47fc-aed7-bd0afd92aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. 加载数据\n",
    "train_iter = AG_NEWS(split='train')\n",
    "\n",
    "# 2. 分词器\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "# 3. 构建词表\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "# 4. 数值化函数\n",
    "def collate_batch(batch):\n",
    "    labels, texts = [], []\n",
    "    for label, text in batch:\n",
    "        labels.append(label - 1)  # 标签从0开始\n",
    "        tokens = tokenizer(text)\n",
    "        ids = vocab(tokens)\n",
    "        texts.append(torch.tensor(ids, dtype=torch.int64))\n",
    "    labels = torch.tensor(labels, dtype=torch.int64)\n",
    "    texts = torch.nn.utils.rnn.pad_sequence(texts, batch_first=True)\n",
    "    return texts, labels\n",
    "\n",
    "# 5. DataLoader\n",
    "train_iter, test_iter = AG_NEWS()\n",
    "train_loader = DataLoader(train_iter, batch_size=8, shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "# 6. 取一个 batch\n",
    "for X, y in train_loader:\n",
    "    print(\"文本 batch:\", X.shape)\n",
    "    print(\"标签 batch:\", y.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614d7d83-69c1-4725-8415-332cafd0bf47",
   "metadata": {},
   "source": [
    "## 4. 总结\n",
    "\n",
    "✅ torchtext 提供的功能：\n",
    "\n",
    "- 数据集：IMDB、AG_NEWS、WikiText2 等\n",
    "\n",
    "- 数据处理：分词、数值化、padding、masking\n",
    "\n",
    "- 词向量：GloVe、FastText、CharNGram\n",
    "\n",
    "- 与 PyTorch 无缝集成：Dataset、DataLoader、Iterator\n",
    "\n",
    "⚠️ 版本差异：\n",
    "\n",
    "- 旧版 API（torchtext.data）：有 Field、Dataset、Iterator\n",
    "\n",
    "- 新版 API（torchtext.datasets & torchtext.transforms）：更模块化，推荐使用"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
