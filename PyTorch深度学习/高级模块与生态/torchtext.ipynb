{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92db7cf7-cac8-4f44-90e4-26e655611e55",
   "metadata": {},
   "source": [
    "# torchtext \n",
    "â€”â€”è¿™æ˜¯` PyTorch `å®˜æ–¹çš„ `è‡ªç„¶è¯­è¨€å¤„ç†`ï¼ˆNLPï¼‰å·¥å…·åŒ…ï¼Œå’Œ` torchvision `åœ¨è®¡ç®—æœºè§†è§‰é¢†åŸŸçš„åœ°ä½ç±»ä¼¼ã€‚\n",
    "\n",
    "## 1. torchtext çš„ä½œç”¨\n",
    "\n",
    "`PyTorch `è‡ªèº«æ˜¯ä¸€ä¸ª `æ·±åº¦å­¦ä¹ æ¡†æ¶`ï¼Œä¸åŒ…å«å¤ªå¤š NLP ä»»åŠ¡ä¸“ç”¨å·¥å…·ã€‚\n",
    "`torchtext `æä¾›äº†å¸¸è§çš„ æ–‡æœ¬å¤„ç†åŠŸèƒ½ï¼Œæ–¹ä¾¿æˆ‘ä»¬å¿«é€Ÿæ­å»º NLP æ¨¡å‹ï¼Œä¸»è¦åŒ…æ‹¬ï¼š\n",
    "\n",
    "- 1.æ•°æ®å¤„ç†:\n",
    "\n",
    "    - å¤„ç†åŸå§‹æ–‡æœ¬æ•°æ®ï¼ˆåˆ†è¯ã€è½¬å°å†™ã€å»é™¤æ ‡ç‚¹ï¼‰\n",
    "    \n",
    "    - å°†æ–‡æœ¬è½¬ä¸ºæ•°å­—ç´¢å¼•ï¼ˆtoken â†’ idï¼‰\n",
    "    \n",
    "    - æ„å»º Vocabï¼ˆè¯è¡¨ï¼‰\n",
    "    \n",
    "    - æ‰¹å¤„ç† & å¡«å……ï¼ˆpaddingã€maskingï¼‰\n",
    "\n",
    "- 2.æ•°æ®é›†:\n",
    "\n",
    "    - æä¾›å¸¸ç”¨ NLP æ•°æ®é›†ï¼ˆIMDBã€AG_NEWSã€SST2ã€WikiText2 ç­‰ï¼‰\n",
    "    \n",
    "    - å†…ç½®ä¸‹è½½ & é¢„å¤„ç†\n",
    "\n",
    "- 3.è¯å‘é‡\n",
    "\n",
    "    - æä¾›é¢„è®­ç»ƒçš„è¯å‘é‡ï¼ˆGloVeã€FastTextã€CharNGramï¼‰\n",
    "    \n",
    "    - å¯ä»¥ç›´æ¥åŠ è½½å¹¶ç”¨äºæ¨¡å‹åˆå§‹åŒ–\n",
    "\n",
    "- 4.ä¸ PyTorch æ— ç¼è¡”æ¥\n",
    "\n",
    "    - æä¾› `Dataset`ã€`DataLoader`ã€`Iterator`\n",
    "    \n",
    "    - å’Œ `torch.nn`ã€`torchtext.vocab`ã€`torchtext.transforms` ç­‰æ¨¡å—é…åˆä½¿ç”¨\n",
    "\n",
    "---\n",
    "## 2. ä¸»è¦æ¨¡å—ç»“æ„\n",
    "\n",
    "`torchtext` ä¸»è¦åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªéƒ¨åˆ†ï¼š\n",
    "\n",
    "### ï¼ˆ1ï¼‰torchtext.dataï¼ˆæ—§ APIï¼Œ`å·²é€æ¸è¢«å¼ƒç”¨`ï¼‰\n",
    "\n",
    "- Fieldï¼šå®šä¹‰å¦‚ä½•å¤„ç†æ•°æ®ï¼ˆåˆ†è¯ã€æ•°å€¼åŒ–ã€padding ç­‰ï¼‰\n",
    "\n",
    "- Datasetï¼šä¿å­˜æ–‡æœ¬æ•°æ®\n",
    "\n",
    "- Iteratorï¼šæŒ‰ batch è¿­ä»£\n",
    "\n",
    "âš ï¸ æ³¨æ„ï¼šæ–°ç‰ˆæœ¬æ¨èç”¨ `torchtext.datasets` å’Œ `torchtext.transforms`ï¼Œä½†ä¸€äº›æ•™ç¨‹è¿˜åœ¨ç”¨æ—§ APIã€‚\n",
    "\n",
    "---\n",
    "### ï¼ˆ2ï¼‰`torchtext.datasets`\n",
    "\n",
    "æä¾›å¼€ç®±å³ç”¨çš„ NLP æ•°æ®é›†ï¼Œè‡ªåŠ¨ä¸‹è½½å’Œå¤„ç†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e8a9c7-c9b3-4567-bdf6-d17d331d1ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import AG_NEWS\n",
    "\n",
    "train_iter = AG_NEWS(split='train')\n",
    "test_iter = AG_NEWS(split='test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd3dbb1-871d-485f-8376-b70bd64669b8",
   "metadata": {},
   "source": [
    "`train_iter` å°±æ˜¯ä¸€ä¸ªè¿­ä»£å™¨ï¼Œé‡Œé¢åŒ…å« `(label, text)`ã€‚\n",
    "\n",
    "---\n",
    "### ï¼ˆ3ï¼‰torchtext.vocab\n",
    "\n",
    "æä¾›è¯è¡¨ç®¡ç† & é¢„è®­ç»ƒè¯å‘é‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084b51fd-bb32-40f5-b6d8-113decc504ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe\n",
    "\n",
    "glove = GloVe(name=\"6B\", dim=100)  # åŠ è½½ GloVe 100ç»´è¯å‘é‡\n",
    "print(glove[\"computer\"])           # ç›´æ¥å–å‘é‡\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60394d28-f04a-47c3-ab35-630e084b8bf4",
   "metadata": {},
   "source": [
    "ä¹Ÿå¯ä»¥ç”¨` build_vocab_from_iterator() `æ¥è‡ªå·±æ„å»ºè¯è¡¨ã€‚\n",
    "\n",
    "---\n",
    "### ï¼ˆ4ï¼‰torchtext.transforms\n",
    "\n",
    "- æä¾›ç°ä»£åŒ–çš„æ•°æ®å¤„ç†æµæ°´çº¿ï¼ˆtokenize â†’ numericalize â†’ padï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30db5bc-5e07-4544-9ea2-e3126ed2ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.transforms import BasicEnglishNormalize, VocabTransform, ToTensor\n",
    "\n",
    "# åŸºç¡€é¢„å¤„ç†\n",
    "text_transform = BasicEnglishNormalize()\n",
    "tokens = text_transform(\"Hello, World!\")\n",
    "print(tokens)  # ['hello', 'world']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f511def5-e32d-40ae-92bf-7f7e533c3437",
   "metadata": {},
   "source": [
    "## BasicEnglishNormalize \n",
    "æ˜¯ä¸€ä¸ªéå¸¸å®ç”¨çš„ `æ–‡æœ¬é¢„å¤„ç†å·¥å…·`ï¼Œä¸»è¦ç”¨äº `è‹±æ–‡æ–‡æœ¬çš„æ ‡å‡†åŒ–å¤„ç†`ï¼Œè®©è¾“å…¥çš„æ–‡æœ¬æ›´å¹²å‡€ã€ç»Ÿä¸€ï¼Œä¾¿äºåç»­åˆ†è¯å’Œå»ºæ¨¡ã€‚\n",
    "\n",
    "### ä½œç”¨\n",
    "\n",
    "`BasicEnglishNormalize` ä¼šå¯¹è¾“å…¥çš„å­—ç¬¦ä¸²åšä»¥ä¸‹æ“ä½œï¼š\n",
    "\n",
    "- 1.å…¨éƒ¨è½¬å°å†™\n",
    "\n",
    "\"Hello WORLD!\" â†’ \"hello world !\"\n",
    "\n",
    "- 2.å»æ‰ä¸å¿…è¦çš„ç¬¦å·\n",
    "\n",
    "æŠŠ \"ã€'sã€n't ç­‰å¤„ç†ä¸ºæ ‡å‡†åŒ–å½¢å¼\n",
    "\n",
    "- 3.å¤„ç†æ ‡ç‚¹ç¬¦å·\n",
    "\n",
    "æŠŠæ ‡ç‚¹å’Œå•è¯åˆ†å¼€ï¼Œä¾‹å¦‚ï¼š\n",
    "\"hello,world!\" â†’ \"hello , world !\"\n",
    "\n",
    "- 4.æ ‡å‡†åŒ–å¸¸è§ç¼©å†™\n",
    "\n",
    "\"I'm\" â†’ \"i 'm\"\n",
    "\n",
    "\"don't\" â†’ \"do n't\"\n",
    "\n",
    "âš ï¸ æ³¨æ„ï¼šå®ƒ `ä¸ä¼šåˆ†è¯`ï¼Œåªæ˜¯æŠŠæ–‡æœ¬è½¬æ¢æˆ `æ ‡å‡†åŒ–å`çš„` token `åˆ—è¡¨ã€‚\n",
    "\n",
    "---\n",
    "### å’Œ get_tokenizer(\"basic_english\") çš„å…³ç³»\n",
    "\n",
    "`BasicEnglishNormalize()` æ˜¯ä¸€ä¸ª `æ ‡å‡†åŒ–å™¨`ï¼Œè¿”å› `è¯å…ƒåˆ—è¡¨`\n",
    "\n",
    "`get_tokenizer(\"basic_english\")` å†…éƒ¨å…¶å®å°±æ˜¯è°ƒç”¨äº†` BasicEnglishNormalize`ï¼Œæ•ˆæœå·®ä¸å¤šï¼Œä½†å†™æ³•æ›´ç®€æ´\n",
    "\n",
    "ç¤ºä¾‹å¯¹æ¯”ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d47bc1d-9b67-4e3f-892f-925e3ecbc057",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.transforms import BasicEnglishNormalize\n",
    "\n",
    "normalizer = BasicEnglishNormalize()\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "text = \"I'm using TorchText, It's great!\"\n",
    "\n",
    "print(\"normalizer:\", normalizer(text))\n",
    "print(\"tokenizer :\", tokenizer(text))\n",
    "\n",
    "è¾“å‡ºï¼š\n",
    "normalizer: ['i', \"'m\", 'using', 'torchtext', ',', 'it', \"'s\", 'great', '!']\n",
    "tokenizer : ['i', \"'m\", 'using', 'torchtext', ',', 'it', \"'s\", 'great', '!']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870d20d-e88d-471c-8f0e-c7565963c3d3",
   "metadata": {},
   "source": [
    "### âœ… æ€»ç»“ï¼š\n",
    "\n",
    "`BasicEnglishNormalize` = `åŸºæœ¬è‹±æ–‡è§„èŒƒåŒ–å·¥å…·`\n",
    "\n",
    "- åŠŸèƒ½ï¼šå°å†™åŒ–ã€æ ‡ç‚¹åˆ†ç¦»ã€ç¼©å†™æ‹†åˆ†\n",
    "\n",
    "- å¸¸ç”¨äºï¼šæ•°æ®æ¸…æ´—ã€è¯è¡¨æ„å»ºã€ä¿æŒè¯å‘é‡ä¸€è‡´æ€§\n",
    "\n",
    "- å¦‚æœ`åªæ˜¯æƒ³å¿«é€Ÿåˆ†è¯`ï¼Œå¯ä»¥ç›´æ¥ç”¨` get_tokenizer(\"basic_english\")`ã€‚\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73979165-1f86-42a8-a9b2-4df48ac816f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6711fec5-2371-4e58-8f57-3b7abfa41019",
   "metadata": {},
   "source": [
    "## VocabTransform \n",
    "æ˜¯ä¸€ä¸ª `æ–‡æœ¬æ•°å€¼åŒ–å·¥å…·`ï¼Œä¸»è¦ä½œç”¨å°±æ˜¯ï¼š\n",
    "\n",
    "ğŸ‘‰ æŠŠè¯ï¼ˆtokenï¼‰è½¬ä¸ºå¯¹åº”çš„æ•´æ•°ç´¢å¼•ï¼ˆidï¼‰ï¼Œä¹Ÿå°±æ˜¯æ‰€è°“çš„ `numericalization`ã€‚\n",
    "è¿™ä¸€æ­¥é€šå¸¸åœ¨ æ„å»ºè¯è¡¨` Vocab `ä¹‹åä½¿ç”¨ã€‚\n",
    "\n",
    "## 1. ä½œç”¨\n",
    "\n",
    "- è¾“å…¥ï¼šä¸€ä¸ª token åºåˆ—ï¼ˆå¦‚ [\"hello\", \"world\"]ï¼‰\n",
    "\n",
    "- è¾“å‡ºï¼šå¯¹åº”çš„ç´¢å¼•åºåˆ—ï¼ˆå¦‚ [42, 1337]ï¼‰\n",
    "\n",
    "ç”¨äºæŠŠæ–‡æœ¬è½¬æˆ å¯ä»¥é€è¿›æ·±åº¦å­¦ä¹ æ¨¡å‹çš„æ•°å­—å½¢å¼ã€‚\n",
    "\n",
    "âš ï¸ `VocabTransform `ä¾èµ–ä¸€ä¸ª` Vocab `å¯¹è±¡ï¼ˆè¯è¡¨ï¼‰ï¼Œå®ƒåªæ˜¯ä¸€ä¸ª`â€œæ˜ å°„å±‚â€`ã€‚\n",
    "\n",
    "## 2. ä½¿ç”¨æ–¹æ³•\n",
    "### ï¼ˆ1ï¼‰æ„å»ºè¯è¡¨ Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ae2dec-32fa-4b31-932b-74494359c9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield text.split()\n",
    "\n",
    "# å‡è®¾æˆ‘ä»¬æœ‰ä¸€äº›æ ·æœ¬\n",
    "samples = [\"hello world\", \"hello pytorch\"]\n",
    "\n",
    "# æ„å»ºè¯è¡¨\n",
    "vocab = build_vocab_from_iterator(yield_tokens(samples), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "æ­¤æ—¶ vocab çš„å†…å®¹å¯èƒ½æ˜¯ï¼š\n",
    "\n",
    "{'<unk>':0, 'hello':1, 'world':2, 'pytorch':3}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1ac4d3-b436-4c89-a62b-a5f2479d9c1d",
   "metadata": {},
   "source": [
    "### ï¼ˆ2ï¼‰åˆ›å»º VocabTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69cc5ba-2ea4-4fec-bc48-417050055b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.transforms import VocabTransform\n",
    "\n",
    "# åˆ›å»º VocabTransform\n",
    "vocab_transform = VocabTransform(vocab)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71953b4-c9c3-48a1-9645-e3398450f3d8",
   "metadata": {},
   "source": [
    "### ï¼ˆ3ï¼‰ä½¿ç”¨ VocabTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a146b683-9177-45d9-ac1a-4c4bfdda7f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\"hello\", \"world\", \"torch\"]\n",
    "ids = vocab_transform(tokens)\n",
    "\n",
    "print(\"tokens:\", tokens)\n",
    "print(\"ids   :\", ids)\n",
    "\n",
    "è¾“å‡ºï¼š\n",
    "\n",
    "tokens: ['hello', 'world', 'torch']\n",
    "ids   : [1, 2, 0]\n",
    "\n",
    "ğŸ‘‰ \"torch\" ä¸åœ¨è¯è¡¨é‡Œï¼Œå˜æˆ <unk> çš„ç´¢å¼• 0ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b166b2f8-2e91-44a6-99da-81af23241959",
   "metadata": {},
   "source": [
    "## 3. å¸¸è§åœºæ™¯\n",
    "\n",
    "æ–‡æœ¬é¢„å¤„ç†æµæ°´çº¿`ï¼ˆPipelineï¼‰`\n",
    "é€šå¸¸å’Œ `BasicEnglishNormalize` æˆ– `get_tokenizer` æ­é…ï¼Œç”¨æ¥æŠŠåŸå§‹æ–‡æœ¬è½¬æˆ` id `åºåˆ—ã€‚\n",
    "\n",
    "ç¤ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1824a07-00f2-4041-a5d6-8fe1ce4bed9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.transforms import Sequential, BasicEnglishNormalize, ToTensor\n",
    "\n",
    "text_pipeline = Sequential(\n",
    "    BasicEnglishNormalize(),   # æ–‡æœ¬æ ‡å‡†åŒ–\n",
    "    vocab_transform,           # token â†’ id\n",
    "    ToTensor(padding_value=0)  # è½¬æˆå¼ é‡ï¼Œè‡ªåŠ¨ padding\n",
    ")\n",
    "\n",
    "text = \"Hello TorchText world!\"\n",
    "print(text_pipeline(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5167fe73-e22f-4324-a799-edd0692eb784",
   "metadata": {},
   "source": [
    "## 4. æ€»ç»“\n",
    "\n",
    "- åŠŸèƒ½ï¼š`VocabTransform` = `token` â†’ `id `çš„æ˜ å°„å·¥å…·\n",
    "\n",
    "- ä¾èµ–ï¼šéœ€è¦å…ˆæ„å»ºå¥½` Vocab`\n",
    "\n",
    "- ä¼˜åŠ¿ï¼šèƒ½å’Œå…¶ä»– `transform `ç»„åˆæˆæµæ°´çº¿ï¼ˆ`Sequential`ï¼‰\n",
    "\n",
    "å…¸å‹æµç¨‹ï¼š\n",
    "\n",
    "åŸå§‹æ–‡æœ¬ â†’ `BasicEnglishNormalize` â†’ `Token åˆ—è¡¨` â†’ `VocabTransform` â†’ `ç´¢å¼•åºåˆ—` â†’ `ToTensor` â†’ `æ¨¡å‹è¾“å…¥`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae00e33e-cebf-4cff-afa8-ab53e77dce0c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beda6d8-bbce-414a-abf1-678ce894e05a",
   "metadata": {},
   "source": [
    "## 3. ç®€å•ç¤ºä¾‹ï¼šæ–‡æœ¬åˆ†ç±»ï¼ˆAG_NEWSï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51dba23-9bcc-47fc-aed7-bd0afd92aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. åŠ è½½æ•°æ®\n",
    "train_iter = AG_NEWS(split='train')\n",
    "\n",
    "# 2. åˆ†è¯å™¨\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "# 3. æ„å»ºè¯è¡¨\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])\n",
    "\n",
    "# 4. æ•°å€¼åŒ–å‡½æ•°\n",
    "def collate_batch(batch):\n",
    "    labels, texts = [], []\n",
    "    for label, text in batch:\n",
    "        labels.append(label - 1)  # æ ‡ç­¾ä»0å¼€å§‹\n",
    "        tokens = tokenizer(text)\n",
    "        ids = vocab(tokens)\n",
    "        texts.append(torch.tensor(ids, dtype=torch.int64))\n",
    "    labels = torch.tensor(labels, dtype=torch.int64)\n",
    "    texts = torch.nn.utils.rnn.pad_sequence(texts, batch_first=True)\n",
    "    return texts, labels\n",
    "\n",
    "# 5. DataLoader\n",
    "train_iter, test_iter = AG_NEWS()\n",
    "train_loader = DataLoader(train_iter, batch_size=8, shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "# 6. å–ä¸€ä¸ª batch\n",
    "for X, y in train_loader:\n",
    "    print(\"æ–‡æœ¬ batch:\", X.shape)\n",
    "    print(\"æ ‡ç­¾ batch:\", y.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614d7d83-69c1-4725-8415-332cafd0bf47",
   "metadata": {},
   "source": [
    "## 4. æ€»ç»“\n",
    "\n",
    "âœ… torchtext æä¾›çš„åŠŸèƒ½ï¼š\n",
    "\n",
    "- æ•°æ®é›†ï¼šIMDBã€AG_NEWSã€WikiText2 ç­‰\n",
    "\n",
    "- æ•°æ®å¤„ç†ï¼šåˆ†è¯ã€æ•°å€¼åŒ–ã€paddingã€masking\n",
    "\n",
    "- è¯å‘é‡ï¼šGloVeã€FastTextã€CharNGram\n",
    "\n",
    "- ä¸ PyTorch æ— ç¼é›†æˆï¼šDatasetã€DataLoaderã€Iterator\n",
    "\n",
    "âš ï¸ ç‰ˆæœ¬å·®å¼‚ï¼š\n",
    "\n",
    "- æ—§ç‰ˆ APIï¼ˆtorchtext.dataï¼‰ï¼šæœ‰ Fieldã€Datasetã€Iterator\n",
    "\n",
    "- æ–°ç‰ˆ APIï¼ˆtorchtext.datasets & torchtext.transformsï¼‰ï¼šæ›´æ¨¡å—åŒ–ï¼Œæ¨èä½¿ç”¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
