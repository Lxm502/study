{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c090412-74d5-4b78-9c93-e901c6d0e5de",
   "metadata": {},
   "source": [
    "# torchvision \n",
    "——这是 PyTorch 专门为 计算机视觉 (CV) 提供的工具包。\n",
    "\n",
    "它主要包括三大类功能：\n",
    "\n",
    "- 数据集 (torchvision.datasets)\n",
    "\n",
    "- 图像变换 (torchvision.transforms)\n",
    "\n",
    "- 模型 (torchvision.models)\n",
    "\n",
    "另外还有一些图像处理工具和可视化方法。\n",
    "\n",
    "---\n",
    "## 1. torchvision.datasets\n",
    "\n",
    "提供了很多常用的` 图像数据集接口`，可以直接下载、加载并返回 PyTorch 的` Dataset `对象，和` DataLoader `配合使用。\n",
    "\n",
    "常见的数据集：\n",
    "| 数据集                    | 任务      | 描述               |\n",
    "| ---------------------- | ------- | ---------------- |\n",
    "| **MNIST**              | 图像分类    | 手写数字 (28×28 灰度图) |\n",
    "| **CIFAR10 / CIFAR100** | 图像分类    | 小图片 (32×32，RGB)  |\n",
    "| **FashionMNIST**       | 图像分类    | 类似 MNIST，但内容是衣物  |\n",
    "| **ImageNet**           | 图像分类    | 大规模数据集 (1000 类)  |\n",
    "| **COCO**               | 目标检测/分割 | 常用的检测 & 分割数据集    |\n",
    "| **VOC**                | 目标检测/分割 | PASCAL VOC 数据集   |\n",
    "\n",
    "示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a526107d-f53e-4d6c-82d0-0b691206f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# 下载 & 加载 MNIST\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=True, download=True, transform=transform\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193ac5d1-86d7-4071-9a6c-58d190787c3c",
   "metadata": {},
   "source": [
    "## 2. torchvision.transforms\n",
    "\n",
    "用于` 数据增强 `/` 预处理`，把` PIL.Image `或` Tensor `转换为适合神经网络的输入。\n",
    "\n",
    "常见操作：\n",
    "| 方法                                       | 作用                     |\n",
    "| ---------------------------------------- | ---------------------- |\n",
    "| `transforms.Resize(size)`                | 调整图片大小                 |\n",
    "| `transforms.CenterCrop(size)`            | 裁剪中心区域                 |\n",
    "| `transforms.RandomCrop(size)`            | 随机裁剪                   |\n",
    "| `transforms.RandomHorizontalFlip(p=0.5)` | 随机水平翻转                 |\n",
    "| `transforms.RandomRotation(degrees)`     | 随机旋转                   |\n",
    "| `transforms.ColorJitter()`               | 随机改变亮度/对比度/饱和度         |\n",
    "| `transforms.ToTensor()`                  | 转换为 Tensor，归一化到 \\[0,1] |\n",
    "| `transforms.Normalize(mean, std)`        | 标准化 `(x-mean)/std`     |\n",
    "| `transforms.Compose([...])`              | 串联多个变换                 |\n",
    "\n",
    "示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afdb88f-a374-4f03-9329-fd2ed119589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   # 统一大小\n",
    "    transforms.RandomHorizontalFlip(),  # 随机翻转\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # 标准化\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457c812f-e0c5-49ac-9825-a5e47df1c136",
   "metadata": {},
   "source": [
    "## 3. torchvision.models\n",
    "\n",
    "提供了很多` 预训练模型`（在 ImageNet 上训练过），可以直接拿来` 迁移学习 `或` 特征提取`。\n",
    "\n",
    "常见模型：\n",
    "\n",
    "- 分类模型：\n",
    "\n",
    "    - ResNet (18/34/50/101/152)\n",
    "    \n",
    "    - VGG (11/13/16/19)\n",
    "    \n",
    "    - DenseNet\n",
    "    \n",
    "    - AlexNet\n",
    "    \n",
    "    - MobileNet\n",
    "    \n",
    "    - EfficientNet\n",
    "    \n",
    "    - Vision Transformer (ViT)\n",
    "\n",
    "- 检测 / 分割模型：\n",
    "\n",
    "    - Faster R-CNN\n",
    "    \n",
    "    - Mask R-CNN\n",
    "    \n",
    "    - RetinaNet\n",
    "    \n",
    "    - SSD\n",
    "    \n",
    "    - DeepLabV3\n",
    "    \n",
    "    - FCN\n",
    "\n",
    "使用预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33623d8-c461-40a2-9ca1-fad67544a751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "# 加载预训练 ResNet18\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# 修改最后一层（适应 10 分类任务）\n",
    "import torch.nn as nn\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a5d685-68a0-43d4-a202-208f47a23c46",
   "metadata": {},
   "source": [
    "## 4. torchvision.io / utils\n",
    "\n",
    "`torchvision.io`：图像/视频的读写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60f65b8-d841-4358-9359-239c934bdcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "img = read_image(\"example.jpg\")  # 直接读取为 Tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e387a9-3c1b-4337-90d2-890c81098368",
   "metadata": {},
   "source": [
    "`torchvision.utils`：可视化工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b823f349-e641-4d6a-bb88-671036d911a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "grid = make_grid(img_batch, nrow=8, normalize=True)\n",
    "plt.imshow(grid.permute(1, 2, 0))  # C,H,W -> H,W,C\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fb77b5-ce27-4cea-95c0-18f3e660d85c",
   "metadata": {},
   "source": [
    "## 5. 总结\n",
    "\n",
    "✅ torchvision 是 PyTorch 的视觉工具包，主要作用：\n",
    "\n",
    "- datasets → 快速加载常见数据集 (MNIST, CIFAR, COCO, VOC, ImageNet)\n",
    "\n",
    "- transforms → 数据增强 & 预处理 (Resize, Flip, Normalize...)\n",
    "\n",
    "- models → 提供预训练模型 (ResNet, VGG, ViT, Faster-RCNN...)\n",
    "\n",
    "- io / utils → 图像读写 & 可视化工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8c2909-0d2d-4bef-aabd-214a4f915fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaf858c8-2db1-4510-8264-38f7fe9c95b0",
   "metadata": {},
   "source": [
    "# 🔥 迁移学习示例：ResNet18 + CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66642062-2424-45c3-80b6-5782d66cabbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ===============================\n",
    "# 1. 数据准备\n",
    "# ===============================\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(224),  # ResNet 输入要求 224x224\n",
    "    transforms.RandomHorizontalFlip(),  # 随机水平翻转\n",
    "    transforms.RandomCrop(224, padding=4),  # 随机裁剪\n",
    "    transforms.ToTensor(),  # 转为 tensor 张量数据类型\n",
    "    transforms.Normalize((0.5, 0.5, 0.5),  # 归一化\n",
    "                         (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(224),   # 重新设置图片的尺寸\n",
    "    transforms.ToTensor(),    \n",
    "    transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                         (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)\n",
    "\n",
    "classes = trainset.classes  # CIFAR-10 类别\n",
    "\n",
    "# ===============================\n",
    "# 2. 定义模型（迁移学习）\n",
    "# ===============================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载预训练模型\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# 冻结前面的卷积层参数（只训练最后全连接层）\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 修改最后一层：CIFAR-10 共有 10 类\n",
    "model.fc = nn.Linear(model.fc.in_features, 10)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# ===============================\n",
    "# 3. 损失函数 & 优化器 & 学习率调度器\n",
    "# ===============================\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)  # 只优化最后一层\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)  # 每 10 epoch 学习率 ×0.1\n",
    "\n",
    "# ===============================\n",
    "# 4. 训练 & 验证\n",
    "# ===============================\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    for inputs, targets in trainloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()   # 清空梯度\n",
    "        outputs = model(inputs) # 预测（前向传播）\n",
    "        loss = criterion(outputs, targets)  # 计算损失\n",
    "        loss.backward()         # 反向梯度传播\n",
    "        optimizer.step()        # 根据梯度更新 权重\n",
    "\n",
    "        running_loss += loss.item()    # 统计训练损失\n",
    "        _, predicted = outputs.max(1)  # 提取预测类别的索引\n",
    "        total += targets.size(0)       # 统计训练总样本\n",
    "        correct += predicted.eq(targets).sum().item()  # 统计准确率\n",
    " \n",
    "    epoch_loss = running_loss / len(trainloader)  # 计算每个epoch损失 \n",
    "    epoch_acc = 100. * correct / total            # 计算每个epoch准确率\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate(epoch):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in testloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(testloader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 5. 主训练循环\n",
    "# ===============================\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(epoch)\n",
    "    val_loss, val_acc = validate(epoch)\n",
    "    scheduler.step()   # 更新学习率\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}% \"\n",
    "          f\"| Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "# ===============================\n",
    "# 6. 可视化 Loss & Acc 曲线\n",
    "# ===============================\n",
    "epochs = range(1, num_epochs+1)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "plt.plot(epochs, val_losses, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, train_accs, label=\"Train Acc\")\n",
    "plt.plot(epochs, val_accs, label=\"Val Acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# ===============================\n",
    "# 7. 测试集可视化预测结果\n",
    "# ===============================\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # 去归一化\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# 随机获取一些测试样本\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# 显示图像\n",
    "imshow(torchvision.utils.make_grid(images[:8]))\n",
    "print(\"GroundTruth: \", \" \".join(f\"{classes[labels[j]]}\" for j in range(8)))\n",
    "\n",
    "# 模型预测\n",
    "images = images.to(device)\n",
    "outputs = model(images)\n",
    "_, predicted = outputs.max(1)\n",
    "\n",
    "print(\"Predicted: \", \" \".join(f\"{classes[predicted[j]]}\" for j in range(8)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb83132f-dfe2-4eed-8540-efe451e7a70f",
   "metadata": {},
   "source": [
    "## 🚀 运行效果\n",
    "\n",
    "训练日志：\n",
    "\n",
    "- 每个 epoch 输出 Train Loss/Acc 和 Val Loss/Acc\n",
    "\n",
    "- Loss & Accuracy 曲线：可视化对比训练 & 验证过程\n",
    "\n",
    "- 测试样本可视化：展示真实标签 vs 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17199938-07e4-4460-9eb2-1f10e01a5f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
