{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e057c0-79d8-4684-a3b4-695f04c8b803",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. 环境准备 : 导入各种需要的包\n",
    "2. 数据准备与预处理\n",
    "  2.1 定义数据转换\n",
    "  2.2 加载数据集\n",
    "  2.3 创建数据加载器\n",
    "3. 模型构建\n",
    "  3.1 自定义CNN模型\n",
    "  3.2 使用预训练模型（可选）\n",
    "4. 训练准备\n",
    "  4.1 初始化模型\n",
    "  4.2 定义损失函数和优化器\n",
    "  4.3 训练和验证函数\n",
    "5. 训练循环\n",
    "6. 训练过程可视化\n",
    "7. 模型评估\n",
    "  7.1 加载最佳模型\n",
    "  7.2 测试集评估\n",
    "  7.3 混淆矩阵和分类报告\n",
    "8. 预测单张图片\n",
    "9. 模型部署（可选）\n",
    "\n",
    "这个完整的PyTorch图片分类工作流程包括：\n",
    "1.数据准备与增强\n",
    "2.模型构建（自定义或预训练模型）\n",
    "3.训练循环与验证\n",
    "4.模型评估与可视化\n",
    "5.预测功能\n",
    "6.模型保存与部署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03eefe8-57d3-4527-ac53-8a1d6762a78e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79bab17-3fec-4db8-a025-4b288db2410c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "765a6ad7-1615-4321-9bc3-1f93c239ab55",
   "metadata": {},
   "source": [
    "# PyTorch 图像分类模型示例，使用经典的 CIFAR-10 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb35687a-6f62-406a-a5dd-c1eb8a810e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import torch.nn as nn        # 用于构建神经网络 的模块\n",
    "import torch.optim as optim  # 用于构建优化器（优化函数）的模块\n",
    "from torch.utils.data import DataLoader # 数据加载模块：它将数据集封装成一个可迭代对象，支持自动批处理、随机打乱、多进程并行加载等功能\n",
    "import torchvision # 是 PyTorch 的官方视觉库，专门为计算机视觉任务设计，提供了三大核心功能：1预训练模型、2数据集、3数据变换\n",
    "import torchvision.transforms as transforms # 数据变换模块：提供丰富的图像预处理和数据增强方法\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ================================\n",
    "# 1. 设置设备：使用 GPU（如果可用）或 CPU\n",
    "# ================================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# ================================\n",
    "# 2. 数据预处理和加载\n",
    "# ================================\n",
    "\n",
    "# 定义图像预处理操作\n",
    "# transforms.Compose 将多个操作组合在一起\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),        # 随机水平翻转，增强数据多样性\n",
    "    transforms.RandomCrop(32, padding=4),     # 随机裁剪到 32x32，边缘填充 4 像素\n",
    "    transforms.ToTensor(),                    # 转换为 Tensor (C, H, W)\n",
    "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465),  # 标准化：减均值除标准差\n",
    "                         std=(0.2023, 0.1994, 0.2010))   # CIFAR-10 的均值和标准差\n",
    "])\n",
    "\n",
    "# 测试集只做标准化，不做数据增强\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465),\n",
    "                         std=(0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "# 加载 CIFAR-10 训练集\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',              # 数据保存路径\n",
    "    train=True,                 # 使用训练集\n",
    "    download=True,              # 如果本地没有，自动下载\n",
    "    transform=transform_train   # 应用预处理\n",
    ")\n",
    "\n",
    "# 加载测试集\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,                # 使用测试集\n",
    "    download=True,\n",
    "    transform=transform_test\n",
    ")\n",
    "\n",
    "# 创建数据加载器（DataLoader），用于批量读取数据\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=128,             # 每批 128 张图片\n",
    "    shuffle=True,               # 打乱顺序\n",
    "    num_workers=2               # 使用 2 个子进程加载数据（加快速度）\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=100,             # 测试时 batch 可稍大\n",
    "    shuffle=False,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "# CIFAR-10 的类别名称\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# ================================\n",
    "# 3. 定义卷积神经网络模型\n",
    "# ================================\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        # 第一个卷积层：3通道输入 -> 32 输出通道，卷积核 3x3\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)  # 2x2 最大池化，尺寸减半\n",
    "\n",
    "        # 第二个卷积层：32 -> 64 通道\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        # 第三个卷积层：64 -> 128 通道\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(2)  # 经过三次池化，32 -> 4\n",
    "\n",
    "        # 全连接层：将特征图展平后分类\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 512)  # 4x4 是最后特征图大小\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)  # 防止过拟合\n",
    "        self.fc2 = nn.Linear(512, num_classes)  # 输出 10 类\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = self.pool3(self.relu3(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)  # 展平成 (batch_size, 128*4*4)\n",
    "        x = self.relu4(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 实例化模型并移动到设备（GPU/CPU）\n",
    "model = SimpleCNN(num_classes=10).to(device)\n",
    "\n",
    "# ================================\n",
    "# 4. 定义损失函数和优化器\n",
    "# ================================\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()  # 多分类交叉熵损失\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # 使用 Adam 优化器\n",
    "\n",
    "# ================================\n",
    "# 5. 训练模型\n",
    "# ================================\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 切换到训练模式（启用 Dropout 等）\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # 移动到 GPU\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()  # 清除梯度\n",
    "        loss.backward()        # 反向传播\n",
    "        optimizer.step()       # 更新参数\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 计算平均训练损失\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "\n",
    "    # 每个 epoch 后在测试集上评估\n",
    "    model.eval()  # 切换到评估模式（关闭 Dropout）\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # 不计算梯度，节省内存\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100. * correct / total\n",
    "    test_accuracies.append(accuracy)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# ================================\n",
    "# 6. 绘制训练过程曲线\n",
    "# ================================\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(test_accuracies, color='orange', label='Test Accuracy')\n",
    "plt.title('Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ================================\n",
    "# 7. 保存模型\n",
    "# ================================\n",
    "\n",
    "torch.save(model.state_dict(), 'cifar10_cnn_model.pth')\n",
    "print(\"模型已保存: cifar10_cnn_model.pth\")\n",
    "\n",
    "# ================================\n",
    "# 8. 可选：测试单张图片并可视化\n",
    "# ================================\n",
    "\n",
    "def imshow(img):\n",
    "    img = img * torch.tensor([0.2023, 0.1994, 0.2010]).view(3,1,1) + \\\n",
    "          torch.tensor([0.4914, 0.4822, 0.4465]).view(3,1,1)  # 反标准化\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# 获取一批测试图像\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "images, labels = images[:4], labels[:4]  # 取前 4 张\n",
    "\n",
    "# 移动到设备\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "# 预测\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# 显示图像和预测结果\n",
    "imshow(torchvision.utils.make_grid(images.cpu()))\n",
    "print('真实标签:', ' '.join(f'{classes[labels[i]]}' for i in range(4)))\n",
    "print('预测标签:', ' '.join(f'{classes[predicted[i]]}' for i in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe48e130-a1d9-4dea-9118-b1dda1de1242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7caa2d94-2738-4345-b501-eacb0a08de84",
   "metadata": {},
   "source": [
    "# PyTorch 回归模型示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3010cd3b-9867-4900-83c6-dcc715eee699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# ================================\n",
    "# 1. 设置设备：使用 GPU（如果可用）或 CPU\n",
    "# ================================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# ================================\n",
    "# 2. 生成模拟回归数据\n",
    "# ================================\n",
    "# 我们模拟一个非线性关系：y = x^2 + sin(x) + 噪声\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 生成 1000 个数据点，x 在 [-5, 5] 区间\n",
    "x = np.random.uniform(-5, 5, size=(1000, 1))\n",
    "y = x ** 2 + np.sin(x * 2) + np.random.normal(0, 0.5, x.shape)  # 添加噪声\n",
    "\n",
    "# 转换为 PyTorch 的 Tensor\n",
    "x_tensor = torch.FloatTensor(x).to(device)\n",
    "y_tensor = torch.FloatTensor(y).to(device)\n",
    "\n",
    "# ================================\n",
    "# 3. 创建数据集和数据加载器\n",
    "# ================================\n",
    "# 使用 TensorDataset 将输入和标签打包\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "# 划分训练集和测试集（80% 训练，20% 测试）\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# 创建 DataLoader，支持批量训练\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"训练样本数: {len(train_dataset)}\")\n",
    "print(f\"测试样本数: {len(test_dataset)}\")\n",
    "\n",
    "# ================================\n",
    "# 4. 定义回归模型（多层感知机 MLP）\n",
    "# ================================\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=64, output_size=1):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        # 定义网络结构：输入层 -> 隐藏层 -> 激活函数 -> 隐藏层 -> 激活函数 -> 输出层\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),    # 第一层：1 -> 64\n",
    "            nn.ReLU(),                             # 激活函数\n",
    "            nn.Linear(hidden_size, hidden_size),   # 第二层：64 -> 64\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)    # 输出层：64 -> 1（回归输出单值）\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# 实例化模型并移动到设备\n",
    "model = RegressionModel(input_size=1, hidden_size=64, output_size=1).to(device)\n",
    "\n",
    "# ================================\n",
    "# 5. 定义损失函数和优化器\n",
    "# ================================\n",
    "# 回归任务使用均方误差（MSE）\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 使用 Adam 优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# ================================\n",
    "# 6. 训练模型\n",
    "# ================================\n",
    "num_epochs = 200\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # 切换到训练模式（虽然这里没有 Dropout/BatchNorm）\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, targets in train_loader:\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()  # 清除梯度\n",
    "        loss.backward()        # 反向传播计算梯度\n",
    "        optimizer.step()       # 更新参数\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 记录每个 epoch 的平均损失\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "\n",
    "    # 每 20 个 epoch 打印一次\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.6f}')\n",
    "\n",
    "# ================================\n",
    "# 7. 绘制训练损失曲线\n",
    "# ================================\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# ================================\n",
    "# 8. 在测试集上评估并可视化预测结果\n",
    "# ================================\n",
    "model.eval()  # 切换到评估模式\n",
    "test_predictions = []\n",
    "test_targets = []\n",
    "\n",
    "with torch.no_grad():  # 不需要梯度计算\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        test_predictions.append(outputs.cpu().numpy())\n",
    "        test_targets.append(targets.cpu().numpy())\n",
    "\n",
    "# 合并所有 batch 的结果\n",
    "test_predictions = np.concatenate(test_predictions)\n",
    "test_targets = np.concatenate(test_targets)\n",
    "\n",
    "# 计算测试集 MSE 和 R²（决定系数）\n",
    "from sklearn.metrics import r2_score\n",
    "test_mse = np.mean((test_predictions - test_targets) ** 2)\n",
    "test_r2 = r2_score(test_targets, test_predictions)\n",
    "\n",
    "print(f\"\\n测试集 MSE: {test_mse:.6f}\")\n",
    "print(f\"测试集 R²: {test_r2:.4f}\")\n",
    "\n",
    "# ================================\n",
    "# 9. 可视化真实值 vs 预测值\n",
    "# ================================\n",
    "# 为了可视化，我们按 x 排序\n",
    "# 获取所有测试数据的输入 x\n",
    "x_test = np.concatenate([x.cpu().numpy() for x, _ in test_loader])\n",
    "idx_sorted = np.argsort(x_test.flatten())\n",
    "\n",
    "x_sorted = x_test[idx_sorted]\n",
    "y_true_sorted = test_targets[idx_sorted]\n",
    "y_pred_sorted = test_predictions[idx_sorted]\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(x_test, test_targets, alpha=0.5, label='真实值', s=10)\n",
    "plt.plot(x_sorted, y_pred_sorted, color='red', linewidth=2, label='模型预测')\n",
    "plt.title('真实值 vs 模型预测')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ================================\n",
    "# 10. 保存模型\n",
    "# ================================\n",
    "torch.save(model.state_dict(), 'regression_model.pth')\n",
    "print(\"模型已保存: regression_model.pth\")\n",
    "\n",
    "# ================================\n",
    "# 11. 使用模型进行单个预测（推理）\n",
    "# ================================\n",
    "# 示例：预测 x = 2.5\n",
    "model.eval()\n",
    "x_new = torch.FloatTensor([[2.5]]).to(device)\n",
    "with torch.no_grad():\n",
    "    y_pred = model(x_new).cpu().numpy()\n",
    "\n",
    "print(f\"输入 x = 2.5，模型预测 y = {y_pred[0][0]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env]",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
