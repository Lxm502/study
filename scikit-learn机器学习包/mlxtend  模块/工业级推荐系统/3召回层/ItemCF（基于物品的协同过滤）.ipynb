{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fec25d3-8c49-401f-be3b-9aaf41260cac",
   "metadata": {},
   "source": [
    "# æ¨èç³»ç»Ÿä¸­çš„ ItemCFï¼ˆåŸºäºç‰©å“çš„ååŒè¿‡æ»¤ï¼‰\n",
    "## 1. ItemCFåŸºæœ¬æ¦‚å¿µ\n",
    "`ItemCF`ï¼ˆItem-Based Collaborative Filteringï¼‰æ˜¯`åŸºäºç‰©å“çš„ååŒè¿‡æ»¤ç®—æ³•`ï¼Œå…¶æ ¸å¿ƒæ€æƒ³æ˜¯ï¼š`å¦‚æœç”¨æˆ·å–œæ¬¢ç‰©å“Aï¼Œé‚£ä¹ˆä»–å¾ˆå¯èƒ½ä¹Ÿå–œæ¬¢ä¸Aç›¸ä¼¼çš„ç‰©å“`ã€‚\n",
    "\n",
    "- ä¸`UserCF`çš„åŒºåˆ«\n",
    "    - `UserCF`ï¼šæ‰¾åˆ°ç›¸ä¼¼ç”¨æˆ·ï¼Œæ¨èç›¸ä¼¼ç”¨æˆ·å–œæ¬¢çš„ç‰©å“\n",
    "    - `ItemCF`ï¼šæ‰¾åˆ°ç›¸ä¼¼ç‰©å“ï¼Œæ¨èä¸ç”¨æˆ·å†å²å–œå¥½ç›¸ä¼¼çš„ç‰©å“\n",
    "\n",
    "---\n",
    "## 2. ItemCFç®—æ³•åŸç†\n",
    "- æ ¸å¿ƒæ­¥éª¤: \\\n",
    "1.è®¡ç®—ç‰©å“ç›¸ä¼¼åº¦ \\\n",
    "2.æ ¹æ®ç”¨æˆ·å†å²è¡Œä¸ºå’Œç‰©å“ç›¸ä¼¼åº¦ç”Ÿæˆæ¨è\n",
    "\n",
    "---\n",
    "### æ ‡å‡†å®ç°æµç¨‹ï¼ˆé«˜å±‚ï¼‰\n",
    "\n",
    "1.å‡†å¤‡æ•°æ®ï¼ˆæ˜¾å¼è¯„åˆ†æˆ–éšå¼äº¤äº’ï¼‰ï¼Œæ„å»º ğ‘…ï¼ˆuser Ã— itemï¼‰ã€‚\n",
    "\n",
    "2.è®¡ç®— item-item ç›¸ä¼¼åº¦çŸ©é˜µ `sim`ï¼ˆæˆ–åªä¿ç•™æ¯ä¸ª item çš„ top-K ç›¸ä¼¼ç‰©å“ï¼‰ã€‚\n",
    "\n",
    "3.å¯¹æ¯ä¸ªç”¨æˆ·ï¼ŒåŸºäºå…¶å·²äº¤äº’ç‰©å“å’Œç›¸ä¼¼åº¦çŸ©é˜µè®¡ç®—å€™é€‰ç‰©å“åˆ†æ•°å¹¶æ’åºï¼ˆè¿‡æ»¤å·²äº¤äº’ï¼‰ã€‚\n",
    "\n",
    "4.è¯„ä¼°ï¼ˆRecall@K / NDCG@K / Precision@K ç­‰ï¼‰ï¼Œåœ¨éªŒè¯é›†ä¸­è°ƒå‚ï¼ˆtopKã€min_supportã€shrinkageã€ç›¸ä¼¼åº¦ç±»å‹ç­‰ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b878d7-857c-4a0d-aba1-5deccfedcc96",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. ItemCFå®ç°ç»†èŠ‚\n",
    "åŸºç¡€Pythonå®ç°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa336f0-a2cf-4087-8c4b-0f3bc2eead16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "\n",
    "class ItemCF:\n",
    "    def __init__(self, k=20, n_recommend=10):\n",
    "        self.k = k  # ç›¸ä¼¼ç‰©å“æ•°\n",
    "        self.n_recommend = n_recommend  # æ¨èç‰©å“æ•°\n",
    "        self.user_item_matrix = None\n",
    "        self.item_similarity = None\n",
    "        self.item_popularity = None\n",
    "        \n",
    "    def fit(self, user_item_data):\n",
    "        \"\"\"è®­ç»ƒæ¨¡å‹\"\"\"\n",
    "        # æ„å»ºç”¨æˆ·-ç‰©å“çŸ©é˜µ\n",
    "        self._build_user_item_matrix(user_item_data)\n",
    "        # è®¡ç®—ç‰©å“ç›¸ä¼¼åº¦\n",
    "        self._calculate_item_similarity()\n",
    "        # è®¡ç®—ç‰©å“æµè¡Œåº¦\n",
    "        self._calculate_item_popularity()\n",
    "        \n",
    "    def _build_user_item_matrix(self, data):\n",
    "        \"\"\"æ„å»ºç”¨æˆ·-ç‰©å“çŸ©é˜µ\"\"\"\n",
    "        users = sorted(set(data['user_id']))\n",
    "        items = sorted(set(data['item_id']))\n",
    "        \n",
    "        self.user_ids = {user: idx for idx, user in enumerate(users)}\n",
    "        self.item_ids = {item: idx for idx, item in enumerate(items)}\n",
    "        self.id_to_item = {idx: item for item, idx in self.item_ids.items()}\n",
    "        \n",
    "        # åˆ›å»ºçŸ©é˜µï¼ˆå¯ä»¥ä½¿ç”¨ç¨€ç–çŸ©é˜µä¼˜åŒ–ï¼‰\n",
    "        self.user_item_matrix = np.zeros((len(users), len(items)))\n",
    "        \n",
    "        for _, row in data.iterrows():\n",
    "            user_idx = self.user_ids[row['user_id']]\n",
    "            item_idx = self.item_ids[row['item_id']]\n",
    "            rating = row.get('rating', 1)  # éšå¼åé¦ˆé»˜è®¤ä¸º1\n",
    "            self.user_item_matrix[user_idx, item_idx] = rating\n",
    "    \n",
    "    def _calculate_item_similarity(self):\n",
    "        \"\"\"è®¡ç®—ç‰©å“ç›¸ä¼¼åº¦çŸ©é˜µ\"\"\"\n",
    "        # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦\n",
    "        self.item_similarity = cosine_similarity(self.user_item_matrix.T)\n",
    "        \n",
    "        # å°†å¯¹è§’çº¿è®¾ä¸º0ï¼ˆç‰©å“ä¸è‡ªèº«çš„ç›¸ä¼¼åº¦æ’é™¤ï¼‰\n",
    "        np.fill_diagonal(self.item_similarity, 0)\n",
    "    \n",
    "    def _calculate_item_popularity(self):\n",
    "        \"\"\"è®¡ç®—ç‰©å“æµè¡Œåº¦\"\"\"\n",
    "        self.item_popularity = np.sum(self.user_item_matrix > 0, axis=0)\n",
    "    \n",
    "    def recommend(self, user_id, filter_interacted=True):\n",
    "        \"\"\"ä¸ºç”¨æˆ·ç”Ÿæˆæ¨è\"\"\"\n",
    "        if user_id not in self.user_ids:\n",
    "            return self._recommend_for_cold_start()\n",
    "            \n",
    "        user_idx = self.user_ids[user_id]\n",
    "        user_interactions = self.user_item_matrix[user_idx]\n",
    "        \n",
    "        # è·å–ç”¨æˆ·äº¤äº’è¿‡çš„ç‰©å“\n",
    "        interacted_items = np.where(user_interactions > 0)[0]\n",
    "        \n",
    "        # è®¡ç®—é¢„æµ‹è¯„åˆ†\n",
    "        scores = np.zeros(self.user_item_matrix.shape[1])\n",
    "        \n",
    "        for item_idx in interacted_items:\n",
    "            # è·å–å½“å‰ç‰©å“çš„æœ€ç›¸ä¼¼ç‰©å“\n",
    "            similar_items = np.argsort(self.item_similarity[item_idx])[::-1][:self.k]\n",
    "            \n",
    "            for sim_item_idx in similar_items:\n",
    "                if filter_interacted and sim_item_idx in interacted_items:\n",
    "                    continue\n",
    "                    \n",
    "                similarity = self.item_similarity[item_idx, sim_item_idx]\n",
    "                rating = user_interactions[item_idx]\n",
    "                scores[sim_item_idx] += similarity * rating\n",
    "        \n",
    "        # å½’ä¸€åŒ–\n",
    "        for i in range(len(scores)):\n",
    "            if scores[i] > 0:\n",
    "                sim_sum = 0\n",
    "                for item_idx in interacted_items:\n",
    "                    sim_sum += abs(self.item_similarity[item_idx, i])\n",
    "                if sim_sum > 0:\n",
    "                    scores[i] /= sim_sum\n",
    "        \n",
    "        # è·å–æ¨èç‰©å“\n",
    "        recommended_items = np.argsort(scores)[::-1][:self.n_recommend]\n",
    "        \n",
    "        recommendations = []\n",
    "        for item_idx in recommended_items:\n",
    "            if scores[item_idx] > 0:\n",
    "                recommendations.append({\n",
    "                    'item_id': self.id_to_item[item_idx],\n",
    "                    'score': scores[item_idx],\n",
    "                    'popularity': self.item_popularity[item_idx]\n",
    "                })\n",
    "        \n",
    "        return recommendations\n",
    "    \n",
    "    def _recommend_for_cold_start(self):\n",
    "        \"\"\"å†·å¯åŠ¨ç”¨æˆ·æ¨èï¼ˆè¿”å›çƒ­é—¨ç‰©å“ï¼‰\"\"\"\n",
    "        popular_items = np.argsort(self.item_popularity)[::-1][:self.n_recommend]\n",
    "        return [{'item_id': self.id_to_item[idx], 'score': 0, 'popularity': self.item_popularity[idx]} \n",
    "                for idx in popular_items]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c78a80e-0f7a-481e-8c18-9ceacb11daa4",
   "metadata": {},
   "source": [
    "## 4. å®é™…åº”ç”¨ç¤ºä¾‹\n",
    "A. æ˜¾å¼è¯„åˆ† â€”â€” è°ƒæ•´ä½™å¼¦ ItemCFï¼ˆé€‚åˆè¯„åˆ†æ•°æ®ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6670376f-bf8f-42c1-acbd-71a045f556d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¾èµ–ï¼šnumpyã€pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def build_user_item_matrix(ratings_df, user_col='user', item_col='item', rating_col='rating'):\n",
    "    \"\"\"\n",
    "    è¿”å›ï¼š\n",
    "      R (np.array) shape=(n_users, n_items) å¡«å…… 0 è¡¨ç¤ºæœªè¯„åˆ†\n",
    "      user_idx, item_idx å­—å…¸æ˜ å°„ id -> ç´¢å¼•\n",
    "      users, items åˆ—è¡¨\n",
    "    \"\"\"\n",
    "    users = ratings_df[user_col].unique()\n",
    "    items = ratings_df[item_col].unique()\n",
    "    user_idx = {u:i for i,u in enumerate(users)}\n",
    "    item_idx = {j:i for i,j in enumerate(items)}\n",
    "    R = np.zeros((len(users), len(items)), dtype=float)\n",
    "    for _, row in ratings_df.iterrows():\n",
    "        R[user_idx[row[user_col]], item_idx[row[item_col]]] = row[rating_col]\n",
    "    return R, user_idx, item_idx, users, items\n",
    "\n",
    "def itemcf_adjusted_cosine_fit(R, eps=1e-9):\n",
    "    \"\"\"\n",
    "    R: numpy array shape (n_users, n_items), 0 è¡¨ç¤ºæœªè¯„åˆ†\n",
    "    è¿”å›ï¼šsimilarity çŸ©é˜µ shape (n_items, n_items)\n",
    "    \"\"\"\n",
    "    mask = (R != 0).astype(float)  # æ ‡è®°å·²è¯„åˆ†\n",
    "    # ç”¨æˆ·å‡å€¼ï¼ˆåªå¯¹å·²è¯„åˆ†æ±‚å¹³å‡ï¼‰\n",
    "    user_sum = R.sum(axis=1)\n",
    "    user_count = mask.sum(axis=1)\n",
    "    user_mean = np.divide(user_sum, user_count, out=np.zeros_like(user_sum), where=user_count!=0)\n",
    "    # å»å‡å€¼ï¼ˆä»…å¯¹å·²è¯„åˆ†ä½ç½®ï¼‰\n",
    "    R_centered = R - (user_mean[:, None] * mask)\n",
    "    # è®¡ç®—åæ–¹å·® / ä½™å¼¦åˆ†å­\n",
    "    numerator = R_centered.T.dot(R_centered)   # shape (n_items, n_items)\n",
    "    # åˆ†æ¯ï¼ˆæ¯ä¸ª item çš„å¹³æ–¹å’Œï¼‰\n",
    "    denom = np.sqrt(np.sum(R_centered**2, axis=0))  # length n_items\n",
    "    denom_matrix = denom[:, None] * denom[None, :] + eps\n",
    "    sim = numerator / denom_matrix\n",
    "    # å¯¹è§’ç½® 0\n",
    "    np.fill_diagonal(sim, 0.0)\n",
    "    return sim\n",
    "\n",
    "def recommend_itemcf_explicit(R, sim, user_index, top_k_neighbors=50, N=10):\n",
    "    \"\"\"\n",
    "    ä¸ºå•ä¸ªç”¨æˆ·ç”Ÿæˆ Top-N æ¨èï¼ˆæ˜¾å¼ï¼‰\n",
    "    - åªä½¿ç”¨è¯¥ç”¨æˆ·å·²è¯„åˆ†ç‰©å“çš„ top_k_neighbors ç›¸ä¼¼åº¦\n",
    "    \"\"\"\n",
    "    rated = np.where(R[user_index] != 0)[0]\n",
    "    if len(rated) == 0:\n",
    "        return []  # å†·å¯åŠ¨ï¼šæ²¡æœ‰å†å²\n",
    "    # è®¡ç®—åˆ†å­ï¼šsim[:, rated] dot (r_u_rated - mean_u)\n",
    "    user_mean = R[user_index, rated].mean()\n",
    "    R_centered_u = R[user_index, rated] - user_mean\n",
    "    # åªå–æ¯ä¸ª item çš„ top_k_neighbors é¿å…æ‰€æœ‰åˆ—éƒ½å‚ä¸ï¼ŒèŠ‚çœè®¡ç®— (å¯é€‰)\n",
    "    # è¿™é‡Œç®€å•ä½¿ç”¨å…¨éƒ¨ rated é¡¹çš„ç›¸ä¼¼åº¦å­çŸ©é˜µ\n",
    "    numer = sim[:, rated].dot(R_centered_u)\n",
    "    denom = np.abs(sim[:, rated]).sum(axis=1) + 1e-9\n",
    "    preds = user_mean + numer / denom\n",
    "    # æ’é™¤ç”¨æˆ·å·²è¯„åˆ†çš„é¡¹\n",
    "    preds[rated] = -np.inf\n",
    "    top_items = np.argsort(preds)[-N:][::-1]\n",
    "    return top_items  # è¿”å› item ç´¢å¼•åˆ—è¡¨\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8abc50-9ba7-44f0-8744-6f94041c1a19",
   "metadata": {},
   "source": [
    "ä½¿ç”¨è¯´æ˜ï¼š\\\n",
    "1.å…ˆæŠŠè¯„åˆ†è¡¨` ratings_df `è½¬æ¢ä¸ºçŸ©é˜µ` R`ï¼Œ \n",
    "\n",
    "2.è°ƒç”¨` itemcf_adjusted_cosine_fit(R) `å¾—åˆ°` sim`ï¼Œ\n",
    "\n",
    "3.ç„¶åå¯¹æ¯ä¸ªç”¨æˆ·è°ƒç”¨` recommend_itemcf_explicit `å¾—åˆ°` Top-N`ï¼ˆ`æŠŠ item `ç´¢å¼•æ˜ å°„å›` item id`ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cae1b7-e91a-40a2-b2f0-10d84c8c905b",
   "metadata": {},
   "source": [
    "---\n",
    "B. éšå¼äº¤äº’ï¼ˆbinary / ç‚¹å‡» / è´­ä¹°ï¼‰ â€”â€” å…±ç° + cosineï¼ˆå¸¸è§ï¼Œè¾ƒå¿«ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da80254-9120-4fe2-8213-cf6a4b50d8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def build_binary_matrix(interactions_df, user_col='user', item_col='item'):\n",
    "    users = interactions_df[user_col].unique()\n",
    "    items = interactions_df[item_col].unique()\n",
    "    u_idx = {u:i for i,u in enumerate(users)}\n",
    "    i_idx = {j:i for i,j in enumerate(items)}\n",
    "    rows = interactions_df[user_col].map(u_idx).values\n",
    "    cols = interactions_df[item_col].map(i_idx).values\n",
    "    data = np.ones(len(rows), dtype=np.float32)\n",
    "    R = csr_matrix((data, (rows, cols)), shape=(len(users), len(items)))\n",
    "    return R, u_idx, i_idx, users, items\n",
    "\n",
    "def itemcf_implicit_cosine(R_csr, topk=None, shrink=0, eps=1e-9):\n",
    "    \"\"\"\n",
    "    R_csr: scipy csr_matrix shape (n_users, n_items), binary or counts\n",
    "    è¿”å›ï¼šsim dense æˆ– sparseï¼ˆè‹¥ topk é None åˆ™è¿”å›ç¨€ç–å½¢å¼ï¼‰\n",
    "    å…¬å¼ï¼šsim = coocc / sqrt(pop_i * pop_j)\n",
    "    shrink: å¯é€‰æ”¶ç¼©é¡¹ï¼ˆå‡å°‘ä½å…±ç°å¯¹ç›¸ä¼¼åº¦çš„å½±å“ï¼‰\n",
    "    \"\"\"\n",
    "    # co-occurrence: item-item å…±ç°çŸ©é˜µ (n_items, n_items)\n",
    "    coocc = (R_csr.T).dot(R_csr)  # sparse matrix\n",
    "    # item popularity\n",
    "    pop = np.array(R_csr.sum(axis=0)).ravel()  # length n_items\n",
    "    denom = np.sqrt(np.outer(pop, pop)) + eps\n",
    "    sim = coocc.toarray() / denom\n",
    "    # shrinkage (ç®€å•ç¤ºä¾‹)\n",
    "    if shrink > 0:\n",
    "        sim = sim * (coocc.toarray() / (coocc.toarray() + shrink))\n",
    "    np.fill_diagonal(sim, 0.0)\n",
    "    if topk is not None:\n",
    "        # åªä¿ç•™æ¯è¡Œ topkï¼Œè½¬ä¸ºç¨€ç–\n",
    "        n_items = sim.shape[0]\n",
    "        rows, cols, vals = [], [], []\n",
    "        for i in range(n_items):\n",
    "            idx = np.argpartition(-sim[i], topk)[:topk]\n",
    "            for j in idx:\n",
    "                if sim[i,j] > 0:\n",
    "                    rows.append(i); cols.append(j); vals.append(sim[i,j])\n",
    "        from scipy.sparse import csr_matrix\n",
    "        sim_sparse = csr_matrix((vals, (rows, cols)), shape=sim.shape)\n",
    "        return sim_sparse\n",
    "    return sim  # dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de263abb-c64f-455e-ae38-e189c704f799",
   "metadata": {},
   "outputs": [],
   "source": [
    "æ¨èè®¡ç®—ï¼ˆéšå¼ï¼‰ï¼š\n",
    "\n",
    "# scores = R (n_users x n_items) dot sim (n_items x n_items) -> (n_users x n_items)\n",
    "# è‹¥ sim æ˜¯ç¨€ç–çŸ©é˜µï¼Œä½¿ç”¨ç¨€ç–ä¹˜æ³•é«˜æ•ˆè®¡ç®—\n",
    "scores = R_csr.dot(sim)  # è‹¥ sim ç¨€ç– csrï¼Œéœ€ sim è½¬ csc æˆ– csr è§†æƒ…å†µ\n",
    "# å¯¹æ¯ä¸ªç”¨æˆ·æŠŠå·²äº¤äº’çš„ç‰©å“ç½® 0ï¼Œç„¶åå– top-N"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87d1884-55a6-4604-ac9a-273a11a7a5c9",
   "metadata": {},
   "source": [
    "## 5.å·¥ç¨‹åŒ– & ä¼˜åŒ–æŠ€å·§ï¼ˆéå¸¸é‡è¦ï¼‰\n",
    "\n",
    "- åªä¿ç•™` top-K `ç›¸ä¼¼åº¦ï¼šå¯¹æ¯ä¸ª` item `åªå­˜` top 50~200 `ä¸ªç›¸ä¼¼` item`ï¼Œå¯æŠŠç›¸ä¼¼åº¦çŸ©é˜µå˜å¾—ç¨€ç–ï¼Œå†…å­˜å’Œè®¡ç®—éƒ½å¤§å¹…å‡å°‘ã€‚\n",
    "\n",
    "- Shrinkage / significance weightingï¼šå¯¹äºå…±ç°æ¬¡æ•°å°çš„` pair`ï¼Œç»™ç›¸ä¼¼åº¦æ‰“æŠ˜ï¼ˆé¿å…å™ªéŸ³ï¼‰ã€‚ä¾‹å¦‚ç”¨å…¬å¼ï¼šsim *= coocc / (coocc + shrink)ã€‚\n",
    "\n",
    "- å½’ä¸€åŒ–/å»åï¼šæ˜¾å¼è¯„åˆ†ç”¨` adjusted cosine `æˆ–` subtract user mean`ï¼›éšå¼å¯ç”¨` TF-IDF `é£æ ¼å¤„ç† `item`ï¼ˆæŠ‘åˆ¶è¶…æµè¡Œ itemï¼‰ã€‚\n",
    "\n",
    "- å¢é‡æ›´æ–°ï¼šå®Œæ•´é‡ç®—` item-item `éå¸¸æ…¢ï¼›ç”Ÿäº§ä¸Šå¸¸æŠŠ` coocc `è®¡æ•°ä¿å­˜å¹¶åªæ›´æ–°è¢«å½±å“çš„` item `å¯¹ï¼ˆç”¨æˆ·äº¤äº’é€šå¸¸åªå½±å“å°‘æ•° item çš„è¡Œ/åˆ—ï¼‰ã€‚\n",
    "\n",
    "- è¿‘é‚»æœç´¢åŠ é€Ÿï¼šå¯¹` item `å‘é‡ï¼ˆä¾‹å¦‚åŸºäº SVD / embeddingï¼‰ç”¨ ANNï¼ˆAnnoyã€Faissï¼‰åšè¿‘é‚»æ£€ç´¢ï¼Œé¿å… ğ‘‚(ğ‘š^2)çš„å…¨å¯¹æ¯”ã€‚\n",
    "\n",
    "- ç¨€ç–çŸ©é˜µä¹˜æ³•ï¼šç”¨ scipy.sparse åšä¹˜æ³•ï¼ˆscores = R * simï¼‰æ¯” dense å¿«ã€å†…å­˜å‹å¥½ã€‚\n",
    "\n",
    "- æ—¶é—´è¡°å‡ï¼šå¯¹äº¤äº’æŒ‰æ—¶é—´åŠ æƒï¼ˆæ–°äº¤äº’æƒé‡å¤§ï¼‰ï¼Œé˜²æ­¢å†å²è¡Œä¸ºä¸»å¯¼æ¨èã€‚\n",
    "\n",
    "- å»çƒ­é—¨ç‰©å“æƒ©ç½šï¼šé˜²æ­¢æ¨èæ€»æ˜¯çƒ­é—¨` top-N`ï¼ˆå¢åŠ æ–°å¥‡æ€§ã€ä¸ªæ€§åŒ–ï¼‰ã€‚\n",
    "\n",
    "---\n",
    "## 6.è¯„ä»·æ–¹å¼ï¼ˆç¦»çº¿å®éªŒï¼‰\n",
    "\n",
    "- åˆ’åˆ†æ–¹æ³•ï¼š`æŒ‰æ—¶é—´åˆ‡åˆ†`ï¼ˆtrain=train interactions before tï¼Œtest=åç»­äº¤äº’ï¼‰ï¼Œæ›´è´´è¿‘çº¿ä¸Šï¼›æˆ– leave-one-outï¼ˆæ¯ç”¨æˆ·ä¿ç•™ä¸€ä¸ªäº¤äº’ä¸ºæµ‹è¯•ï¼‰ã€‚\n",
    "\n",
    "- æŒ‡æ ‡ï¼šRecall@K / Precision@K / NDCG@K / MAP@K / HitRate@K / MRRã€‚\n",
    "\n",
    "- A/Bï¼šçº¿ä¸‹æŒ‡æ ‡æå‡ â‰  çº¿ä¸Šä¸šåŠ¡æå‡ï¼Œéœ€åšåœ¨çº¿å®éªŒéªŒè¯ï¼ˆCTRã€è½¬åŒ–ç‡ã€GMV ç­‰ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b969d-d2bb-467c-8c54-85d9187fad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def evaluate_itemcf(model, test_data, top_k=10):\n",
    "    \"\"\"è¯„ä¼°ItemCFæ¨¡å‹æ€§èƒ½\"\"\"\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    for user_id in test_data['user_id'].unique():\n",
    "        user_test_items = set(test_data[test_data['user_id'] == user_id]['item_id'])\n",
    "        \n",
    "        if len(user_test_items) == 0:\n",
    "            continue\n",
    "            \n",
    "        # ç”Ÿæˆæ¨è\n",
    "        recommendations = model.recommend(user_id)\n",
    "        recommended_items = set([rec['item_id'] for rec in recommendations[:top_k]])\n",
    "        \n",
    "        # è®¡ç®—å‡†ç¡®ç‡å’Œå¬å›ç‡\n",
    "        if len(recommended_items) > 0:\n",
    "            hit_items = user_test_items & recommended_items\n",
    "            \n",
    "            precision = len(hit_items) / len(recommended_items)\n",
    "            recall = len(hit_items) / len(user_test_items)\n",
    "            \n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "    \n",
    "    avg_precision = np.mean(precisions) if precisions else 0\n",
    "    avg_recall = np.mean(recalls) if recalls else 0\n",
    "    f1 = 2 * avg_precision * avg_recall / (avg_precision + avg_recall) if (avg_precision + avg_recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'precision@k': avg_precision,\n",
    "        'recall@k': avg_recall,\n",
    "        'f1@k': f1\n",
    "    }\n",
    "\n",
    "# ä½¿ç”¨ç¤ºä¾‹\n",
    "data = create_sample_data()\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "model = ItemCF(k=10, n_recommend=5)\n",
    "model.fit(train_data)\n",
    "\n",
    "metrics = evaluate_itemcf(model, test_data, top_k=3)\n",
    "print(\"æ¨¡å‹è¯„ä¼°ç»“æœ:\")\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d035d6-a4b6-404b-913d-7ec43258881f",
   "metadata": {},
   "source": [
    "---\n",
    "## 7.å¸¸è§é—®é¢˜ä¸å¯¹ç­–\n",
    "\n",
    "- æ–°ç”¨æˆ·å†·å¯åŠ¨ï¼šItemCF æ— å†å²åˆ™æ— æ³•å¬å›â€”â€”ç”¨å†·å¯åŠ¨ç­–ç•¥ï¼ˆçƒ­é—¨æ¦œã€åŸºäºå†…å®¹æˆ–å¼•å¯¼é—®å·ï¼‰ã€‚\n",
    "\n",
    "- æ–°ç‰©å“å†·å¯åŠ¨ï¼šItemCF éœ€è¦ç‰©å“æœ‰äº¤äº’æ‰èƒ½ä¸å…¶ä»–ç‰©å“å»ºç«‹è”ç³»â€”â€”ç”¨ç‰©å“å±æ€§åšæ··åˆï¼ˆcontent-based + ItemCFï¼‰ã€‚\n",
    "\n",
    "- é•¿å°¾ç‰©å“ç¨€ç–ï¼šå¯ä»¥åˆå¹¶åŒç±»ç›®ã€ç”¨ item embedding æˆ–å¢å¼ºæ•°æ®ï¼ˆç±»åˆ«èšåˆï¼‰æ¥ç¼“è§£ã€‚\n",
    "\n",
    "- æµè¡Œæ€§åå·®ï¼šå¯ç”¨ TF-IDFã€é€†æ–‡æ¡£é¢‘ç‡æˆ–å¯¹ç›¸ä¼¼åº¦æ‰“æŠ˜æ¥å¹³è¡¡ã€‚\n",
    "\n",
    "---\n",
    "## 8.ä¼˜ç¼ºç‚¹æ€»ç»“\n",
    "\n",
    "- ä¼˜ç‚¹ï¼šå®ç°ç®€å•ã€è§£é‡Šæ€§å¼ºï¼ˆèƒ½ç›´æ¥è¯´â€œå› ä¸ºä½ çœ‹è¿‡ Xï¼Œæ‰€ä»¥æ¨è Yâ€ï¼‰ã€å·¥ç¨‹åŒ–å®¹æ˜“ï¼ˆitem-item çŸ©é˜µå¯ç¦»çº¿è®¡ç®—å’Œç¼“å­˜ï¼‰ã€å¯¹ç¨€ç–æ€§è¾ƒ UserCF æ›´ç¨³å¥ã€‚\n",
    "\n",
    "- ç¼ºç‚¹ï¼šé¢å¯¹å†·å¯åŠ¨/æ–°ç‰©å“å¼±åŠ¿ï¼›è‹¥åªç”¨å…±ç°å®¹æ˜“äº§ç”Ÿçƒ­é—¨æ³¡æ²«ï¼›åœ¨æå¤§è§„æ¨¡ç‰©å“é›†ä¸Šè®¡ç®—ä»æœ‰æŒ‘æˆ˜ï¼ˆéœ€ç¨€ç–åŒ–/è¿‘ä¼¼ï¼‰ã€‚\n",
    "\n",
    "---\n",
    "## 9. è¿›é˜¶/å˜ä½“ï¼ˆæŒ‡è·¯ï¼‰\n",
    "\n",
    "- Implicit ALS / Matrix Factorizationï¼šå½“ç”¨æˆ·æˆ–ç‰©å“æ•°é‡æå¤§ï¼Œå› å­åˆ†è§£é€šå¸¸èƒ½å­¦åˆ°æ›´ä½ç»´çš„ item embeddingsï¼Œå¯ç”¨ ANN åšå¬å›æˆ–ç›´æ¥ç”¨å› å­ç›¸ä¼¼åº¦åš ItemCFã€‚\n",
    "\n",
    "- Session-based/Sequence-aware ItemCFï¼šå¯¹ session é¡ºåºæ•æ„Ÿçš„åœºæ™¯ï¼ˆçŸ­ä¼šè¯æ¨èï¼‰å¯ä»¥ç»“åˆåºåˆ—æ¨¡å‹ï¼ˆRNNã€Transformerï¼‰æˆ– session-based co-occurrenceã€‚\n",
    "\n",
    "- Graph-based æ–¹æ³•ï¼šæŠŠç”¨æˆ·å’Œç‰©å“çœ‹ä½œäºŒåˆ†å›¾ï¼Œç”¨å›¾ä¼ æ’­æˆ–éšæœºæ¸¸èµ°ï¼ˆe.g., LightGCNï¼‰æ›¿ä»£ä¼ ç»Ÿ ItemCFï¼Œæ•ˆæœé€šå¸¸æ›´å¥½ä½†å®ç°å¤æ‚ã€‚\n",
    "\n",
    "---\n",
    "## 10.å°ç»“ + å®è·µå»ºè®®\n",
    "\n",
    "- èµ·æ­¥ï¼šç”¨**éšå¼ ItemCFï¼ˆå…±ç° + cosineï¼‰**å¿«é€Ÿä¸Šçº¿ä¸€ä¸ª baselineï¼ˆå®ç°å¿«ï¼Œæ•ˆæœç¨³ï¼‰ã€‚\n",
    "\n",
    "- è‹¥è¦æå‡æ•ˆæœï¼šå¯¹æ˜¾å¼è¯„åˆ†é‡‡ç”¨ adjusted cosineï¼›åŠ  top-Kã€shrinkageã€æ—¶é—´è¡°å‡ä¸å»æµè¡Œæ€§ç­–ç•¥ã€‚\n",
    "\n",
    "- å¤§è§„æ¨¡ï¼šæŠŠç›¸ä¼¼åº¦çŸ©é˜µç¨€ç–åŒ–å¹¶ç”¨è¿‘é‚»æ£€ç´¢/embedding åšå¬å› + å†ç”¨æ’åºæ¨¡å‹ï¼ˆLearning-to-Rankï¼‰åšæœ€ç»ˆæ’åºã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e763e543-72eb-481e-be8c-60f0a5f27ec4",
   "metadata": {},
   "source": [
    "---\n",
    "## åº”ç”¨ç¤ºä¾‹ ï¼šç”µå½±æ¨èç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29024d1-8e61-49c6-a3dc-a77aee485017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# åˆ›å»ºç¤ºä¾‹æ•°æ®\n",
    "def create_sample_data():\n",
    "    \"\"\"åˆ›å»ºç”µå½±è¯„åˆ†ç¤ºä¾‹æ•°æ®\"\"\"\n",
    "    data = {\n",
    "        'user_id': [1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5],\n",
    "        'item_id': [101, 102, 103, 104, 101, 102, 105, 103, 104, 106, 102, 105, 107, 101, 108],\n",
    "        'rating': [5, 4, 3, 2, 4, 5, 3, 4, 3, 5, 4, 2, 3, 5, 4]\n",
    "    }\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# ä½¿ç”¨ItemCFè¿›è¡Œæ¨è\n",
    "def movie_recommendation_example():\n",
    "    # å‡†å¤‡æ•°æ®\n",
    "    data = create_sample_data()\n",
    "    print(\"åŸå§‹æ•°æ®:\")\n",
    "    print(data)\n",
    "    \n",
    "    # è®­ç»ƒæ¨¡å‹\n",
    "    item_cf = ItemCF(k=3, n_recommend=5)\n",
    "    item_cf.fit(data)\n",
    "    \n",
    "    # ä¸ºç”¨æˆ·ç”Ÿæˆæ¨è\n",
    "    for user_id in [1, 2, 3, 4, 5]:\n",
    "        recommendations = item_cf.recommend(user_id)\n",
    "        print(f\"\\nç”¨æˆ· {user_id} çš„æ¨è:\")\n",
    "        for rec in recommendations:\n",
    "            print(f\"ç”µå½±{rec['item_id']}: è¯„åˆ†{rec['score']:.3f}, æµè¡Œåº¦{rec['popularity']}\")\n",
    "    \n",
    "    # åˆ†æç‰©å“ç›¸ä¼¼åº¦\n",
    "    print(\"\\nç‰©å“ç›¸ä¼¼åº¦çŸ©é˜µ:\")\n",
    "    similarity_df = pd.DataFrame(\n",
    "        item_cf.item_similarity,\n",
    "        index=item_cf.item_ids.keys(),\n",
    "        columns=item_cf.item_ids.keys()\n",
    "    )\n",
    "    print(similarity_df.round(3))\n",
    "\n",
    "# è¿è¡Œç¤ºä¾‹\n",
    "movie_recommendation_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepseek_env]",
   "language": "python",
   "name": "conda-env-deepseek_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
