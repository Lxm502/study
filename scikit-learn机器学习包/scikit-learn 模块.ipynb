{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1440034f-7346-4a22-9cfa-5a40f0523563",
   "metadata": {},
   "source": [
    "# scikit-learn 模块\n",
    "它封装了大量经典机器学习算法，接口统一、易于使用、适合入门和工程实践。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e6f828-1808-42d7-acfa-e73cc1c89c2f",
   "metadata": {},
   "source": [
    "## 常见功能一览"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d34efc-ad15-4636-9f25-4785bbf82db7",
   "metadata": {},
   "source": [
    "| 模块                        | 用途          | 示例算法 / 工具                             |\n",
    "| ------------------------- | ----------- | ------------------------------------- |\n",
    "| `sklearn.datasets`        | 内置数据集加载     | `load_iris()`、`load_digits()`         |\n",
    "| `sklearn.model_selection` | 数据划分、交叉验证   | `train_test_split()`、`GridSearchCV()` |\n",
    "| `sklearn.preprocessing`   | 特征预处理       | 标准化、归一化、独热编码                          |\n",
    "| `sklearn.linear_model`    | 线性模型（分类、回归） | 线性回归、逻辑回归                             |\n",
    "| `sklearn.tree`            | 决策树         | `DecisionTreeClassifier`              |\n",
    "| `sklearn.ensemble`        | 集成模型（强模型）   | 随机森林、梯度提升                             |\n",
    "| `sklearn.svm`             | 支持向量机       | `SVC`, `SVR`                          |\n",
    "| `sklearn.neighbors`       | K 近邻模型      | `KNeighborsClassifier`                |\n",
    "| `sklearn.cluster`         | 聚类算法        | `KMeans`                              |\n",
    "| `sklearn.metrics`         | 模型评估指标      | 精度、召回率、ROC                            |\n",
    "| `sklearn.pipeline`        | 构建 ML 流水线   | 数据清洗 + 模型训练组合                         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2551ebc-6f76-4842-a54d-4b4290423e07",
   "metadata": {},
   "source": [
    "## 1.sklearn.datasets\n",
    "加载内置的标准数据集（如鸢尾花、手写数字、波士顿房价等），以及 生成用于测试的随机数据集，非常适合机器学习建模练习、算法测试与教学使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567ac4dd-7d2a-4f86-bd05-03aa0c98948f",
   "metadata": {},
   "source": [
    "### 常见功能分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546d886e-a8a1-414a-bd55-78554c71e10f",
   "metadata": {},
   "source": [
    "| 类型        | 功能          | 常用函数                                                              |\n",
    "| --------- | ----------- | ----------------------------------------------------------------- |\n",
    "| 加载小型经典数据集 | 内置的、适合教学和实验 | `load_iris`, `load_digits`, `load_breast_cancer`, `load_diabetes` |\n",
    "| 加载大型真实数据集 | 从网上下载并缓存    | `fetch_20newsgroups`, `fetch_california_housing`                  |\n",
    "| 人工生成数据集   | 生成可控特征结构    | `make_classification`, `make_regression`, `make_blobs`            |\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b7be37a-29df-4d48-abdf-d890fa3b9f69",
   "metadata": {},
   "source": [
    "函数对应的——————>  数据集\n",
    "\n",
    "鸢尾花: load_iris\n",
    "手写数字识别： load_digits\n",
    "乳腺癌数据： load_breast_cancer\n",
    "糖尿病回归数据： load_diabetes\n",
    "20类新闻文本数据集（文本分类）： fetch_20newsgroups\n",
    "加利福尼亚房价数据集（回归）： fetch_california_housing\n",
    "生成分类数据集: make_classification\n",
    "生成回归数据集: make_regression\n",
    "生成聚类用的 blob 数据: make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc42b4e1-87db-472d-b0a6-975638b78ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829bebb6-1737-48cd-8d06-f1b76a2e7aa6",
   "metadata": {},
   "source": [
    "| 参数              | 说明           |\n",
    "| --------------- | ------------ |\n",
    "| `n_samples`     | 样本数量         |\n",
    "| `n_features`    | 特征数量         |\n",
    "| `n_informative` | 有信息量的特征数量    |\n",
    "| `n_classes`     | 类别数量（2 是二分类） |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9469034e-b2ad-48d7-9ecf-b12eb1f3229a",
   "metadata": {},
   "source": [
    "# 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2d618b-66dc-4ee5-8be9-ceb4e5cee92a",
   "metadata": {},
   "source": [
    "| 类别   | 函数                                                                      | 应用方向    |\n",
    "| ---- | ----------------------------------------------------------------------- | ------- |\n",
    "| 分类数据 | `load_iris`, `load_digits`, `load_breast_cancer`, `make_classification` | 多种分类练习  |\n",
    "| 回归数据 | `load_diabetes`, `fetch_california_housing`, `make_regression`          | 回归建模    |\n",
    "| 文本数据 | `fetch_20newsgroups`                                                    | NLP 预处理 |\n",
    "| 聚类数据 | `make_blobs`                                                            | 无监督学习测试 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7af403-9702-458c-a9d1-9c39415dcf51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd6b707c-ada9-46a2-9364-5eed15f2c893",
   "metadata": {},
   "source": [
    "# 2.sklearn.model_selection\n",
    "是 Scikit-learn 中 模型选择与验证的重要模块，用于 划分训练/测试集、交叉验证、网格搜索超参数调优等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5b2fc4-8e91-4ec5-a115-ac92f62f2959",
   "metadata": {},
   "source": [
    "## 常用功能速览"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb9c4ed-10e4-476d-9ba6-b26be2ede399",
   "metadata": {},
   "source": [
    "| 功能类型 | 常用函数                                | 说明                |\n",
    "| ---- | ----------------------------------- | ----------------- |\n",
    "| 数据划分 | `train_test_split`                  | 随机将数据分成训练集和测试集    |\n",
    "| 交叉验证 | `cross_val_score`, `cross_validate` | 多次划分数据，验证模型性能稳定性  |\n",
    "| 分层划分 | `StratifiedKFold`                   | 保证每折中各类别比例一致      |\n",
    "| 网格搜索 | `GridSearchCV`                      | 枚举超参数组合，寻找最优      |\n",
    "| 随机搜索 | `RandomizedSearchCV`                | 随机选择部分组合搜索，提高效率   |\n",
    "| 学习曲线 | `learning_curve`                    | 查看样本数量变化对模型的影响    |\n",
    "| 验证曲线 | `validation_curve`                  | 查看某超参数的不同取值对模型的影响 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3027acda-a667-43d5-a2c8-356633f657fd",
   "metadata": {},
   "source": [
    "## 2.1. 数据集划分 — train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05d48862-24f6-4380-9aaa-373ad75f5a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,shuffle=True,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a0cdb4-057a-4f8b-87d6-844204c39958",
   "metadata": {},
   "source": [
    "| 参数名            | 含义                                |\n",
    "| -------------- | --------------------------------- |\n",
    "| `X`            | 特征数据（通常是 DataFrame 或 ndarray）     |\n",
    "| `y`            | 标签数据（1D 数组或 Series）               |\n",
    "| `test_size`    | 测试集所占比例或数量（如 0.2 表示 20%，或直接填整数数量） |\n",
    "| `train_size`   | 训练集所占比例或数量（与 `test_size` 二选一填写即可） |\n",
    "| `random_state` | 随机种子（使每次分割结果一致）                   |\n",
    "| `shuffle`      | 是否在分割前打乱数据（默认为 `True`）            |\n",
    "| `stratify`     | 用于分类问题，按类别比例分层抽样（如：`stratify=y`）  |\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "002a73f8-e87a-4f5c-8339-22af732a26d4",
   "metadata": {},
   "source": [
    "X 是特征（输入数据），y 是标签（目标值）。\n",
    "\n",
    "stratify = y 表示按标签 y 的类别分布进行“等比例划分”，确保训练集和测试集中各类别占比一致。\n",
    "stratify=y 中的 y 必须是一维可迭代对象，且为分类标签；\n",
    "如果 y 中某类样本太少，且你划分比例太小，可能会报错：The least populated class in y has only 1 member，这时需要调小 test_size 或去掉 rare 类别。\n",
    "\n",
    "✅ 返回值：\n",
    "train_test_split 会返回和输入一样数量的数据对象：\n",
    "\n",
    "如果输入 X, y：返回 X_train, X_test, y_train, y_test\n",
    "如果输入 X1, X2, ..., y：会将每个输入都拆分为训练与测试两部分\n",
    "\n",
    "⚠️ 注意事项：\n",
    "不要在测试集上 .fit() 模型，否则会造成数据泄露。\n",
    "若是不平衡分类问题，推荐设置 stratify=y 保证类别分布一致。\n",
    "可通过 train_size 精确指定训练集大小（与 test_size 相对）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbb058d-df53-4cb3-bfd6-51701f363bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6579bc5a-b5a7-42fd-bc42-57156898089a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3efd4a8c-c674-43eb-9e19-0896bbf01afd",
   "metadata": {},
   "source": [
    "## 2.2. 交叉验证 — cross_val_score\n",
    "🔹 作用：对数据进行 K 折划分，每次用 K-1 份数据训练模型，剩下的 1 份验证，重复 K 次，返回每次验证的得分（如准确率、MSE、AUC 等）。\n",
    "\n",
    "🔹 作用： \\\n",
    "只用于评估模型在交叉验证下的表现，不涉及参数调优。\n",
    "\n",
    "✅ 典型使用场景： \\\n",
    "初步比较多个模型（如逻辑回归、决策树、随机森林）的泛化能力 \\\n",
    "观察模型在不同数据划分下的得分稳定性 \\\n",
    "快速测试某个模型的大致表现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "227aac78-6eb6-42e9-84d0-78a634f6e918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每折得分: [0.815 0.835 0.78  0.72  0.765]\n",
      "平均得分: 0.7829999999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "scores = cross_val_score(model, X, y, cv=5) # cv=5：5折交叉验证（将数据分为5份，每次1份做验证，其余做训练）\n",
    "print(\"每折得分:\", scores)\n",
    "print(\"平均得分:\", scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b45fe0-221e-47b7-8fed-a51839af5edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "📌 一、基本语法\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator, X, y=None, *, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', error_score=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479959fa-876f-4197-b260-41a8106e8559",
   "metadata": {},
   "source": [
    "| 参数名               | 类型                     | 含义                                                                                                    |\n",
    "| ----------------- | ---------------------- | ----------------------------------------------------------------------------------------------------- |\n",
    "| **estimator**     | 对象                     | 要评估的模型，例如 `LogisticRegression()`，必须实现 `.fit()` 和 `.predict()` 方法                                      |\n",
    "| **X**             | array-like             | 特征数据集                                                                                                 |\n",
    "| **y**             | array-like 或 None      | 标签数据；回归任务中为连续变量，分类任务为类别标签                                                                             |\n",
    "| **scoring**       | 字符串 或 callable         | 指定评估指标，如 `\"accuracy\"`、`\"f1\"`、`\"roc_auc\"`，默认使用模型的 `.score()` 方法                                        |\n",
    "| **cv**            | int、交叉验证生成器 或 iterable | 交叉验证策略，如：<br> - int: `cv=5` 表示 K 折交叉验证（K=5）<br> - `StratifiedKFold`、`KFold` 等对象<br> - 自定义划分索引（可传索引列表） |\n",
    "| **n\\_jobs**       | int                    | 并行数：<br> - `1`：单线程（默认）<br> - `-1`：使用所有核心<br> - `>1`：指定核心数                                             |\n",
    "| **verbose**       | int                    | 日志冗长度，默认为 0                                                                                           |\n",
    "| **fit\\_params**   | dict                   | 传递给 estimator `.fit()` 的其他参数（如早停、权重等）                                                                 |\n",
    "| **pre\\_dispatch** | int 或 str              | 控制并行任务的调度策略，默认 `'2*n_jobs'`                                                                           |\n",
    "| **error\\_score**  | float 或 ‘raise’        | 若出错时得分：<br> - `'raise'` 抛出异常<br> - `np.nan`（默认）将出错模型的得分设为 NaN                                         |\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6148d5c2-1ff0-4ad0-ba8f-e1f07e3fbff7",
   "metadata": {},
   "source": [
    "🎯 二、常用 scoring 选项\n",
    "分类任务常用：\n",
    "\"accuracy\"：准确率（默认）\n",
    "\"precision\"、\"recall\"：精确率/召回率\n",
    "\"f1\"：F1 分数\n",
    "\"roc_auc\"：AUC 分数（二分类）\n",
    "\n",
    "回归任务常用：\n",
    "\"neg_mean_squared_error\"  --> 代表的是负的均方误差（−MSE）. 更高的分数表示更好的模型性能\n",
    "\"neg_mean_absolute_error\" --> 它是平均绝对误差 (MAE) 的负值, 分数越高（越接近 0 的负数），模型性能越好。\n",
    "\"r2\"：R² 分数（拟合优度）--> 你的模型比“瞎猜”（比如总是预测平均值）好多少？ 0 < R² < 1: R² 越接近 1，拟合效果越好。\n",
    "注意：某些回归指标会返回“负数”以符合“越大越好”的策略。例如 neg_mean_squared_error 实际 MSE 是其绝对值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d656e691-2c8a-4174-8d16-23597c27a0ac",
   "metadata": {},
   "source": [
    "#### 🎯 2.1. 常用 scoring 评估指标举例\n",
    "| 模型类型 | 指标名称    | scoring值                              |\n",
    "| ---- | ------- | ------------------------------------- |\n",
    "| 分类   | 准确率     | `'accuracy'`                          |\n",
    "| 分类   | ROC-AUC | `'roc_auc'`                           |\n",
    "| 分类   | F1 分数   | `'f1'`, `'f1_macro'`, `'f1_weighted'` |\n",
    "| 回归   | MSE     | `'neg_mean_squared_error'`            |\n",
    "| 回归   | R²      | `'r2'`                                |\n",
    "\n",
    "⚠️ 注意：回归中的误差类指标都是“负数”，如 neg_mean_squared_error，因为 Scikit-learn 所有得分都是 越大越好，所以误差项要加负号。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57063780-2377-4798-ae4c-56e2342eb3ce",
   "metadata": {},
   "source": [
    "### 🧩 一图概览区别\n",
    "\n",
    "| 特性 / 方法     | `cross_val_score` | `GridSearchCV`                      | `RandomizedSearchCV`                |\n",
    "| ----------- | ----------------- | ----------------------------------- | ----------------------------------- |\n",
    "| ✅ 功能        | 模型评估              | 模型调参 + 评估                           | 模型调参 + 评估                           |\n",
    "| 🔄 参数搜索     | ❌ 不支持             | ✅ 网格搜索（穷举）                          | ✅ 随机搜索                              |\n",
    "| 📊 交叉验证     | ✅ 支持              | ✅ 支持（默认 5 折）                        | ✅ 支持（默认 5 折）                        |\n",
    "| ⚙️ 搜索范围     | 不涉及参数             | 所有组合都会尝试                            | 随机抽样固定次数                            |\n",
    "| 🕰️ 计算速度    | 快                 | 慢（组合多时计算量大）                         | 快（可控制尝试次数）                          |\n",
    "| 🔍 是否返回最佳参数 | ❌                 | ✅ `best_params_`, `best_estimator_` | ✅ `best_params_`, `best_estimator_` |\n",
    "| 🎯 使用目标     | 评估模型稳定性或泛化能力      | 精调模型参数                              | 快速调参、粗调阶段                           |\n",
    "\n",
    "### 🚀 总结：三者使用建议\n",
    "\n",
    "| 目的      | 推荐方法                 | 原因              |\n",
    "| ------- | -------------------- | --------------- |\n",
    "| 评估模型表现  | `cross_val_score`    | 简洁高效，适合初步评估多个模型 |\n",
    "| 小范围精调   | `GridSearchCV`       | 搜索全面，能找出最优参数组合  |\n",
    "| 大范围快速调参 | `RandomizedSearchCV` | 效率高，适合初期探索性调参   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20764d54-2313-4b3c-b4d7-f6abc6ca51bc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e1d0ac-d70c-4658-bf06-751236ea4a33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64ce7993-8621-436e-8241-06d03c451559",
   "metadata": {},
   "source": [
    "## 2.3. 网格搜索 — GridSearchCV\n",
    "#### 用于系统地搜索（遍历）超参数的最佳组合,精细调参神器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e084208f-48cd-4bb2-89e4-538fd71b3ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最优参数: {'C': 10, 'kernel': 'rbf'}\n",
      "最优得分: 0.9425000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC  # 训练的模型\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "grid = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"最优参数:\", grid.best_params_)\n",
    "print(\"最优得分:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740b174c-0942-4017-92eb-8bb23a6fe0dc",
   "metadata": {},
   "source": [
    "### 📌 一、基本用法语法"
   ]
  },
  {
   "cell_type": "raw",
   "id": "87c927fe-33af-4041-a1d2-35ab5127807c",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "\n",
    "grid_search = GridSearchCV(estimator, param_grid, *, scoring=None, cv=None, \n",
    "                           n_jobs=None, verbose=0, refit=True, return_train_score=False, ...) \n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba8f0d4-66df-4291-a012-9fd5984c48a1",
   "metadata": {},
   "source": [
    "| 参数名                      | 类型                  | 说明                                                                        |\n",
    "| ------------------------ | ------------------- | ------------------------------------------------------------------------- |\n",
    "| **estimator**            | 对象                  | 要调参的模型，比如 `SVC()`、`RandomForestClassifier()`，必须实现 `.fit()` 和 `.predict()` |\n",
    "| **param\\_grid**          | dict 或 list of dict | 参数网格：<br> - `{'C':[0.1,1,10], 'kernel':['linear','rbf']}`<br> - 支持多个参数组合  |\n",
    "| **scoring**              | str 或 callable      | 模型评估指标，如 `'accuracy'`, `'f1'`, `'roc_auc'`, `'neg_mean_squared_error'` 等  |\n",
    "| **cv**                   | int 或 CV 生成器        | 指定交叉验证的方式，例如：<br> - `cv=5` 表示 5 折交叉验证<br> - `StratifiedKFold(n_splits=5)` |\n",
    "| **n\\_jobs**              | int                 | 并行运行数：<br> - `-1` 使用所有CPU核<br> - `1` 单线程                                  |\n",
    "| **verbose**              | int                 | 控制输出的详细程度：<br> - `0`: 静默<br> - `1`: 简单输出<br> - `2`: 显示每个参数组合的评估过程         |\n",
    "| **refit**                | bool 或 str          | 训练完成后是否用最佳参数组合重新训练一个完整模型<br> - `True`：使用最佳参数重新训练<br> - `'f1'`：根据某个指标选最优   |\n",
    "| **return\\_train\\_score** | bool                | 是否在 `cv_results_` 中返回训练集得分，默认 `False`                                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b819003-6241-4fc0-aced-bd0a85f797cf",
   "metadata": {},
   "source": [
    "### ✅ 二、常用属性（模型训练后）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb3dd37-18e1-492b-a27b-56051eb0db07",
   "metadata": {},
   "source": [
    "| 属性名               | 类型        | 含义                                                                                                                  |\n",
    "| ----------------- | --------- | ------------------------------------------------------------------------------------------------------------------- |\n",
    "| `best_params_`    | dict      | 最优参数组合                                                                                                              |\n",
    "| `best_score_`     | float     | 最佳交叉验证得分                                                                                                            |\n",
    "| `best_estimator_` | estimator | 最佳模型（相当于 refit 后的模型）                                                                                                |\n",
    "| `cv_results_`     | dict      | 所有参数组合的交叉验证结果，包含：<br> - `mean_test_score`<br> - `mean_train_score`（若 `return_train_score=True`）<br> - `params`：对应参数 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c161ca-ed40-4c3c-a869-1b84e7d9c907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "352b0885-ff09-4768-bda7-516b1e02b1a6",
   "metadata": {},
   "source": [
    "## 2.4. 随机搜索 — RandomizedSearchCV\n",
    "#### 从参数分布中随机采样一定数量的组合，适用于参数组合非常多时，避免全排列计算过慢。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "957c6a50-43cc-46c6-8038-6f770508991f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [3, 5, 10, None],\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000019D82E729C0&gt;})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomizedSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [3, 5, 10, None],\n",
       "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000019D82E729C0&gt;})</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: RandomForestClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_estimators=145)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_estimators=145)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "                   param_distributions={'max_depth': [3, 5, 10, None],\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x0000019D82E729C0>})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {'n_estimators': randint(10, 200), 'max_depth': [3, 5, 10, None]}\n",
    "random_search = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_dist, n_iter=10, cv=5)\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445991cc-c151-406d-8f42-37fb9174d231",
   "metadata": {},
   "source": [
    "### 📌 一、基本语法"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59d91a1f-3e20-4fc7-863b-481121c41776",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator, param_distributions, \n",
    "    n_iter=10, scoring=None, \n",
    "    n_jobs=None, cv=None, \n",
    "    verbose=0, random_state=None, \n",
    "    return_train_score=False, refit=True\n",
    ")\n",
    "search.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69625c0b-d0ef-4960-aabe-9593f051b0a1",
   "metadata": {},
   "source": [
    "| 参数                       | 类型             | 说明                                                                                                              |\n",
    "| ------------------------ | -------------- | --------------------------------------------------------------------------------------------------------------- |\n",
    "| **estimator**            | 模型对象           | 要调参的模型，如 `RandomForestClassifier()`、`SVC()`，必须实现 `.fit()` 方法                                                    |\n",
    "| **param\\_distributions** | dict           | 参数分布（或取值列表）：<br> - 如：`{'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}`<br> - 或者可传概率分布（如 `scipy.stats.uniform`） |\n",
    "| **n\\_iter**              | int            | 随机采样的参数组合数（总共尝试几组）                                                                                              |\n",
    "| **scoring**              | str 或 callable | 模型评分方式，如 `'accuracy'`, `'f1'`, `'roc_auc'`                                                                      |\n",
    "| **cv**                   | int 或 CV生成器    | 交叉验证的折数，如 `cv=5` 表示 5 折                                                                                         |\n",
    "| **n\\_jobs**              | int            | 并行数：<br> - `-1` 使用全部核心<br> - `1` 单线程                                                                            |\n",
    "| **verbose**              | int            | 控制输出详细程度                                                                                                        |\n",
    "| **random\\_state**        | int            | 控制随机性（确保每次运行结果可复现）                                                                                              |\n",
    "| **refit**                | bool 或 str     | 是否在搜索结束后用最优参数重新训练                                                                                               |\n",
    "| **return\\_train\\_score** | bool           | 是否返回训练集得分                                                                                                       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792db38b-67a9-4e3c-b17c-b86cf31c595e",
   "metadata": {},
   "source": [
    "### ✅ 二、常用属性（与 GridSearchCV 相同）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f3c244-97d3-41a2-98cf-f830422cad3f",
   "metadata": {},
   "source": [
    "| 属性名               | 类型    | 含义                   |\n",
    "| ----------------- | ----- | -------------------- |\n",
    "| `best_params_`    | dict  | 最优参数组合               |\n",
    "| `best_score_`     | float | 最佳交叉验证得分             |\n",
    "| `best_estimator_` | 模型    | 最佳模型对象               |\n",
    "| `cv_results_`     | dict  | 所有搜索结果（每次采样对应得分、参数等） |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d37e38-f5ad-4588-b6e2-0467cf4c6b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7f1ea12-f268-429b-80aa-1ceb26933ca2",
   "metadata": {},
   "source": [
    "## 2.5. K 折交叉验证划分器 — KFold、StratifiedKFold\n",
    "用于在模型评估中将数据划分为训练集与验证集，主要区别在于是否保持类别比例（即标签的分布）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df15ed79-f01f-4b4e-ac16-0ce81a50b17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.model_selection import KFold\\n\\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\\nfor train_index, test_index in kf.split(X):\\n    print(\"Train:\", train_index, \"Test:\", test_index)\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"Train:\", train_index, \"Test:\", test_index)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421b04d0-0df2-4ad2-b36a-53dab6e0ec7e",
   "metadata": {},
   "source": [
    "### 📌 一、KFold\n",
    "✅ 概念  \\\n",
    "KFold 将数据集等量地划分成 K 个子集（folds），每次选择其中一个作为验证集，剩下的作为训练集，不考虑标签分布。\n",
    "\n",
    "🧩 适用场景  \\\n",
    "--: 回归问题  \\\n",
    "--: 分类问题中类别分布比较均匀\n",
    "\n",
    "#### 📘 使用方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c0b405-9dd6-473f-a4ee-30bb171a710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966e7038-6693-4bd7-8b6c-cc60a48827fd",
   "metadata": {},
   "source": [
    "| 参数             | 说明                             |\n",
    "| -------------- | ------------------------------ |\n",
    "| `n_splits`     | 拆成几折（K）                        |\n",
    "| `shuffle`      | 是否在划分前打乱数据（默认 False）           |\n",
    "| `random_state` | 控制打乱的随机性（当 `shuffle=True` 时有效） |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6042b5f9-4fac-4ae5-8124-837b63173709",
   "metadata": {},
   "source": [
    "# 📌 二、StratifiedKFold\n",
    "✅ 概念  \\\n",
    "是 分层 K 折交叉验证 方法，主要用于分类任务。其核心特点是确保每一折中各类别的样本比例与原始数据集保持一致，特别适用于处理类别不平衡的数据集。\n",
    "\n",
    "📌 核心特点 \\\n",
    "1、分层抽样：保持每折数据的类别分布与原始数据集一致 \\\n",
    "2、分类任务专用：适用于分类问题（回归任务通常用 KFold） \\\n",
    "3、解决类别不平衡：防止某折中漏掉少数类样本\n",
    "\n",
    "#### 📘 使用方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb989d2-2a1f-489e-ba9a-069dcc97cde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(\n",
    "    n_splits=5,  # 折数 默认5折\n",
    "    shuffle=True,  # 是否打乱数据\n",
    "    random_state=42)  # 随机种子\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "🧩注意：split(X, y) 必须传入标签 y，因为它需要按照标签进行分层。\n",
    "       数据泄漏风险：若使用 shuffle=True，确保在数据预处理（如标准化）之后再打乱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67061be7-0295-41bd-b496-39e7a0915007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9a04bd3-3f44-44dd-9d45-6c5e7c1a7ced",
   "metadata": {},
   "source": [
    "### KFold vs StratifiedKFold 对比总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15d889c-970f-4cae-9f28-1bfb2563ff75",
   "metadata": {},
   "source": [
    "| 特性             | `KFold` | `StratifiedKFold` |\n",
    "| -------------- | ------- | ----------------- |\n",
    "| 是否保持类别比例       | ❌ 否     | ✅ 是               |\n",
    "| 是否适合不平衡分类      | ❌ 不推荐   | ✅ 推荐              |\n",
    "| 是否适合回归任务       | ✅ 推荐    | ❌ 不适合             |\n",
    "| 是否需要传入 y       | ❌ 不需要   | ✅ 必须传入            |\n",
    "| 是否有 shuffle 参数 | ✅ 有     | ✅ 有               |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeab2e4-3026-4de7-9e86-181ae4443735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ada04be-7fea-43f7-91c4-5958586bc44a",
   "metadata": {},
   "source": [
    "# 2.6. 学习曲线 — learning_curve\n",
    "用于绘制 学习曲线 ，帮助判断模型的过拟合或欠拟合情况，以及是否需要更多的数据或更复杂的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b20af3-0b59-4eec-ab8b-6d2d4b83edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_sizes, train_scores, val_scores = learning_curve(LogisticRegression(), X, y, cv=5)\n",
    "\n",
    "plt.plot(train_sizes, train_scores.mean(axis=1), label='Train')\n",
    "plt.plot(train_sizes, val_scores.mean(axis=1), label='Validation')\n",
    "plt.legend()\n",
    "plt.title(\"学习曲线\")\n",
    "plt.xlabel(\"训练样本数\")\n",
    "plt.ylabel(\"得分\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdeb1e52-d827-47dd-9d3f-3568c3b56b90",
   "metadata": {},
   "source": [
    "### 🧠 一、什么是学习曲线？\n",
    "学习曲线展示了训练集大小变化对模型性能的影响，通常包含两条线： \\\n",
    "📈 训练得分曲线：表示模型在训练集上的表现  \\\n",
    "📉 验证得分曲线：表示模型在交叉验证上的表现  \\\n",
    "通过对比两条曲线，可以判断模型的状态："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbeb045-0359-43a6-99d9-61cf3acd070b",
   "metadata": {},
   "source": [
    "| 情况   | 表现          | 原因         | 解决方案          |\n",
    "| ---- | ----------- | ---------- | ------------- |\n",
    "| 欠拟合  | 训练、验证得分都低   | 模型太简单      | 换更复杂模型/特征工程   |\n",
    "| 过拟合  | 训练得分高，验证得分低 | 模型太复杂/数据太少 | 正则化/简化模型/多拿数据 |\n",
    "| 拟合良好 | 两条曲线靠近，得分高  | 正常         | ✅             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5191d5-46b2-42cd-9582-c344f324418e",
   "metadata": {},
   "source": [
    "### 🧪 二、基本语法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be94c04c-aa9b-43f9-992e-c4c36cb99615",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    estimator, X, y, *,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "    cv=None, scoring=None, n_jobs=None, shuffle=False,\n",
    "    random_state=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234a00db-da6e-4928-9df9-2a1e5e96cc56",
   "metadata": {},
   "source": [
    "| 参数                | 类型             | 说明                                                        |\n",
    "| ----------------- | -------------- | --------------------------------------------------------- |\n",
    "| **estimator**     | 模型对象           | 要评估的模型（如 `SVC()`, `RandomForestClassifier()` 等）           |\n",
    "| **X, y**          | 特征与标签          | 数据集                                                       |\n",
    "| **train\\_sizes**  | array          | 训练集比例列表，例如 `np.linspace(0.1, 1.0, 5)` 表示使用 10%-100% 的训练数据 |\n",
    "| **cv**            | int 或 CV生成器    | 指定交叉验证方式，如 `cv=5`、`StratifiedKFold()`                     |\n",
    "| **scoring**       | str 或 callable | 评估指标，如 `'accuracy'`, `'f1'`, `'neg_mean_squared_error'`   |\n",
    "| **n\\_jobs**       | int            | 并行运行数，`-1` 为使用全部核心                                        |\n",
    "| **shuffle**       | bool           | 是否在划分训练集前打乱数据                                             |\n",
    "| **random\\_state** | int            | 随机种子（用于 `shuffle=True`）                                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e96d2e9-fc4e-49f5-9cf0-824a851d9291",
   "metadata": {},
   "source": [
    "###  ✅ 三、返回值说明\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d4fc61-8cb9-4674-813f-64b65c56c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes      # 每次使用的训练样本数\n",
    "train_scores     # 每次训练得分，shape=(len(train_sizes), n_cv_folds)\n",
    "test_scores      # 每次验证得分，shape=(len(train_sizes), n_cv_folds)\n",
    "\n",
    "你通常会对它们取平均和标准差来绘图。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623a4e08-85f7-44cf-baf4-f26b2c8861fb",
   "metadata": {},
   "source": [
    "### 📊 四、绘图示例（完整）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e06c1b-c999-4661-984c-79f84ebef166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 加载数据\n",
    "X, y = load_digits(return_X_y=True)\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# 计算学习曲线数据\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    model, X, y, cv=5,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    scoring='accuracy', n_jobs=-1\n",
    ")\n",
    "\n",
    "# 计算平均分和标准差\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# 绘图\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_sizes, train_mean, 'o-', color='r', label='Training score')\n",
    "plt.plot(train_sizes, test_mean, 'o-', color='g', label='Cross-validation score')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='r', alpha=0.1)\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color='g', alpha=0.1)\n",
    "plt.xlabel(\"Training Set Size\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55426257-bc77-45bf-b3ea-c68c4d57a630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "512b8adc-2849-461f-b5ae-c9317fa3064a",
   "metadata": {},
   "source": [
    "# 2.7. 验证曲线 — validation_curve\n",
    "用于绘制 验证曲线 ，用来研究某个超参数的不同取值如何影响模型性能，从而帮助你选择最佳超参数，避免过拟合或欠拟合。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cf45a3-0ee9-47fc-ade2-8f38298eabe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "param_range = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "train_scores, val_scores = validation_curve(\n",
    "    LogisticRegression(), X, y, param_name='C', param_range=param_range, cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9749f9b-ff7f-40b1-852a-3754164c0dab",
   "metadata": {},
   "source": [
    "### 🧠 一、什么是验证曲线？\n",
    "验证曲线反映了模型性能随着某个特定超参数变化的趋势，可视化训练分数与交叉验证分数随超参数变化而变化的情况。\n",
    "\n",
    "💡 对比学习曲线（关注样本数量），验证曲线关注的是** “某个参数值” 对模型的影响 **。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d17962-3c1c-4d7b-b579-02daf2de3598",
   "metadata": {},
   "source": [
    "### 📌 二、函数语法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dadc9ed-a47e-4d68-9e58-6e8da3b3c4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    estimator, X, y,\n",
    "    param_name, param_range,\n",
    "    cv=None, scoring=None, n_jobs=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2e1bae-587c-4194-a570-4e85025153ba",
   "metadata": {},
   "source": [
    "| 参数名              | 类型             | 说明                                          |\n",
    "| ---------------- | -------------- | ------------------------------------------- |\n",
    "| **estimator**    | 模型对象           | 要评估的模型，如 `SVC()`、`RandomForestClassifier()` |\n",
    "| **X, y**         | array-like     | 训练数据与标签                                     |\n",
    "| **param\\_name**  | str            | 要评估的超参数名称（字符串），如 `'max_depth'`、`'C'`        |\n",
    "| **param\\_range** | array-like     | 要尝试的超参数取值列表或数组                              |\n",
    "| **cv**           | int 或 CV对象     | 交叉验证的折数                                     |\n",
    "| **scoring**      | str 或 callable | 性能评估指标，如 `'accuracy'`、`'f1'`                |\n",
    "| **n\\_jobs**      | int            | 并行运行个数，`-1` 表示使用全部 CPU 核                    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf66a2f-15b8-4ef3-b50e-5b5b27a2b8da",
   "metadata": {},
   "source": [
    "### ✅ 三、返回值"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bea736-16c9-4628-a92d-9eacfeed1dee",
   "metadata": {},
   "source": [
    "| 返回值            | 类型                                          | 说明                |\n",
    "| -------------- | ------------------------------------------- | ----------------- |\n",
    "| `train_scores` | array, shape=(len(param\\_range), n\\_splits) | 每个参数值下，交叉验证中训练集得分 |\n",
    "| `test_scores`  | array, shape=(len(param\\_range), n\\_splits) | 每个参数值下，交叉验证中验证集得分 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109a09c9-5241-4fa4-85a6-ea04e8e1dac4",
   "metadata": {},
   "source": [
    "### 📊 四、绘图示例（完整代码）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9298afb4-c2de-486a-9d7f-949c10112c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 加载数据\n",
    "X, y = load_digits(return_X_y=True)\n",
    "\n",
    "# 指定模型 & 参数\n",
    "model = RandomForestClassifier(random_state=0)\n",
    "param_name = \"max_depth\"\n",
    "param_range = np.arange(1, 15)\n",
    "\n",
    "# 计算验证曲线\n",
    "train_scores, test_scores = validation_curve(\n",
    "    model, X, y,\n",
    "    param_name=param_name,\n",
    "    param_range=param_range,\n",
    "    cv=5, scoring=\"accuracy\", n_jobs=-1\n",
    ")\n",
    "\n",
    "# 平均和标准差\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# 绘图\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(param_range, train_mean, label=\"Training score\", color=\"r\")\n",
    "plt.plot(param_range, test_mean, label=\"Cross-validation score\", color=\"g\")\n",
    "plt.fill_between(param_range, train_mean - train_std, train_mean + train_std, alpha=0.2, color=\"r\")\n",
    "plt.fill_between(param_range, test_mean - test_std, test_mean + test_std, alpha=0.2, color=\"g\")\n",
    "plt.title(\"Validation Curve\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cead5b93-2da5-4c77-aa96-919580b775bd",
   "metadata": {},
   "source": [
    "### 🎯 五、典型用途\n",
    "调整单个超参数（如 C, gamma, max_depth, n_neighbors）\n",
    "\n",
    "检查某参数是否太小（欠拟合）或太大（过拟合）\n",
    "\n",
    "选择最佳参数范围（用于后续 GridSearchCV/RandomizedSearchCV）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86690a03-3739-4e9d-a315-d43685d1b75d",
   "metadata": {},
   "source": [
    "###  🧠六、如何解读验证曲线？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f24904-ce6e-4831-8de2-457177a85747",
   "metadata": {},
   "source": [
    "| 现象           | 含义   | 建议                |\n",
    "| ------------ | ---- | ----------------- |\n",
    "| 训练分数和验证分数都低  | 欠拟合  | 增加模型复杂度           |\n",
    "| 训练分数高，验证分数低  | 过拟合  | 减少模型复杂度，或增加数据/正则化 |\n",
    "| 训练和验证分数都高且接近 | 拟合良好 | ✅                 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2ece16-0d79-4add-bc93-d650a54c6677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd620bad-320a-47bc-ab6a-49e41757026e",
   "metadata": {},
   "source": [
    "# 🧠 2.8.sklearn.model_selection 总结表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7370d051-609b-4035-973f-4b2a0823dbd3",
   "metadata": {},
   "source": [
    "| 任务    | 函数                         | 说明            |\n",
    "| ----- | -------------------------- | ------------- |\n",
    "| 划分数据集 | `train_test_split`         | 划分训练与测试集      |\n",
    "| 模型打分  | `cross_val_score`          | 快速交叉验证打分      |\n",
    "| 模型验证  | `cross_validate`           | 多输出（时间/得分）    |\n",
    "| 网格调参  | `GridSearchCV`             | 穷举组合找最佳超参数    |\n",
    "| 随机调参  | `RandomizedSearchCV`       | 采样部分参数组合      |\n",
    "| 学习曲线  | `learning_curve`           | 分析训练样本量对性能的影响 |\n",
    "| 验证曲线  | `validation_curve`         | 分析超参数对模型的影响   |\n",
    "| K折    | `KFold`, `StratifiedKFold` | 自定义数据分折方式     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f2eba5-4330-4268-b486-3cf3fb44d3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8edf9e8d-40be-4a02-b5e1-5471a0fc04d3",
   "metadata": {},
   "source": [
    "# 3.sklearn.preprocessing \n",
    "是 Scikit-learn 中用于 特征预处理 的重要模块，它包含了多种标准化、归一化、编码、离散化等工具，帮助我们将原始数据转换为更适合模型训练的格式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b3ae27-c139-41f7-89f6-aca0a1911a4e",
   "metadata": {},
   "source": [
    "## 模块用途总览"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a130e7c-c52b-478c-aecc-a4b5cefa8b92",
   "metadata": {},
   "source": [
    "| 功能类别   | 代表方法                                     | 简述             |\n",
    "| ------ | ---------------------------------------- | -------------- |\n",
    "| 数值缩放   | `StandardScaler`, `MinMaxScaler`         | 标准化/归一化数值特征    |\n",
    "| 特征转换   | `PolynomialFeatures`, `PowerTransformer` | 特征扩展/非线性变换     |\n",
    "| 类别编码   | `OneHotEncoder`, `LabelEncoder`          | 将类别变量转换为数值型    |\n",
    "| 缺失值填充  | `SimpleImputer`                          | 替换缺失值          |\n",
    "| 二值/离散化 | `Binarizer`, `KBinsDiscretizer`          | 数值特征转换为离散/分类变量 |\n",
    "| 特征选择   | `FunctionTransformer`                    | 自定义函数进行特征变换    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cd669c-8000-4c3d-9971-aa507a3f37df",
   "metadata": {},
   "source": [
    "## 3.1. StandardScaler\n",
    "对特征进行 标准化（均值为0，方差为1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488d4714-ddae-42ee-860b-b75ed075b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # X 是二维特征数组\n",
    "\n",
    "⚠️适用于：大多数模型，如线性回归、SVM、KNN、逻辑回归等"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f78c230-e5c2-4e4e-823a-62ef96dc49f0",
   "metadata": {},
   "source": [
    "### 📌 一、作用说明\n",
    "StandardScaler 会将特征转换为 均值为 0，标准差为 1 的标准正态分布，也称为 Z-score 标准化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaad285-04d6-42fc-9dcc-43833b521e19",
   "metadata": {},
   "source": [
    "### 🧠 二、为什么使用 StandardScaler？\n",
    "🚀 提升模型表现：许多模型（如 SVM、KNN、逻辑回归、神经网络）对特征的尺度敏感\n",
    "\n",
    "⚖️ 加速收敛：梯度下降类模型在特征值缩放一致后更容易收敛\n",
    "\n",
    "🧮 避免某些特征主导模型：当特征量级差距大时，模型可能偏向大数值的特征"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26de7f6-e5bc-4c3d-b444-7437c352d2a8",
   "metadata": {},
   "source": [
    "### 📘 三、用法示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d4f2cc-edb4-4999-bc5a-2de08fdf7ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# 假设数据\n",
    "X = np.array([[1, 2],\n",
    "              [3, 4],\n",
    "              [5, 6]])\n",
    "\n",
    "# 创建标准化对象\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 拟合并转换数据\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"原始数据：\\n\", X)\n",
    "print(\"标准化后：\\n\", X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f1e600-c403-4172-8b89-a28b26fa4b97",
   "metadata": {},
   "source": [
    "###  四、常用方法和属性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eef8df-4b93-438f-aa78-bcc23d212e76",
   "metadata": {},
   "source": [
    "| 方法 / 属性                        | 说明                             |\n",
    "| ------------------------------ | ------------------------------ |\n",
    "| `.fit(X)`                      | 计算均值和标准差（不转换数据）                |\n",
    "| `.transform(X)`                | 使用已有参数转换新数据                    |\n",
    "| `.fit_transform(X)`            | 等同于先 `.fit()` 再 `.transform()` |\n",
    "| `.inverse_transform(X_scaled)` | 将标准化后的数据还原回原始值                 |\n",
    "| `.mean_`                       | 每列特征的均值                        |\n",
    "| `.scale_`                      | 每列特征的标准差（实际是 `std_`）           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33a6938-f317-4781-8817-ad87d83865a4",
   "metadata": {},
   "source": [
    "### ✅ 五、应用于训练 + 测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5fbe87-65da-4d02-82ea-0428fc5a5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)  # 注意：只能用训练集拟合的参数来转换测试集！\n",
    "⚠️ 不要在测试集上调用 .fit()，否则会造成数据泄露！"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ea788dcc-64c0-4540-909c-f8ea38cd7a8b",
   "metadata": {},
   "source": [
    "📌 一、什么是“数据泄露”（Data Leakage）？\n",
    "数据泄露是指在模型训练或调参过程中，测试集中的信息被提前使用，导致模型对测试集的评估结果不真实（过于乐观），最终泛化能力下降。\n",
    "\n",
    "🎯 二、StandardScaler 中的泄露是什么？\n",
    "🔍 问题描述：\n",
    "# 错误示范\n",
    "scaler = StandardScaler()\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n",
    "\n",
    "这样做的后果是：\n",
    "你让 StandardScaler 在 测试集上计算了均值和标准差，\n",
    "这些 测试集的信息（μ, σ）参与了模型构建流程，\n",
    "这就等于“看了一眼考试答案后再考试”，虽然你没有用 y_test（测试标签），但你用了 X_test 的分布信息。\n",
    "\n",
    "✅ 三、正确的标准化流程（训练集拟合 → 测试集转换）\n",
    "# 正确做法\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)   # ✅ 拟合 + 转换训练集\n",
    "X_test_scaled = scaler.transform(X_test)         # ✅ 用训练集得出的 μ 和 σ 转换测试集\n",
    "\n",
    "🧠 原因：\n",
    ".fit()：会计算 μ（均值）和 σ（标准差）\n",
    ".transform()：使用已有的 μ 和 σ 来转换数据\n",
    "✅ 正确的逻辑是：\n",
    "你在训练集上得到数据的特征分布 → 用这些分布来处理新数据（测试集）\n",
    "就像你在现实中用旧数据训练模型，然后把它应用到从未见过的数据上一样。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ceb7577b-71ee-4144-9c05-f142fe37eb00",
   "metadata": {},
   "source": [
    "📊 四、一个数值例子帮你理解\n",
    "假设我们有如下训练集和测试集：\n",
    "\n",
    "X_train = [[10], [12], [14]]\n",
    "X_test = [[100]]\n",
    "\n",
    "# 正确流程：\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  # 得到 μ=12, σ=2\n",
    "scaler.transform(X_test) = [[(100 - 12)/2]] = [[44.0]]\n",
    "\n",
    "# 错误流程：\n",
    "scaler.fit_transform(X_test) → μ=100, σ=0 → 会返回 [[0.0]]\n",
    "\n",
    "错误流程让测试数据看起来“太完美”，误导了评估。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5920174d-727d-44bf-bd5d-658b386b8416",
   "metadata": {},
   "source": [
    "🧪 五、在交叉验证、GridSearch 中如何避免泄露？\n",
    "使用 Pipeline，它能确保每次交叉验证中：\n",
    "只对训练折 .fit() Scaler\n",
    "对验证折 .transform()，不泄露未来信息\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv=5)  # 自动避免泄露\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1abdd4-37ba-49f9-9c81-8adb836f74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "✅ 六、总结：防止数据泄露的关键点"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797f0a18-d9fc-4f19-a722-1d2021a6a9fa",
   "metadata": {},
   "source": [
    "| 操作阶段      | 正确行为                            | 错误行为（造成泄露）                          |\n",
    "| --------- | ------------------------------- | ----------------------------------- |\n",
    "| 特征缩放      | 训练集 `.fit()`，测试集 `.transform()` | 在测试集上 `.fit()` 或 `.fit_transform()` |\n",
    "| 特征选择 / 降维 | 训练集上选择特征，再应用于测试集                | 在所有数据上选择特征                          |\n",
    "| 交叉验证      | 使用 `Pipeline` 或分步骤手动处理          | 在划分前全体 `.fit()`                     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a83420-750a-4967-a492-8186dff77672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85cdfbd7-9efd-408d-afe8-4d1e282906a5",
   "metadata": {},
   "source": [
    "### 🔄 六、在 Pipeline 中使用\n",
    "Pipeline 是 sklearn 提供的一种 将多个数据处理步骤串联起来 的工具。它能保证： \\\n",
    "每一步按照正确顺序执行（如：标准化 → 降维 → 模型）  \\\n",
    "在交叉验证或网格搜索时避免数据泄露"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc74f403-c6ca-459b-a84c-752f93f96969",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "pipe.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bb3241-9161-4964-b781-0d8da34471cb",
   "metadata": {},
   "source": [
    "### 📊 七、StandardScaler 与其他缩放方法对比"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43363cd-c8ae-454e-98f7-9ce2d1e52709",
   "metadata": {},
   "source": [
    "| 方法               | 模块                      | 适用情况                              |\n",
    "| ---------------- | ----------------------- | --------------------------------- |\n",
    "| `StandardScaler` | `sklearn.preprocessing` | 将数据标准化为均值 0 方差 1，适用于大多数模型         |\n",
    "| `MinMaxScaler`   | `sklearn.preprocessing` | 将数据缩放到 \\[0,1] 区间，适用于分布已知或不含异常值的特征 |\n",
    "| `RobustScaler`   | `sklearn.preprocessing` | 使用中位数与四分位距，**适合异常值多**的数据          |\n",
    "| `Normalizer`     | `sklearn.preprocessing` | 将每一行样本标准化（而不是每一列特征），多用于文本/距离类模型   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f801be-2389-4e76-94e9-fe551f0c45fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73507c36-6c3d-4c38-9eaf-dbf7bcfb186a",
   "metadata": {},
   "source": [
    "## 3.2. MinMaxScaler\n",
    "是 Scikit-learn 中常用的特征缩放方法之一，它会将特征缩放到一个指定的最小值和最大值之间（通常是 [0, 1]）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f40b219-b2ac-4b47-a764-c8759f83cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "⚠️适用于：对范围敏感的模型（如神经网络）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56d595b-bec6-4d41-bee8-3192c03e3d32",
   "metadata": {},
   "source": [
    "### 🔧 一、MinMaxScaler 的作用\n",
    "✅ 主要用途： \\\n",
    "将每个特征缩放到相同的范围，避免特征之间因为量纲不同而影响模型效果。\n",
    "\n",
    "### 📐 二、缩放公式\n",
    "\n",
    "X_scaled = (X - X_min) / (X_max - X_min)  \\\n",
    "其中：  \\\n",
    "X_min: 特征的最小值  \\\n",
    "X_max: 特征的最大值  \\\n",
    "缩放后，所有特征值 ∈ [0, 1]（默认情况下）\n",
    "\n",
    "也可以指定范围：\n",
    "\n",
    "MinMaxScaler(feature_range=(a, b))  \\\n",
    "将数据缩放到 [a, b] 范围。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f875878e-e785-4627-804b-d0ef3e43d3c0",
   "metadata": {},
   "source": [
    "### 🧪 三、使用示例\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8ab138-bdf2-4837-825f-78b6cb3f8b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# 假设这是原始数据（2个特征）\n",
    "X = np.array([[1, 10],\n",
    "              [2, 20],\n",
    "              [3, 30]])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(X_scaled)\n",
    "\n",
    "输出结果：\n",
    "\n",
    "[[0.  0. ]\n",
    " [0.5 0.5]\n",
    " [1.  1. ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae04248-7f18-4aec-979c-1a42ddd18f4b",
   "metadata": {},
   "source": [
    "### 🧱 四、常见属性和方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6281732-343b-4eed-bc47-14353cada001",
   "metadata": {},
   "source": [
    "| 属性 / 方法                        | 说明           |\n",
    "| ------------------------------ | ------------ |\n",
    "| `.fit(X)`                      | 计算 min 和 max |\n",
    "| `.transform(X)`                | 应用缩放         |\n",
    "| `.fit_transform(X)`            | 一步完成         |\n",
    "| `.inverse_transform(X_scaled)` | 还原回原始值       |\n",
    "| `.data_min_`, `.data_max_`     | 保存的最小最大值     |\n",
    "| `feature_range=(min, max)`     | 自定义缩放范围      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a357b5-b4ad-4cd9-b988-8005477f03fd",
   "metadata": {},
   "source": [
    "### ❗ 五、注意事项\n",
    "🚫 不要在测试集上调用 .fit()！  \\\n",
    "因为 .fit() 会计算 min 和 max，若在测试集上使用会导致数据泄露。\n",
    "\n",
    "正确做法：\n",
    "\n",
    "scaler = MinMaxScaler()  \\\n",
    "X_train_scaled = scaler.fit_transform(X_train)   # 在训练集上拟合并转换  \\\n",
    "X_test_scaled = scaler.transform(X_test)         # 只对测试集转换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70c1b1f-f92e-4bd9-9776-499c7aacf491",
   "metadata": {},
   "source": [
    "### 📊 六、与其他缩放器对比"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d80255-8f3d-4030-ac7c-4acfce67f318",
   "metadata": {},
   "source": [
    "| 方法               | 说明                    | 是否受异常值影响 |\n",
    "| ---------------- | --------------------- | -------- |\n",
    "| `StandardScaler` | 使特征服从标准正态分布 N(0,1)    | ✅ 敏感     |\n",
    "| `MinMaxScaler`   | 将特征缩放到 \\[0,1]（或自定义范围） | ✅ 敏感     |\n",
    "| `RobustScaler`   | 使用中位数和四分位数缩放          | ❌ 不敏感    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3e5f50-c4d5-40c0-9d6e-0ad4dd4be826",
   "metadata": {},
   "source": [
    "### ✅ 七、适用场景\n",
    "--:  图像数据（像素值需在 [0,1]） \\\n",
    "--:  神经网络模型（对输入值敏感）\\\n",
    "--:  特征值范围差异很大时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd158c8-046d-4c1f-8b03-709b5f9c01a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66e027cf-0ef8-401b-afc0-563acdffff8c",
   "metadata": {},
   "source": [
    "## 3.3. OneHotEncoder\n",
    "是 Scikit-learn 中用于**将分类变量转换为独热编码（One-Hot Encoding）**的工具，适合将文本标签（如 \"red\", \"blue\", \"green\"）转化为数值特征，供模型处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0737dc07-5470-4ec2-935c-3ce4f513699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "X_encoded = encoder.fit_transform([['red'], ['green'], ['blue']])\n",
    "\n",
    "⚠️与 pd.get_dummies() 功能类似，适用于：树模型、线性模型、神经网络等"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10ef23c-fc23-43b9-902e-f9afc2188bc1",
   "metadata": {},
   "source": [
    "### 🛠️ 一、基本用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5df331-270b-4cbe-8259-0a3ca6da6f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([[\"red\"], [\"green\"], [\"blue\"], [\"green\"]])\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoded = encoder.fit_transform(data)\n",
    "\n",
    "# 默认输出是稀疏矩阵，若要转成数组：\n",
    "print(encoded.toarray())\n",
    "\n",
    "输出：\n",
    "\n",
    "[[0. 0. 1.]  # red\n",
    " [0. 1. 0.]  # green\n",
    " [1. 0. 0.]  # blue\n",
    " [0. 1. 0.]] # green\n",
    "注意：列的顺序是按字母顺序排列的（blue, green, red）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d93f9e-00c6-4fe0-b82b-dca035174859",
   "metadata": {},
   "source": [
    "### ⚙️ 二、常用参数\n",
    "| 参数                       | 说明                                |\n",
    "| ------------------------ | --------------------------------- |\n",
    "| `sparse=True`            | 是否返回稀疏矩阵（节省内存）                    |\n",
    "| `handle_unknown='error'` | 测试集出现新类别时的处理方式（默认报错）              |\n",
    "| `drop=None`              | 是否删除某个类别，防止多重共线性（比如设置为 `'first'`） |\n",
    "| `dtype=np.float64`       | 输出数据的类型                           |\n",
    "\n",
    "\n",
    "                                # 设置为返回稠密数组 + 新类别忽略\n",
    "                                encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05316da-ad09-4183-a6a8-464cb1aa7fb7",
   "metadata": {},
   "source": [
    "### 🔁 三、常用方法\n",
    "| 方法                        | 说明          |\n",
    "| ------------------------- | ----------- |\n",
    "| `fit(X)`                  | 拟合编码器       |\n",
    "| `transform(X)`            | 对数据进行编码     |\n",
    "| `fit_transform(X)`        | 一步完成        |\n",
    "| `get_feature_names_out()` | 查看每一列对应的编码名 |\n",
    "\n",
    "\n",
    "                                                encoder.get_feature_names_out()\n",
    "                                                # 输出示例：['x0_blue' 'x0_green' 'x0_red']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd52e685-4e14-4a83-a466-32243d4b3d83",
   "metadata": {},
   "source": [
    "### ⚠️ 四、数据泄露问题注意\n",
    "和所有预处理一样，不能在测试集上调用 .fit()。正确方式：\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore') \\\n",
    "X_train_enc = encoder.fit_transform(X_train)  \\\n",
    "X_test_enc = encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631b85ab-c97f-4184-adb3-202a82a17a72",
   "metadata": {},
   "source": [
    "### 🔄 五、与 pd.get_dummies() 的对比\n",
    "| 特点            | `OneHotEncoder` | `pd.get_dummies()` |\n",
    "| ------------- | --------------- | ------------------ |\n",
    "| 可用于 Pipelines | ✅ 是             | ❌ 不是               |\n",
    "| 支持稀疏矩阵        | ✅               | ❌                  |\n",
    "| 支持未知类别处理      | ✅               | ❌                  |\n",
    "| 自动处理多列        | ✅               | ✅                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569f9c04-d8d7-4158-96ae-cba057c65a1b",
   "metadata": {},
   "source": [
    "### 🧱 六、示例：配合 ColumnTransformer 使用\n",
    "ColumnTransformer 针对数据框中的不同列应用不同的转换方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72187720-0b40-4da6-b33d-3cfe1b3a0f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer  \n",
    "from sklearn.pipeline import Pipeline  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 假设有分类特征列0和数值列1\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), [0])\n",
    "    ],\n",
    "    remainder='passthrough'  # 其他列原样保留\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('pre', preprocessor),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f5514d-8721-4c2b-a045-d1f257c9e6da",
   "metadata": {},
   "source": [
    "### ✅ 七、 总结 OneHotEncoder 适用场景\n",
    "--> 适用于非数值的分类变量  \\\n",
    "--> 必须用于对模型 ** 不接受类别变量（如线性模型、神经网络）** 的场景  \\\n",
    "--> 可与 Pipeline、ColumnTransformer 一起灵活处理结构化数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427e2e6c-694c-4235-84ae-7a605ec790a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f882c30d-1f8e-46a0-aaff-88b94dffeb2b",
   "metadata": {},
   "source": [
    "## 3.4. LabelEncoder\n",
    "是 Scikit-learn 提供的一种将类别型标签（target 值）编码为数字的工具，常用于将分类模型的目标变量（如 \"yes\"/\"no\"、\"cat\"/\"dog\" 等）转换为可用于训练的整数形式。\n",
    "\n",
    "✅ 使用场景\\\n",
    "通常用于 类别标签转为整数（仅限目标值 y） 的编码。 \\\n",
    "不推荐用于特征变量（X）中的非数值类别特征 —— 这种场景应使用 OneHotEncoder 或 OrdinalEncoder。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ad8d96-b62c-4086-bb04-274c60a621b6",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(['spam', 'ham', 'spam', 'ham'])\n",
    "\n",
    "⚠️注意：不能用于 X 特征的多列编码！只适合单标签向量 y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8755c1ea-e2c1-4715-8d92-93f8cdfd3a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "✅ 常见用法\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = ['dog', 'cat', 'dog', 'fish']\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "print(y_encoded)\n",
    "# 输出示例: [1 0 1 2]\n",
    "print(le.classes_)\n",
    "# 输出: ['cat' 'dog' 'fish']\n",
    "\n",
    "编码结果是按字母顺序排序后的索引：cat→0, dog→1, fish→2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd0c284-0700-4bf1-9286-7f6492f482a0",
   "metadata": {},
   "source": [
    "✅ 方法说明\n",
    "| 方法                             | 说明               |\n",
    "| ------------------------------ | ---------------- |\n",
    "| `fit(y)`                       | 拟合标签（仅建立映射，不转换）  |\n",
    "| `transform(y)`                 | 将标签转为数字          |\n",
    "| `fit_transform(y)`             | 拟合并转换            |\n",
    "| `inverse_transform(y_encoded)` | 将数字转换回原始标签       |\n",
    "| `classes_`                     | 存储所有标签对应的类名（排序后） |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb32016-87ef-40fa-a8c8-5d7c026f6c46",
   "metadata": {},
   "outputs": [],
   "source": [
    " ⚠ 注意事项  ：  不能用于输入特征（X）中的非数值特征！\n",
    "\n",
    "le.fit(['red', 'blue', 'green'])\n",
    "le.transform(['red', 'blue'])  # 输出可能是 [2, 0]\n",
    "这会人为引入数值关系，例如认为 red > green，但实际类别无序！\n",
    "\n",
    "训练集和测试集要使用同一个 encoder 对象\n",
    "\n",
    "le.fit(y_train)\n",
    "y_test_encoded = le.transform(y_test)  # 不要对 test 再 .fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58158968-bd20-4cba-a68d-dec7b62b756e",
   "metadata": {},
   "source": [
    "✅ 与 OneHotEncoder 的对比\n",
    "\n",
    "| 特性      | LabelEncoder | OneHotEncoder |\n",
    "| ------- | ------------ | ------------- |\n",
    "| 编码形式    | 整数编码         | 稀疏矩阵/独热编码     |\n",
    "| 适用对象    | 通常用于目标变量（y）  | 通常用于输入特征（X）   |\n",
    "| 是否有顺序关系 | 有（按字典序）      | 无             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ba8c51-6fd2-441e-9767-6ee8f821cf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "✅ 示例：应用于分类模型的目标变量\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 示例标签\n",
    "y = ['spam', 'ham', 'ham', 'spam', 'spam']\n",
    "\n",
    "# 编码\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "# 模型训练\n",
    "X = [[0], [1], [2], [3], [4]]\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X, y_encoded)\n",
    "\n",
    "# 预测结果还原\n",
    "y_pred_encoded = clf.predict([[1]])\n",
    "y_pred = le.inverse_transform(y_pred_encoded)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dc8e29-b491-412b-9d5f-34cc2632c9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "614de7f8-d182-46c1-a00d-7a64950184d8",
   "metadata": {},
   "source": [
    "## 3.5. Binarizer\n",
    "是 sklearn.preprocessing 中的一个工具，用于将数值型特征二值化（binarize），即： \\\n",
    "将每个数值特征根据某个阈值（threshold）转化为 0 或 1。\n",
    "\n",
    "#### ✅ 使用场景\n",
    "处理特征数据（X），用于将特定特征转为布尔值或离散值  \\\n",
    "适用于如：是否大于某个分数、是否启用、是否满足条件等特征处理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bfa606-0658-460a-9c88-82d0f22d3177",
   "metadata": {},
   "source": [
    "#### ✅ 原理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1153246-d406-4cb3-bbe4-bda102f13509",
   "metadata": {},
   "outputs": [],
   "source": [
    "对于每个输入值 x： \n",
    "if x > threshold: \n",
    "    return 1  \n",
    "else:  \n",
    "    return 0  \n",
    "默认 threshold=0.0，即正数为 1，负数或 0 为 0。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77cdb79-9618-4f0a-8ff3-34bbba0eeadc",
   "metadata": {},
   "source": [
    "#### ✅ 基本用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f31eee4-9a46-4949-af54-cfa62f3ebb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1.5, -0.5, 2.0],\n",
    "              [0.0,  0.0, 3.0],\n",
    "              [1.2,  1.3, -1.5]])\n",
    "\n",
    "# 创建二值化器，设置阈值为1.0\n",
    "binarizer = Binarizer(threshold=1.0)\n",
    "\n",
    "# 应用转换\n",
    "X_binarized = binarizer.fit_transform(X)\n",
    "\n",
    "print(X_binarized)\n",
    "\n",
    "输出：\n",
    "\n",
    "[[1. 0. 1.]\n",
    " [0. 0. 1.]\n",
    " [1. 1. 0.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611d3654-9987-4f62-bf15-07f2b1253dc9",
   "metadata": {},
   "source": [
    "#### ✅ 参数说明\n",
    "| 参数          | 说明                                  |\n",
    "| ----------- | ----------------------------------- |\n",
    "| `threshold` | 阈值，默认 0.0；大于此值的设为 1，否则设为 0          |\n",
    "| `copy`      | 是否复制原始数据，默认 True，设为 False 可就地转换节省内存 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7699cb03-2758-4e19-85a2-67f855794413",
   "metadata": {},
   "source": [
    "#### ✅ 方法说明\n",
    "| 方法                 | 说明                      |\n",
    "| ------------------ | ----------------------- |\n",
    "| `fit(X)`           | 对数据结构“拟合”，但不学习参数（无实际作用） |\n",
    "| `transform(X)`     | 对数据应用二值化转换              |\n",
    "| `fit_transform(X)` | 拟合并转换                   |\n",
    "\n",
    "⚠ 注意事项  :   \n",
    "与 LabelBinarizer 不同：Binarizer 是对数值特征进行处理，而 LabelBinarizer 是对 ** 分类标签（字符串或整数）** 进行编码。  \\\n",
    "如果你使用逻辑回归/树模型，建议不要直接使用 Binarizer 降维（模型会自己处理非线性关系），但在一些规则或启发式建模中可作为特征工程步骤。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf565a9-ac8c-4eaa-94aa-a958bff69858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ab14f63-6879-4e83-8926-81cd2952c69d",
   "metadata": {},
   "source": [
    "## 3.6. PolynomialFeatures\n",
    "特征多项式扩展，用于线性模型拟合非线性问题"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef88d0b8-ce84-4aa1-85d2-d04c5f9788eb",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform([[2, 3]])\n",
    "\n",
    "输出：\n",
    "2,3,4,6,9 （包含原始特征、平方项、交叉项）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63e47c5-0864-4110-9daa-c27e9cea795f",
   "metadata": {},
   "source": [
    "## 3.7. PowerTransformer\n",
    "是 sklearn.preprocessing 中的一个特征变换器，用于将特征转换为更**接近正态分布（高斯分布）**的形式，目的是提高模型性能，特别是在数据偏态严重时。\n",
    "\n",
    "#### 🧠 背景原理\n",
    "现实中的特征数据往往不是正态分布，可能是右偏、左偏、长尾等，很多机器学习模型（如线性回归、SVM）对数据分布比较敏感。 \\\n",
    "PowerTransformer 提供两种变换方法：\n",
    "\n",
    "| 方法              | 描述                      |\n",
    "| --------------- | ----------------------- |\n",
    "| `'yeo-johnson'` | **适用于任意实数（包括负数）**，是默认选项 |\n",
    "| `'box-cox'`     | **仅适用于正数**，变换速度稍快       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948ce7f1-0261-4b51-a2d8-ce1445519e7a",
   "metadata": {},
   "source": [
    "#### ✅ 用法示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e2ebf6-3e2a-4bdc-b368-69ff0dfe57d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[1], [2], [3], [4], [5], [6]])\n",
    "\n",
    "pt = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "X_trans = pt.fit_transform(X)\n",
    "\n",
    "print(X_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e307444-e3e3-4bf9-8866-0f06f275d342",
   "metadata": {},
   "source": [
    "\n",
    "| 参数            | 默认值             | 说明                               |\n",
    "| ------------- | --------------- | -------------------------------- |\n",
    "| `method`      | `'yeo-johnson'` | 选择 `'yeo-johnson'` 或 `'box-cox'` |\n",
    "| `standardize` | `True`          | 是否将变换后的数据标准化为均值0、方差1             |\n",
    "| `copy`        | `True`          | 是否复制输入数据                         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5495a5f2-f0f1-4ac6-8eb6-d3532915c95e",
   "metadata": {},
   "source": [
    "#### 📊 变换前后对比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59e4e5f8-431a-464a-91c2-5f7cf2f43851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']  # 使用黑体作为默认字体以支持中文\n",
    "plt.rcParams['axes.unicode_minus'] = False    # 解决负号'-'显示为方块的问题\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# 偏态分布数据\n",
    "X = np.random.exponential(scale=2, size=(1000, 1))\n",
    "\n",
    "# PowerTransformer\n",
    "pt = PowerTransformer()\n",
    "X_trans = pt.fit_transform(X)\n",
    "\n",
    "# 可视化对比\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "sns.histplot(X, ax=axes[0], kde=True).set_title(\" PowerTransform 变换前\")\n",
    "sns.histplot(X_trans, ax=axes[1], kde=True).set_title(\"PowerTransform 变换后\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1974a8ce-a1fe-4d73-a662-97f4869dcd49",
   "metadata": {},
   "source": [
    "### 🔍 Yeo-Johnson vs Box-Cox\n",
    "\n",
    "| 比较项    | Yeo-Johnson | Box-Cox   |\n",
    "| ------ | ----------- | --------- |\n",
    "| 是否支持负数 | ✅ 是         | ❌ 否（只能正数） |\n",
    "| 稳定性    | 稍慢但稳定       | 较快但不适用于负数 |\n",
    "| 应用范围   | 更通用         | 特定场景更快    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e171b3-80cd-48af-9b09-32605a8b94dc",
   "metadata": {},
   "source": [
    "#### 🧪 适用场景\n",
    "特征严重偏态分布，尤其是： \\\n",
    "收入、支出等长尾数据  \\\n",
    "样本不平衡导致分布不均  \\\n",
    "提升线性模型的表现（例如线性回归、逻辑回归） \\\n",
    "替代 log(x+1)、sqrt(x) 等人工手动转换\n",
    "\n",
    "🧷 注意事项\n",
    "对于稀疏数据（含很多0），建议先尝试 Yeo-Johnson（Box-Cox 不支持0或负数）\\\n",
    "可以配合 Pipeline 一起使用：\n",
    "\n",
    "from sklearn.pipeline import make_pipeline  \\\n",
    "model = make_pipeline(PowerTransformer(), LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e812fed-4797-4b9b-8b71-d954d4995658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcfca5fb-cf29-461f-9b44-44f3daa3c152",
   "metadata": {},
   "source": [
    "## 3.8. KBinsDiscretizer\n",
    "是 sklearn.preprocessing 中的一个离散化（分箱）转换器，用于将连续特征（如年龄、收入等）划分为离散的区间（bin），常用于将连续值特征变为分类变量或分级变量，以适应某些模型（如朴素贝叶斯、决策树等）。\n",
    "\n",
    "### 🧠 简单理解\n",
    "把连续变量“分桶”成多个区间，然后用 0、1、2… 表示每个区间。\n",
    "\n",
    "例如：\n",
    "年龄（连续）： \\\n",
    "[18, 22, 25, 40, 60] → 分成 3 个箱：[0-25), [25-45), [45+] → 离散值：[0, 0, 0, 1, 2]\n",
    "\n",
    "### ✅ 典型用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147aa688-8fee-4689-9c09-ec873df50edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "import numpy as np\n",
    "\n",
    "X = np.array([[5], [15], [25], [35], [45]])\n",
    "\n",
    "kbd = KBinsDiscretizer(n_bins=3, encode='ordinal', strategy='uniform')\n",
    "X_binned = kbd.fit_transform(X)\n",
    "\n",
    "print(X_binned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c29a090-97e7-4568-bd57-8bf7cbbf2805",
   "metadata": {},
   "source": [
    "| 参数          | 默认值          | 说明                                                                                                         |\n",
    "| ----------- | ------------ | ---------------------------------------------------------------------------------------------------------- |\n",
    "| `n_bins`    | 5            | 要划分的箱数，可以是 int 或 array（针对每列指定）                                                                             |\n",
    "| `encode`    | `'onehot'`   | 结果编码方式：`'ordinal'`、`'onehot'`、`'onehot-dense'`                                                             |\n",
    "| `strategy`  | `'quantile'` | 分箱策略：<br>• `'uniform'`：等宽分箱（区间宽度一样）<br>• `'quantile'`：等频分箱（每个箱样本数量一样）<br>• `'kmeans'`：聚类分箱（使用 KMeans 聚类中心） |\n",
    "| `subsample` | `None`       | KMeans 分箱时使用的样本数                                                                                           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3787507d-34fc-4430-b615-1858d82b1000",
   "metadata": {},
   "source": [
    "### 📦 encode 三种方式比较：\n",
    "\n",
    "| encode 方式        | 输出   | 示例                         |\n",
    "| ---------------- | ---- | -------------------------- |\n",
    "| `'ordinal'`      | 数值编码 | `[0, 1, 2, ...]`           |\n",
    "| `'onehot'`       | 稀疏矩阵 | 每个 bin 一列，类似 OneHotEncoder |\n",
    "| `'onehot-dense'` | 密集矩阵 | 同上，但返回普通 Numpy 数组          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039837a5-262a-4505-b1a5-d9a0a5c533e0",
   "metadata": {},
   "source": [
    "### 📊 示例对比：三种 strategy"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ae30632-f058-4098-b5e8-8e3de0bb9a3e",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "X = np.linspace(0, 100, 1000).reshape(-1, 1)\n",
    "\n",
    "for strategy in ['uniform', 'quantile', 'kmeans']:\n",
    "    kbd = KBinsDiscretizer(n_bins=4, encode='ordinal', strategy=strategy)\n",
    "    X_binned = kbd.fit_transform(X)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.title(f\"Strategy: {strategy}\")\n",
    "    # 统计每个箱子中的样本数量\n",
    "    unique, counts = np.unique(X_binned, return_counts=True)\n",
    "    plt.bar(unique, counts)\n",
    "    plt.xlabel(\"Bin\")\n",
    "    plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896fc532-1d66-452b-9920-3d832ddd1fa9",
   "metadata": {},
   "source": [
    "### 🎯 应用场景\n",
    "特征值范围广泛、分布不均时 \\\n",
    "想把连续值转成分类值（如：年龄段、价格段）\\\n",
    "模型对分类变量效果更好（如朴素贝叶斯）\\\n",
    "特征工程中引入非线性（特别是线性模型）\n",
    "\n",
    "### 🚧 注意事项\n",
    "若使用 'ordinal' 编码，注意不会产生虚拟变量（可能影响某些模型性能） \\\n",
    "若用在 pipeline 中，建议配合 ColumnTransformer 分别对数值和类别数据处理  \\\n",
    "若 strategy='quantile'，容易受重复值影响（尤其在小样本中）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af0bd56-ebb8-4c2c-b3d1-e4740b3da8df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db4e141b-a8d5-42d3-94ef-61ff6f3cfd9a",
   "metadata": {},
   "source": [
    "## 3.9. SimpleImputer\n",
    "是 sklearn.impute 模块中的一个类，用于处理数据中的缺失值（NaN）。它通过指定的策略来替换缺失值，是机器学习数据预处理中的常用工具。\n",
    "\n",
    "### 🔧 基本语法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad099a37-f79e-4aa0-950e-b1712c1f1228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f9dc51-07b8-4281-9250-6f91d00c72b3",
   "metadata": {},
   "source": [
    "| 参数               | 说明                                                                                                                                                   |\n",
    "| ---------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| `missing_values` | 指定哪些值是缺失值。默认是 `np.nan`，也可以设置为其他（如 0、-1）来表示缺失。                                                                                                        |\n",
    "| `strategy`       | 指定填补缺失值的策略，常用如下：<br>• `'mean'`：均值（仅适用于数值）<br>• `'median'`：中位数（仅适用于数值）<br>• `'most_frequent'`：众数（适用于分类和数值）<br>• `'constant'`：使用固定的值（需配合 `fill_value`） |\n",
    "| `fill_value`     | 当 `strategy='constant'` 时，用于指定填充值。默认是 0。                                                                                                             |\n",
    "| `copy`           | 是否复制 `X`。默认 `True` 表示不在原数据上修改。                                                                                                                       |\n",
    "| `add_indicator`  | 如果为 `True`，会为每个含缺失值的特征添加一个是否缺失的布尔指示列。                                                                                                                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b13ba9d-5a75-44e3-acf0-db65689b42d4",
   "metadata": {},
   "source": [
    "### 🧪 方法介绍\n",
    "| 方法                 | 说明                                    |\n",
    "| ------------------ | ------------------------------------- |\n",
    "| `fit(X)`           | 计算用于填充的统计量（如均值、众数等）。                  |\n",
    "| `transform(X)`     | 将缺失值替换为拟合时计算出的值。                      |\n",
    "| `fit_transform(X)` | 组合 `fit()` 和 `transform()`，常用于训练数据处理。 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e60a85b-ce4f-42fd-8456-8ca0d57a6407",
   "metadata": {},
   "outputs": [],
   "source": [
    "📌 示例\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "X = np.array([[1, 2], [np.nan, 3], [7, 6]])\n",
    "\n",
    "# 使用均值填充\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_new = imputer.fit_transform(X)\n",
    "\n",
    "print(X_new)\n",
    "# 输出：\n",
    "# [[1.  2. ]\n",
    "#  [4.  3. ]\n",
    "#  [7.  6. ]]\n",
    "\n",
    "⚠️ 注意事项\n",
    "fit() 应始终只在训练集上调用；测试集只能 transform()，避免数据泄露。\n",
    "\n",
    "对于分类数据（字符串类型），通常使用 'most_frequent' 策略。\n",
    "\n",
    "缺失值较多的列可能应考虑删除，而非插补。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0481b660-7034-4c0d-a94a-d85ed34cb1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4047c6bf-e6a2-4fdc-b6ca-fd5958da599b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ff6f7cf-3320-4063-a8ea-363dbe079541",
   "metadata": {},
   "source": [
    "## 3.10.自定义转换器：FunctionTransformer\n",
    "是 sklearn.preprocessing 模块中的一个实用工具，可以将任意函数包装成一个“转换器”，用于 Pipeline 或特征工程中自定义转换。\n",
    "\n",
    "### 🧠 作用\n",
    "允许你将自己的数据转换函数（如 log、square、自定义映射函数等）转换为兼容 Scikit-learn 的 transformer 对象（支持 .fit_transform()、.transform() 等），从而与流水线无缝集成。\n",
    "\n",
    "### 📦 基本用法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb29168b-fa0e-4a62-a41d-adf1e7761b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import numpy as np\n",
    "\n",
    "# 定义函数，例如取对数（加1防止log(0)）\n",
    "log_transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "\n",
    "X = np.array([[1], [2], [3]])\n",
    "X_trans = log_transformer.fit_transform(X)b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8047bcb4-645d-4f66-baed-0a5f7a1d67b1",
   "metadata": {},
   "source": [
    "| 参数                  | 说明                                                 |\n",
    "| ------------------- | -------------------------------------------------- |\n",
    "| `func`              | 要应用的函数，例如 `np.log1p`, `np.square`，或者自定义函数。         |\n",
    "| `inverse_func`      | 逆变换函数（如果你需要 `.inverse_transform()`）。               |\n",
    "| `validate`          | 是否验证输入类型。默认 `False`，为 `True` 时会强制输入为 2D `ndarray`。 |\n",
    "| `accept_sparse`     | 是否接受稀疏矩阵。                                          |\n",
    "| `check_inverse`     | 是否检查 `func` 与 `inverse_func` 是否互为逆操作。              |\n",
    "| `feature_names_out` | 输出特征名的策略。可选 `\"one-to-one\"` 或 callable。             |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f024cf2e-e02d-47e6-b32e-0650bc476e48",
   "metadata": {},
   "source": [
    "### 🎯 常见用途\n",
    "\n",
    "| 用途            | 示例函数                  |\n",
    "| ------------- | --------------------- |\n",
    "| log 转换        | `np.log1p`            |\n",
    "| 平方或开方         | `np.sqrt`、`np.square` |\n",
    "| 自定义 lambda 函数 | `lambda x: x + 5`     |\n",
    "| 特征标准化以外的自定义变换 | 比如反转、加噪声、变换日期格式等      |\n",
    "\n",
    "\n",
    "### ✅ 示例：自定义函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb327f7-1782-4b77-a23a-9ef19d42f896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import numpy as np\n",
    "\n",
    "# 自定义：将每个值加5\n",
    "add5 = FunctionTransformer(lambda x: x + 5)\n",
    "X = np.array([[1], [2], [3]])\n",
    "print(add5.fit_transform(X))\n",
    "# 输出：[[6], [7], [8]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587db53f-2426-4bc0-9970-311dc2084f7f",
   "metadata": {},
   "source": [
    "### 🧪 和 Pipeline 配合\n",
    "from sklearn.pipeline import Pipeline  \\\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pipeline = Pipeline([('log', FunctionTransformer(np.log1p)),\n",
    "('model', LinearRegression())])\n",
    "\n",
    "### ⚠️ 注意事项\n",
    "FunctionTransformer 默认不会改变数据形状（除非你的函数明确地改变它）。  \\\n",
    "用于非数值列时（如文本列），需确保转换函数能正确处理。  \\\n",
    "若你自定义函数包含 fit/transform 逻辑，则建议使用 TransformerMixin 创建自定义类，而非 FunctionTransformer。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1f3350-6a89-4794-90fd-88bdedf2848e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8db5fdbb-0116-4da0-a78e-b34a1dddd668",
   "metadata": {},
   "source": [
    "# 📌 小结对照表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb1474d-f2f7-4770-8000-92a995f04c49",
   "metadata": {},
   "source": [
    "| 方法 / 类名              | 功能           | 常用模型 / 场景    |\n",
    "| -------------------- | ------------ | ------------ |\n",
    "| `StandardScaler`     | 标准化（均值0，方差1） | 线性模型、SVM、KNN |\n",
    "| `MinMaxScaler`       | 缩放到\\[0,1]    | 神经网络         |\n",
    "| `LabelEncoder`       | 类别标签转数字      | y 标签编码       |\n",
    "| `OneHotEncoder`      | 类别转 one-hot  | 所有模型         |\n",
    "| `SimpleImputer`      | 缺失值填充        | 数据预处理必备      |\n",
    "| `PolynomialFeatures` | 特征多项式扩展      | 线性回归拟合非线性    |\n",
    "| `KBinsDiscretizer`   | 分箱/离散化       | 树模型、特征工程     |\n",
    "| `PowerTransformer`   | 正态分布转换       | 非对称分布数据      |\n",
    "| `Binarizer`          | 阈值变二值        | 特征简化、离散化     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73db5897-f5cc-4920-9ddc-96c97f294b56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bc515b8-429c-4c28-b814-52f9780dca29",
   "metadata": {},
   "source": [
    "# 4.sklearn.linear_model \n",
    "是 scikit-learn 中专门实现线性模型类算法的模块，涵盖了从最基本的线性回归到正则化回归、逻辑回归、鲁棒回归等多种模型，适用于回归与分类任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10e07f6-31ad-4331-b13e-c16965ec9e50",
   "metadata": {},
   "source": [
    "## 📘 模块作用：线性模型集合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7d3af6-f8de-4c14-822e-37002b28ed51",
   "metadata": {},
   "source": [
    "| 模型名称                                | 用途    | 主要任务       | 是否支持正则化  |\n",
    "| ----------------------------------- | ----- | ---------- | -------- |\n",
    "| `LinearRegression`                  | 回归    | 预测连续变量     | 否（可手动添加） |\n",
    "| `Ridge`, `Lasso`                    | 回归    | 正则化线性回归    | 是        |\n",
    "| `LogisticRegression`                | 分类    | 二分类/多分类    | 是        |\n",
    "| `SGDRegressor`, `SGDClassifier`     | 回归/分类 | 使用随机梯度下降   | 是        |\n",
    "| `ElasticNet`                        | 回归    | L1 + L2 正则 | 是        |\n",
    "| `HuberRegressor`, `RANSACRegressor` | 回归    | 鲁棒回归       | 是        |\n",
    "| `Perceptron`                        | 分类    | 感知机分类      | 是        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c5d186-2ea7-4fae-a5b8-8b7d553f2100",
   "metadata": {},
   "source": [
    "## 4.1. LinearRegression —— 线性回归模型"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f584a5e-0cec-4922-8e31-cfbe0e667905",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "特点：\n",
    "不使用正则化（容易过拟合）\n",
    "系数保存在 model.coef_，截距为 model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757ac80b-00ce-468c-ac28-ad5a10b381b2",
   "metadata": {},
   "source": [
    "## 4.2. Ridge / Lasso —— 正则化回归\n",
    "都是对 线性回归 模型添加了 正则化项（Regularization） 的变体，目的是防止模型过拟合，并在一定程度上进行特征选择或控制权重规模。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89ac6e-0952-4a2a-8e2f-f1d930991b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = Ridge(alpha=1.0)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6a4569-ee1a-45c2-9c78-e7fc7bfe989a",
   "metadata": {},
   "source": [
    "Lasso（L1 正则，自动进行特征选择）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9889004-7601-4fbf-96ee-7fd887f039a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model = Lasso(alpha=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "正则化的作用是防止过拟合，其中：\n",
    "L2（Ridge）：惩罚系数平方，保留所有特征但缩小权重\n",
    "L1（Lasso）：惩罚系数绝对值，会压缩某些权重到 0，实现特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60540870-d87e-4cbb-9ae3-449d97e901cb",
   "metadata": {},
   "source": [
    "| 特性     | Ridge 回归（L2）         | Lasso 回归（L1）         |      |   |\n",
    "| ------ | -------------------- | -------------------- | ---- | - |\n",
    "| 正则化类型  | L2 正则化               | L1 正则化               |      |   |\n",
    "| 惩罚项公式  | $\\lambda \\sum w_i^2$ | (\\lambda \\sum        | w\\_i | ) |\n",
    "| 权重缩小方式 | 将权重 **压缩但不为0**       | 将权重 **压缩为0**（可做特征选择） |      |   |\n",
    "| 特征选择能力 | 无（保留所有特征）            | 有（可剔除不重要的特征）         |      |   |\n",
    "| 适合场景   | 多重共线性数据              | 特征稀疏（高维）数据           |      |   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8a4cfa-24df-4273-8412-d8db53f52c1d",
   "metadata": {},
   "source": [
    "### 🔷 调节参数 alpha 的影响\n",
    "alpha=0 时，Ridge/Lasso 等价于普通的 LinearRegression\n",
    "\n",
    "alpha ↑ → 惩罚越强 → 模型越简单（权重越小/为0） → 偏差 ↑，方差 ↓\n",
    "\n",
    "可以用交叉验证自动选择 alpha：RidgeCV, LassoCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a07520-af80-4fd8-bb3d-1d8a9178a700",
   "metadata": {},
   "source": [
    "### 🔷 何时用 Ridge / Lasso？\n",
    "\n",
    "\n",
    "| 数据特征场景      | 推荐模型       | 原因                |\n",
    "| ----------- | ---------- | ----------------- |\n",
    "| 多重共线性       | Ridge      | 可以缓解特征间的共线性问题     |\n",
    "| 高维特征、特征选择需要 | Lasso      | 可以自动将无用特征的权重归0    |\n",
    "| 需要平衡两者      | ElasticNet | 综合 L1 + L2，有更强灵活性 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d2380e-29ba-4f6f-8698-ccc0ba3f1428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439d5d3f-242c-4db5-83bb-4620fed09ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2ff4de2-4475-4faa-91fb-3f6caedab8b6",
   "metadata": {},
   "source": [
    "## 4.3. LogisticRegression —— 逻辑回归（二分类 / 多分类）\n",
    "是 scikit-learn 中用于 分类问题 的线性模型，尤其常用于二分类任务。尽管名字叫“回归”，它实际上是一个 分类模型，预测的不是连续值，而是某个类别。\n",
    "\n",
    "### ✅ 适用问题\n",
    "二分类（如 0/1，是否患病）  \\\n",
    "多分类（multi_class='multinomial'） \\\n",
    "逻辑回归是 广义线性模型，输出类别概率。   \n",
    "\n",
    "### 📦 使用方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5648b61-f6b1-4773-8daf-be7594bda773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)               # 预测类别\n",
    "y_prob = model.predict_proba(X_test)[:, 1]   # 预测属于正类的概率\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82374c1d-e171-4d7a-bedf-d0e301396d86",
   "metadata": {},
   "source": [
    "| 参数             | 说明                                                |\n",
    "| -------------- | ------------------------------------------------- |\n",
    "| `penalty`      | 正则化类型：`'l2'`（默认），`'l1'`，`'elasticnet'`，或 `'none'` |\n",
    "| `C`            | 正则化强度（越小惩罚越强）                                     |\n",
    "| `solver`       | 求解器：如 `'liblinear'`, `'saga'`, `'lbfgs'`          |\n",
    "| `max_iter`     | 最大迭代次数（默认 100）                                    |\n",
    "| `multi_class`  | 多分类处理方式：`'auto'`, `'ovr'`, `'multinomial'`        |\n",
    "| `class_weight` | 类别权重，如 `'balanced'`                               |\n",
    "| `random_state` | 控制随机性，保证结果复现                                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39ded59-7fd7-4eb9-b031-6fb322f60e55",
   "metadata": {},
   "source": [
    "### 🧪 示例：二分类预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f25c2ff-7d61-4617-8446-a07f6c9b7ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(clf.score(X_test, y_test))  # 输出准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95647a45-42ce-4960-b0f7-97c7f2485256",
   "metadata": {},
   "source": [
    "### 📉 正则化与 C\n",
    "逻辑回归中默认使用 L2 正则化（岭回归），通过 C 控制其强度：  \\\n",
    "C 越小 → 正则化越强 → 防止过拟合  \\\n",
    "C=1.0 是默认值   \\\n",
    "如果要使用 L1 正则（可进行特征选择），设置：\\\n",
    "LogisticRegression(penalty='l1', solver='liblinear')\n",
    "\n",
    "### 📈 多分类处理\n",
    "逻辑回归可处理多分类问题，方式有两种： \\\n",
    "one-vs-rest (OvR)：每个类与其他所有类分别建一个分类器（默认）  \\\n",
    "multinomial：适用于 Softmax 回归，多类同时处理（推荐）\\\n",
    "LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "### ✅ 优点\n",
    "模型简单、速度快、易解释  \\\n",
    "可输出概率  \\\n",
    "可添加正则防止过拟合  \\\n",
    "对线性可分问题表现优秀\n",
    "\n",
    "### ⚠️ 注意事项\n",
    "特征应 数值化，最好 标准化（例如使用 StandardScaler）  \\\n",
    "对于非线性问题可能效果不佳  \\\n",
    "高维稀疏特征时，liblinear、saga 更适用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a6651a-6015-4b3c-8307-c68b3f040bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f514a4-c565-4ed7-b588-0f54e53a0d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4da1bf2-15dd-4606-b230-0540f3b9f1c1",
   "metadata": {},
   "source": [
    "## 4.4. ElasticNet —— L1 + L2 混合正则\n",
    "它结合了 Ridge（L2 正则） 和 Lasso（L1 正则） 的优点，是一种更加灵活、稳定的线性模型正则化方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2bd06d-ddb9-4a22-b3b3-4040a7785343",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "model = ElasticNet(alpha=1.0, l1_ratio=0.5) # alpha 是整体正则强度，l1_ratio 控制 L1/L2 比例 l1_ratio 越大越偏向 Lasso\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a0ee56-00a1-48af-93fa-f1e48f00c13b",
   "metadata": {},
   "source": [
    "### 🔷 一、ElasticNet 的优势\n",
    "\n",
    "| 特点           | 描述                             |\n",
    "| ------------ | ------------------------------ |\n",
    "| 特征选择能力       | 像 Lasso 一样可以将部分系数压缩为 0         |\n",
    "| 稳定性好         | 像 Ridge 一样在共线性时保持模型稳定          |\n",
    "| 更强的灵活性       | 通过 `l1_ratio` 可以平衡 L1 和 L2 正则化 |\n",
    "| 高维稀疏数据 + 共线性 | ElasticNet 是兼顾这两种情况的首选模型       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c693415-f247-4f95-b6ce-2681a9099d60",
   "metadata": {},
   "source": [
    "### 🔷 二、自动调参：ElasticNetCV（交叉验证）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00558b23-186f-430d-99bc-d373d1090571",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "\n",
    "model_cv = ElasticNetCV(alphas=[0.01, 0.1, 1, 10], l1_ratio=[0.1, 0.5, 0.9], cv=5)\n",
    "model_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"最优 alpha:\", model_cv.alpha_)\n",
    "print(\"最优 l1_ratio:\", model_cv.l1_ratio_)\n",
    "print(\"R²分数:\", model_cv.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85bd97a-29a6-48ce-b058-776c0b102de1",
   "metadata": {},
   "source": [
    "### 🔷 三、适用场景\n",
    "| 场景特征         | 是否推荐使用 ElasticNet |\n",
    "| ------------ | ----------------- |\n",
    "| 特征多但只有一部分相关  | ✅（可以特征选择）         |\n",
    "| 多重共线性 + 高维特征 | ✅（结合 Ridge 优势）    |\n",
    "| Lasso 表现不稳定  | ✅（ElasticNet 更稳）  |\n",
    "\n",
    "\n",
    "### 🔷 七、注意事项\n",
    "使用前建议做特征标准化（StandardScaler）\n",
    "\n",
    "ElasticNet 是在线性关系假设下的模型，不适合强非线性数据\n",
    "\n",
    "l1_ratio 和 alpha 调节非常关键，建议使用交叉验证调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f0679b-d461-40cf-bb94-ac7ae2b06ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4072328d-be18-40e5-814e-cc80cc0f23c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff26eb1b-901b-462b-be2d-187da062258b",
   "metadata": {},
   "source": [
    "## 4.5. SGDClassifier / SGDRegressor —— 随机梯度下降（适合大规模数据）\n",
    "\n",
    "是 scikit-learn 提供的两个基于 随机梯度下降（Stochastic Gradient Descent, SGD） 的模型，分别用于：\n",
    "\n",
    "✅ SGDClassifier：分类任务（二分类或多分类） \\\n",
    "✅ SGDRegressor：回归任务\n",
    "\n",
    "它们的最大特点是：能够高效处理大规模数据集（尤其是稀疏数据），适合在线学习或增量学习。\n",
    "\n",
    "### 🔷 一、什么是 SGD（随机梯度下降）？\n",
    "随机梯度下降是一种优化算法，用于最小化损失函数。\\\n",
    "与普通的批量梯度下降（BGD）相比：\n",
    "| 方法             | 特点                    |\n",
    "| -------------- | --------------------- |\n",
    "| **BGD**        | 每次更新使用所有样本，收敛稳定，但慢    |\n",
    "| **SGD**        | 每次只用一个样本更新参数，速度快，波动大  |\n",
    "| **Mini-Batch** | 一次用一小批样本更新参数，兼顾速度和稳定性 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df29fcca-d9a0-48ee-a68a-4615048d547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "model = SGDClassifier(loss='log_loss', penalty='l2', max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "优点：\n",
    "适用于大数据集（不必整体加载进内存）\n",
    "支持各种损失函数，如：\n",
    "loss='log_loss'（等同于逻辑回归）\n",
    "loss='hinge'（SVM）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526d4d31-9500-46f0-af6b-cba6cc9986ce",
   "metadata": {},
   "source": [
    "| 参数               | 说明                                                              |\n",
    "| ---------------- | --------------------------------------------------------------- |\n",
    "| `loss`           | 损失函数（见上）                                                        |\n",
    "| `penalty`        | 正则化：`'l2'`（默认）、`'l1'`、`'elasticnet'`                            |\n",
    "| `alpha`          | 正则化强度，越大越强                                                      |\n",
    "| `max_iter`       | 最大迭代次数                                                          |\n",
    "| `tol`            | 收敛阈值，loss 改变小于 tol 就停止                                          |\n",
    "| `learning_rate`  | 学习率策略，如 `'constant'`, `'optimal'`, `'invscaling'`, `'adaptive'` |\n",
    "| `eta0`           | 初始学习率（配合 `learning_rate` 使用）                                    |\n",
    "| `early_stopping` | 是否使用早停（防止过拟合）                                                   |\n",
    "| `average`        | 是否对参数做均值化（适用于噪声大的场景）                                            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bd0270-9b2c-4649-b788-30a9e244d281",
   "metadata": {},
   "source": [
    "### 🔷 二、SGDClassifier 详解\n",
    "✅ 1. 适用于哪些模型？ \\\n",
    "你可以通过设置 loss 参数来选择不同的分类模型：\n",
    "\n",
    "| loss               | 对应模型                      |\n",
    "| ------------------ | ------------------------- |\n",
    "| `'hinge'`          | 线性 SVM（默认）                |\n",
    "| `'log_loss'`       | 逻辑回归（Logistic Regression） |\n",
    "| `'modified_huber'` | 稳健版本的逻辑回归                 |\n",
    "| `'perceptron'`     | 感知机模型                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df16d33f-9599-4ad6-85b8-d8832f98cd29",
   "metadata": {},
   "source": [
    "### 🔷 三、SGDRegressor 详解\n",
    "✅ 1. 支持的回归类型：\n",
    "| loss                    | 对应模型类型          |\n",
    "| ----------------------- | --------------- |\n",
    "| `'squared_error'`       | 普通线性回归（默认）      |\n",
    "| `'huber'`               | 稳健回归，抗异常值       |\n",
    "| `'epsilon_insensitive'` | 支持向量回归的 ε-不敏感损失 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62efa843-ed91-432c-87ae-1fa0874e6da8",
   "metadata": {},
   "source": [
    "### 🔷 四、什么时候使用 SGD 系列模型？\n",
    "\n",
    "| 场景                | 是否适合用 SGD              |\n",
    "| ----------------- | ---------------------- |\n",
    "| 特征很多（高维数据）        | ✅ 非常适合                 |\n",
    "| 数据量很大，不能一次全部加载    | ✅ 可以逐批更新（partial\\_fit） |\n",
    "| 数据是稀疏格式（如 TF-IDF） | ✅ 非常适合                 |\n",
    "| 需要快速训练模型          | ✅ 很快                   |\n",
    "| 对模型精度要求极高         | ❌ 可能不如普通方法稳定           |\n",
    "\n",
    "### 🔷 五、支持在线学习：partial_fit()\n",
    "SGD 模型支持增量训练，适合流式数据或内存限制场景：\n",
    "\n",
    "clf.partial_fit(X_batch, y_batch, classes=[0, 1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16111880-2a8a-4f42-82f9-b4e49a49608b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3889fde-607a-499b-bec8-25e3147a481b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "139c51b6-b1ec-4c4b-93f6-1dfa0a4c6a11",
   "metadata": {},
   "source": [
    "## 4.6. 鲁棒回归：HuberRegressor / RANSACRegressor\n",
    "适用于含有离群点的回归数据。目的是在数据中存在**离群点（outliers）**时，仍能保持模型稳定、不被严重干扰。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1112c738-7287-4a4a-9ae5-b5db35c5c3cf",
   "metadata": {},
   "source": [
    "### 🔷 一、对比总结：HuberRegressor vs RANSACRegressor\n",
    "\n",
    "| 特性       | HuberRegressor      | RANSACRegressor           |\n",
    "| -------- | ------------------- | ------------------------- |\n",
    "| 类型       | 基于损失函数优化（梯度法）       | 基于抽样与投票的鲁棒估计（迭代随机采样）      |\n",
    "| 是否鲁棒     | ✅ 抗离群点              | ✅ 抗离群点                    |\n",
    "| 离群点处理方式  | 用 Huber 损失函数减少离群点影响 | 直接忽略不在模型内的样本（视为 outliers） |\n",
    "| 是否支持在线学习 | ❌ 不支持               | ❌ 不支持                     |\n",
    "| 优点       | 数学连续，训练稳定           | 非参数化，能去除极端点，效果直观          |\n",
    "| 缺点       | 离群点太多时不如 RANSAC 效果好 | 随机性较大，结果不稳定               |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80a03889-3629-449a-b7cd-3e8bd95bfd97",
   "metadata": {},
   "source": [
    "### 二、HuberRegressor 原理\n",
    "Huber 损失函数是 MSE 与 MAE 的折中版本：\\\n",
    "对小误差使用平方惩罚（像线性回归）\\\n",
    "对大误差使用线性惩罚（像 MAE）\\\n",
    "δ 是阈值，控制“离群点”的标准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd540dd-2522-4338-a77b-459be3595b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import HuberRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成数据 + 添加离群点\n",
    "X, y = make_regression(n_samples=100, noise=10, random_state=0)\n",
    "y[::10] += 100  # 每 10 个样本添加离群点\n",
    "\n",
    "# 拆分数据\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# 训练模型\n",
    "huber = HuberRegressor()\n",
    "huber.fit(X_train, y_train)\n",
    "\n",
    "print(\"R²分数:\", huber.score(X_test, y_test))\n",
    "print(\"回归系数:\", huber.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4923cfbb-f808-401d-b10d-9631eeba30f4",
   "metadata": {},
   "source": [
    "### 🔷 三、RANSACRegressor 原理\n",
    "RANSAC（RANdom SAmple Consensus）是一种迭代方法：\\\n",
    "随机选取数据子集，拟合模型\\\n",
    "判断哪些点在误差范围内 → 视为“内点”\\\n",
    "如果“内点”数量足够多 → 保留该模型\\\n",
    "重复 n 次，选择表现最好的模型\n",
    "\n",
    "适合处理大比例离群点，例如：\\\n",
    "线性模型中混有大量随机点\\\n",
    "特征与目标之间大部分线性，但小部分杂质数据干扰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa338d7-a86a-4bdc-9b0c-553692ed1845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RANSACRegressor, LinearRegression\n",
    "\n",
    "# 使用 RANSAC + LinearRegression 做基础模型\n",
    "ransac = RANSACRegressor(base_estimator=LinearRegression(), residual_threshold=10.0)\n",
    "ransac.fit(X_train, y_train)\n",
    "\n",
    "print(\"R²分数:\", ransac.score(X_test, y_test))\n",
    "print(\"估计器系数:\", ransac.estimator_.coef_)\n",
    "\n",
    "# 判断哪些是内点/外点\n",
    "inlier_mask = ransac.inlier_mask_\n",
    "outlier_mask = ~inlier_mask\n",
    "\n",
    "# 可视化\n",
    "plt.scatter(X[inlier_mask], y[inlier_mask], color='blue', label='内点')\n",
    "plt.scatter(X[outlier_mask], y[outlier_mask], color='red', label='离群点')\n",
    "line_X = np.linspace(X.min(), X.max(), 100)[:, np.newaxis]\n",
    "line_y_ransac = ransac.predict(line_X)\n",
    "plt.plot(line_X, line_y_ransac, color='green', label='RANSAC 线')\n",
    "plt.legend()\n",
    "plt.title(\"RANSAC Regressor\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708ef3b5-8ba8-49cf-a2dd-929202759e44",
   "metadata": {},
   "source": [
    "### 🔷 四、参数对比\n",
    "| 参数                   | HuberRegressor | RANSACRegressor  |\n",
    "| -------------------- | -------------- | ---------------- |\n",
    "| `epsilon`            | Huber 损失的容差阈值  | -                |\n",
    "| `max_iter`           | 最大迭代次数         | 最大尝试次数           |\n",
    "| `alpha`              | 正则化强度          | -                |\n",
    "| `residual_threshold` | -              | 判断内点误差阈值         |\n",
    "| `loss`               | 固定为 Huber      | 可更换为不同损失函数（底层模型） |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b672c7b-1d8b-46f3-aa59-b2f35316b6d3",
   "metadata": {},
   "source": [
    "### 🔷 五、应用场景总结\n",
    "| 场景              | 推荐模型              |\n",
    "| --------------- | ----------------- |\n",
    "| 少量离群点           | HuberRegressor ✅  |\n",
    "| 大量或严重离群点        | RANSACRegressor ✅ |\n",
    "| 训练数据噪声中等        | Huber ✅           |\n",
    "| 离群点不易定义，但有极值    | RANSAC ✅          |\n",
    "| 可解释性 / 连续优化     | Huber ✅           |\n",
    "| 要求鲁棒模型估计、拟合主干数据 | RANSAC ✅          |\n",
    "\n",
    "####  ✅ 总结一句话：\n",
    "HuberRegressor：温和处理离群点（通过损失函数），适合轻量级鲁棒回归\n",
    "    \n",
    "RANSACRegressor：强硬忽略离群点（通过样本筛选），适合严重污染数据场景\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71ada71-108e-4ce8-80d8-74750c3c5144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44b84fd-3d73-4194-92e4-01484efba468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11cbb281-4586-422c-8658-ff37d0977665",
   "metadata": {},
   "source": [
    "## 4.7. 感知机：Perceptron（早期神经网络原型）\n",
    " 是一种 线性二分类模型，属于最早的神经网络模型之一 \\\n",
    " 它的核心思想： \\\n",
    "给定输入样本，通过线性函数进行加权求和并加偏置，最后经过符号函数得到二分类输出（+1 或 -1 / 0 或 1）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4230706f-42d5-4153-9aff-63e23af18bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 生成线性可分数据\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, \n",
    "                           n_redundant=5, random_state=42)\n",
    "# 转换标签为 {-1, 1}\n",
    "y = 2 * y - 1\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# 初始化模型\n",
    "clf = Perceptron(max_iter=1000, eta0=1.0, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 准确率\n",
    "print(\"Train acc:\", clf.score(X_train, y_train))\n",
    "print(\"Test acc:\", clf.score(X_test, y_test))\n",
    "\n",
    "⚠️用于线性可分的分类任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d3c8a9-52cc-4a10-b642-685b04b982d7",
   "metadata": {},
   "source": [
    "| 参数              | 含义                                       |\n",
    "| --------------- | ---------------------------------------- |\n",
    "| `penalty`       | 是否添加正则项，如 `'l2'`, `'l1'`, `'elasticnet'` |\n",
    "| `alpha`         | 正则化强度（如果有）                               |\n",
    "| `max_iter`      | 最大迭代次数                                   |\n",
    "| `eta0`          | 初始学习率                                    |\n",
    "| `fit_intercept` | 是否学习偏置项                                  |\n",
    "| `shuffle`       | 每次迭代是否打乱数据                               |\n",
    "| `tol`           | 停止训练的容差                                  |\n",
    "\n",
    "### ✅ 六、优缺点\n",
    "✅ 优点：\\\n",
    "实现简单，速度快 \\\n",
    "对于线性可分问题能快速收敛 \\\n",
    "可以在线学习（partial_fit）\n",
    "\n",
    "❌ 缺点：\\\n",
    "只能用于线性可分问题，不能解决非线性问题 \\\n",
    "对异常值敏感 \\\n",
    "训练结果依赖样本顺序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3ad73c-093e-4a41-96f7-ac5a8eb563d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "888c52b2-7a0c-4b2b-acbe-092733b6a9f3",
   "metadata": {},
   "source": [
    "# 📌 系数查看与评估指标"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5aad1819-c2b7-4d35-969a-51cdb9d3429e",
   "metadata": {},
   "source": [
    "model.coef_        # 查看权重\n",
    "model.intercept_   # 截距\n",
    "model.score(X, y)  # 回归: R² 分数，分类: 准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46caadbb-a0d6-49ff-8fa3-85622706b43c",
   "metadata": {},
   "source": [
    "# ✅ 总结对照表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ad1de2-19de-4965-90a8-f7df9b2e9865",
   "metadata": {},
   "source": [
    "| 模型名                  | 任务 | 特点           | 正则化 |\n",
    "| -------------------- | -- | ------------ | --- |\n",
    "| `LinearRegression`   | 回归 | 标准线性回归       | ❌   |\n",
    "| `Ridge`              | 回归 | L2 正则        | ✅   |\n",
    "| `Lasso`              | 回归 | L1 正则 + 特征选择 | ✅   |\n",
    "| `ElasticNet`         | 回归 | L1 + L2 混合   | ✅   |\n",
    "| `LogisticRegression` | 分类 | 线性分类器        | ✅   |\n",
    "| `SGDClassifier`      | 分类 | 大规模线性分类      | ✅   |\n",
    "| `SGDRegressor`       | 回归 | 大规模线性回归      | ✅   |\n",
    "| `Perceptron`         | 分类 | 感知机          | ✅   |\n",
    "| `HuberRegressor`     | 回归 | 鲁棒性强         | ✅   |\n",
    "| `RANSACRegressor`    | 回归 | 离群点鲁棒        | ✅   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccb5e10-6464-48da-b612-cc6a2188a11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6197219f-2c72-4380-ba10-3cb75ebcf466",
   "metadata": {},
   "source": [
    "# 5.sklearn.tree \n",
    "是 scikit-learn 中用于决策树模型的模块，适用于分类与回归任务，也支持模型可视化，是树模型的核心模块之一。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a9fd7-988a-4502-8036-56dab1294142",
   "metadata": {},
   "source": [
    "## 🎯 模块用途概览"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a690caa-2410-44c0-ad92-712ceb097a13",
   "metadata": {},
   "source": [
    "| 模型                       | 任务类型 | 描述           |\n",
    "| ------------------------ | ---- | ------------ |\n",
    "| `DecisionTreeClassifier` | 分类   | 决策树分类器       |\n",
    "| `DecisionTreeRegressor`  | 回归   | 决策树回归器       |\n",
    "| `export_text`            | 工具   | 打印文本形式的决策树结构 |\n",
    "| `plot_tree`              | 工具   | 可视化决策树（图形）   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6f87d0-17b1-453a-a187-dcd17bdef30c",
   "metadata": {},
   "source": [
    "## 5.1. 决策树分类器：DecisionTreeClassifier\n",
    "是一种监督学习算法，属于树模型（Tree-based Models）的一种，用于分类任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cece9cc-d570-4c58-97cb-1f42e731766a",
   "metadata": {},
   "source": [
    "### 🔍 一、基本原理\n",
    "DecisionTreeClassifier 通过构造一棵树结构，将特征空间划分为若干子区域，实现对输入数据的分类。\\\n",
    "核心思想：\\\n",
    "递归地选择一个最优特征，将数据集划分为纯度更高的子集，直到满足停止条件。\n",
    "\n",
    "### 🌳 二、模型结构\n",
    "每个节点表示一个特征判断，每条边表示一个判断结果，叶节点表示一个分类结果。\n",
    "例子：\n",
    "\n",
    "        是否下雨?\n",
    "         /     \\\n",
    "       是       否\n",
    "      /           \\\n",
    "  带伞   ----  -----    ----- ----不带伞"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27eba7e5-f82c-47e6-b7fb-954331ac2395",
   "metadata": {},
   "source": [
    "### 🧠 三、核心术语\n",
    "| 术语         | 含义            |\n",
    "| ---------- | ------------- |\n",
    "| 根节点        | 决策树的起点        |\n",
    "| 内部节点       | 包含特征判断的节点     |\n",
    "| 叶节点        | 最终分类的结果       |\n",
    "| 分裂（Split）  | 根据特征划分数据      |\n",
    "| 纯度（Purity） | 节点中样本属于同一类的程度 |\n",
    "\n",
    "### 🧮 四、划分准则（常用）\n",
    "| 划分标准           | 描述                  |\n",
    "| -------------- | ------------------- |\n",
    "| **Gini系数**（默认） | 衡量数据的不纯度，越小越好       |\n",
    "| 信息增益（Entropy）  | 用于衡量特征划分后信息的不确定性降低量 |\n",
    "| 信息增益率          | 修正信息增益偏向特征值多的缺点     |\n",
    "\n",
    "### 🛑 五、停止条件\n",
    "样本全部属于同一类 \\\n",
    "达到最大树深度（max_depth） \\\n",
    "节点样本数低于某个阈值（min_samples_split, min_samples_leaf） \\\n",
    "特征无法进一步分裂\n",
    "\n",
    "### ⚙️ 六、常用参数（sklearn.tree.DecisionTreeClassifier###）\n",
    "| 参数                  | 含义                             |\n",
    "| ------------------- | ------------------------------ |\n",
    "| `criterion`         | 分裂准则：`\"gini\"`（默认）或 `\"entropy\"` |\n",
    "| `max_depth`         | 树的最大深度                         |\n",
    "| `min_samples_split` | 内部节点再划分所需最小样本数                 |\n",
    "| `min_samples_leaf`  | 叶子节点最少样本数                      |\n",
    "| `max_features`      | 每次分裂考虑的最大特征数                   |\n",
    "| `class_weight`      | 类别权重，用于处理不平衡数据                 |\n",
    "\n",
    "#### ✅ 七、优点\n",
    "结构清晰、易于解释（可视化）\\\n",
    "对特征缩放不敏感（无需归一化）\\\n",
    "可以处理非线性关系\n",
    "\n",
    "#### ❌ 八、缺点\n",
    "容易过拟合（需剪枝或设深度限制）\\\n",
    "对微小的数据变化敏感（不稳定）\\\n",
    "决策边界是轴对齐的，不够灵活"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f04c5-6192-45b7-b655-ebb62382bf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"准确率:\", clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731f114d-c921-4481-aa17-c28e6a3b5fb2",
   "metadata": {},
   "source": [
    "| 参数                  | 含义                             |\n",
    "| ------------------- | ------------------------------ |\n",
    "| `criterion`         | 分裂标准：`'gini'`（默认）或 `'entropy'` |\n",
    "| `max_depth`         | 树最大深度                          |\n",
    "| `min_samples_split` | 内部节点再划分所需最小样本数                 |\n",
    "| `min_samples_leaf`  | 叶子节点最少样本数                      |\n",
    "| `max_features`      | 划分时考虑的特征数（可用于随机性）              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86050ff-408a-468a-98ae-4cb5efc2e052",
   "metadata": {},
   "source": [
    "### 📊 十、可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51641fcd-0fe4-4417-9e79-0763c04f3ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plot_tree(clf, filled=True, feature_names=load_iris().feature_names, class_names=load_iris().target_names)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef941f2-a8f1-421a-a94a-fe0658e44fbf",
   "metadata": {},
   "source": [
    "| 参数名                                       | 类型                                                    | 说明                                                                  |\n",
    "| ----------------------------------------- | ----------------------------------------------------- | ------------------------------------------------------------------- |\n",
    "| `clf`                                     | `DecisionTreeClassifier` 或 `DecisionTreeRegressor` 实例 | 要绘制的模型，必须是训练好的（即已 `.fit()`）决策树                                      |\n",
    "| `filled=True`                             | `bool`                                                | 是否用颜色填充节点。<br>开启后，颜色代表该节点中最主要类别/数值，颜色越深代表该类占比越大                     |\n",
    "| `feature_names=load_iris().feature_names` | `list of str`                                         | 特征名列表，会显示在每个分裂条件上。若不指定则显示 `X[0]`, `X[1]` 这类形式                       |\n",
    "| `class_names=load_iris().target_names`    | `list of str`                                         | 类别名列表，仅用于分类树。用来显示每个类别的名称，例如 `[‘setosa’, ‘versicolor’, ‘virginica’]` |\n",
    "| `rounded`                                 | `bool`，可选                                             | 是否将节点边框绘制成圆角矩形（默认为 False）                                           |\n",
    "| `precision`                               | `int`，可选                                              | 控制浮点数显示精度（默认 3 位小数）                                                 |\n",
    "| `fontsize`                                | `int`，可选                                              | 设置节点中文字的字体大小                                                        |\n",
    "| `proportion`                              | `bool`，可选                                             | 若为 True，则显示的是每个节点内各类别的比例；为 False 则显示的是样本数                           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b3d393-f52b-4c02-abae-17c48abb6123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d66db5e-2b5a-44bd-9478-dac69fff9519",
   "metadata": {},
   "source": [
    "## 5.2. 决策树回归器：DecisionTreeRegressor\n",
    "是用于回归任务的决策树模型，属于 sklearn.tree 模块。它根据特征对连续值进行预测，通过最小化均方误差（MSE）来划分数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d63939-bad1-4b57-861a-76b2e776e69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import load_boston  # 或 load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 加载数据\n",
    "X, y = load_boston(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# 创建模型并训练\n",
    "reg = DecisionTreeRegressor(max_depth=4, random_state=42)\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_pred = reg.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432ea94f-af2b-460a-b991-c6b2513e689a",
   "metadata": {},
   "source": [
    "| 参数名                     | 说明                                                                     |\n",
    "| ----------------------- | ---------------------------------------------------------------------- |\n",
    "| `criterion`             | 默认是 `'squared_error'`（均方误差），也支持 `'friedman_mse'`、`'absolute_error'` 等。 |\n",
    "| `splitter`              | `'best'`（默认）或 `'random'`，用于选择分裂的策略。                                    |\n",
    "| `max_depth`             | 树的最大深度，防止过拟合。                                                          |\n",
    "| `min_samples_split`     | 内部节点再划分所需最小样本数，默认是2。                                                   |\n",
    "| `min_samples_leaf`      | 叶子节点最少样本数。                                                             |\n",
    "| `max_features`          | 在每次分裂时考虑的最大特征数。                                                        |\n",
    "| `random_state`          | 控制随机性（可复现）。                                                            |\n",
    "| `max_leaf_nodes`        | 限制最大叶节点数。                                                              |\n",
    "| `min_impurity_decrease` | 最小不纯度减少量，控制节点是否分裂。                                                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358a345c-6fef-4061-bea3-2b4859161826",
   "metadata": {},
   "source": [
    "### ✅ 与 DecisionTreeClassifier 的区别：\n",
    "| 项目   | `DecisionTreeClassifier` | `DecisionTreeRegressor` |\n",
    "| ---- | ------------------------ | ----------------------- |\n",
    "| 用途   | 分类任务                     | 回归任务                    |\n",
    "| 目标值  | 离散类别                     | 连续实数                    |\n",
    "| 损失函数 | Gini、Entropy             | MSE、MAE 等               |\n",
    "| 预测值  | 类别或概率                    | 连续数值                    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b75afe-afcd-4722-a862-f8dcffd27f63",
   "metadata": {},
   "source": [
    "### 回归树使用 MSE（均方误差）或 MAE 作为划分标准。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c57b533-8848-4373-b277-639d7501cd01",
   "metadata": {},
   "source": [
    "## 🧩 示例：分类 vs 回归\n",
    "分类任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafb2a01-c646-4648-9a98-aa152150ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=4)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))  # 输出准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22885383-4869-49b8-9d5a-eb5df512c161",
   "metadata": {},
   "source": [
    "回归任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718e7184-65dd-486a-8653-71ad396c968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "X, y = fetch_california_housing(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "reg = DecisionTreeRegressor(max_depth=5)\n",
    "reg.fit(X_train, y_train)\n",
    "print(reg.score(X_test, y_test))  # 输出 R² 分数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098f38d0-0de2-4925-8584-1d74c784bfb8",
   "metadata": {},
   "source": [
    "# 🌳决策树可视化工具"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a97258f-02a0-4438-ad02-7fe7543b57d7",
   "metadata": {},
   "source": [
    "## 5.3🌳 export_text:文本输出"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a972b4b4-4644-4110-8df8-1633002c90dc",
   "metadata": {},
   "source": [
    "from sklearn.tree import export_text\n",
    "\n",
    "print(export_text(clf, feature_names=iris.feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b47a26b-2e55-4112-980b-ff06a18c94c5",
   "metadata": {},
   "source": [
    "## 5.4🌳 plot_tree : 图形输出\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4865a320-a159-4b11-bd2c-6bd22e30c810",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(clf, filled=True, feature_names=iris.feature_names, class_names=iris.target_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4563a5-7772-4418-b362-aab9e720246a",
   "metadata": {},
   "source": [
    "## 📌 属性一览"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3996470-8ac0-47c2-b411-85218ff29259",
   "metadata": {},
   "source": [
    "| 属性名                    | 含义              |\n",
    "| ---------------------- | --------------- |\n",
    "| `feature_importances_` | 每个特征的重要性（权重）    |\n",
    "| `tree_.node_count`     | 总节点数            |\n",
    "| `tree_.max_depth`      | 树的最大深度          |\n",
    "| `clf.classes_`         | 所有类别标签（分类器）     |\n",
    "| `clf.predict()`        | 预测结果            |\n",
    "| `clf.score()`          | 准确率（分类）或 R²（回归） |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f628ff-f8f9-40e3-936e-9abe68e3836f",
   "metadata": {},
   "source": [
    "## 🚧 决策树的缺点与改进"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a664194d-d4e1-46fe-8948-3a67cc4b9abb",
   "metadata": {},
   "source": [
    "| 问题         | 解决方法          |\n",
    "| ---------- | ------------- |\n",
    "| 容易过拟合      | 限制深度、剪枝、正则化   |\n",
    "| 不稳定（对噪声敏感） | 使用集成方法（如随机森林） |\n",
    "| 无法很好处理线性边界 | 考虑逻辑回归或 SVM 等 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2db237c-095a-43ca-a666-fb5af36a1020",
   "metadata": {},
   "source": [
    "# ✅ 小结对照表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dcd5bd-3978-4fad-bae2-9950dcee0c01",
   "metadata": {},
   "source": [
    "| 模型名                      | 任务 | 默认分裂标准            | 主要用途        |\n",
    "| ------------------------ | -- | ----------------- | ----------- |\n",
    "| `DecisionTreeClassifier` | 分类 | `'gini'`          | 分类问题（如鸢尾花）  |\n",
    "| `DecisionTreeRegressor`  | 回归 | `'squared_error'` | 连续目标预测（如房价） |\n",
    "| `plot_tree`              | 工具 | ——                | 图形化结构       |\n",
    "| `export_text`            | 工具 | ——                | 文本结构展示      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33c43f2-e0b2-40e3-9242-20cfbcb74fdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "049e3b01-ac0e-4324-86f1-966a624bde73",
   "metadata": {},
   "source": [
    "# 6.sklearn.ensemble \n",
    "是 scikit-learn 中用于集成学习（Ensemble Learning）的模块，提供了一系列强大的模型，通过集成多个基础学习器（如决策树）来提升预测性能，常用于分类、回归和概率估计任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a59a91-56cb-48f6-8d7a-abc630f1a3b9",
   "metadata": {},
   "source": [
    "## 🎯 什么是集成学习？\n",
    "集成学习通过组合多个弱模型（通常是决策树）来构建一个强模型，主要分为两类："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b6d865-acc7-4125-834e-d031f3876e1e",
   "metadata": {},
   "source": [
    "| 方法           | 核心思想      | 举例模型                           |\n",
    "| ------------ | --------- | ------------------------------ |\n",
    "| **Bagging**  | 并行训练多个模型  | `RandomForest`, `Bagging`      |\n",
    "| **Boosting** | 逐步纠错式串行训练 | `GradientBoosting`, `AdaBoost` |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d82efe-32d7-4680-8bfd-afbeb88f5e1f",
   "metadata": {},
   "source": [
    "## 📦 sklearn.ensemble 中的常用模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0004e9a-8b05-4024-b276-7fed805d9449",
   "metadata": {},
   "source": [
    "| 模型名称                         | 类型 | 说明                  |\n",
    "| ---------------------------- | -- | ------------------- |\n",
    "| `RandomForestClassifier`     | 分类 | 随机森林（Bagging + 决策树） |\n",
    "| `RandomForestRegressor`      | 回归 |                     |\n",
    "| `GradientBoostingClassifier` | 分类 | 梯度提升树（Boosting）     |\n",
    "| `GradientBoostingRegressor`  | 回归 |                     |\n",
    "| `AdaBoostClassifier`         | 分类 | AdaBoost（Boosting）  |\n",
    "| `AdaBoostRegressor`          | 回归 |                     |\n",
    "| `BaggingClassifier`          | 分类 | 装袋法，可组合任意基分类器       |\n",
    "| `BaggingRegressor`           | 回归 |                     |\n",
    "| `VotingClassifier`           | 分类 | 多个模型投票表决（软/硬）       |\n",
    "| `StackingClassifier`         | 分类 | 多模型堆叠学习（模型融合）       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb10e87-48bd-422f-8dc2-4af5ea50bdf9",
   "metadata": {},
   "source": [
    "## 6. 1. RandomForestClassifier / RandomForestRegressor\n",
    " 是 sklearn.ensemble 模块中用于分类和回归问题的集成学习模型，核心思想是使用 Bagging + 多棵决策树，从而提升模型的鲁棒性与泛化能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc93b8d7-29f2-46d8-80c1-b1c43cf2a087",
   "metadata": {},
   "source": [
    "### 一、基本概念对比\n",
    "| 项目  | RandomForestClassifier | RandomForestRegressor |\n",
    "| --- | ---------------------- | --------------------- |\n",
    "| 任务  | 分类（预测类别）               | 回归（预测数值）              |\n",
    "| 基模型 | 决策树（分类树）               | 决策树（回归树）              |\n",
    "| 输出  | 多棵树的**投票结果**（多数）       | 多棵树的**平均结果**          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d0fc94-15df-464e-9449-46793e1493cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "特点：\n",
    "1.每棵树训练在不同的数据子集 + 特征子集上（防止过拟合）\n",
    "2.可提取特征重要性：rf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08d0619-f7a2-4115-bbd1-5ac99943874d",
   "metadata": {},
   "source": [
    "### 二、常用参数（适用于两者）\n",
    "| 参数名                 | 含义                                                                   |\n",
    "| ------------------- | -------------------------------------------------------------------- |\n",
    "| `n_estimators`      | 森林中树的数量，默认 100                                                       |\n",
    "| `criterion`         | 分裂准则<br>分类：`gini`, `entropy`<br>回归：`squared_error`, `absolute_error` |\n",
    "| `max_depth`         | 决策树最大深度                                                              |\n",
    "| `min_samples_split` | 内部节点再划分所需的最小样本数                                                      |\n",
    "| `min_samples_leaf`  | 叶子节点所需的最小样本数                                                         |\n",
    "| `max_features`      | 每次分裂考虑的特征数（分类默认 `'sqrt'`，回归默认 `'1.0'`）                               |\n",
    "| `bootstrap`         | 是否采用自助采样（默认 True）                                                    |\n",
    "| `random_state`      | 随机种子（保证可复现）                                                          |\n",
    "| `n_jobs`            | 并行处理数（-1 表示使用所有 CPU）                                                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54157e7-b63e-44c7-a315-8df1e2c73d0b",
   "metadata": {},
   "source": [
    "## 6.2. GradientBoostingClassifier / Regressor\n",
    "是 梯度提升树（Gradient Boosting Trees） 的分类与回归实现。它们属于 集成学习（Ensemble Learning） 中的提升方法（Boosting）。\n",
    "\n",
    "### 一、基本原理（Gradient Boosting）\n",
    "梯度提升是一种 逐步拟合残差 的方法： \\\n",
    "初始模型是一个弱模型（通常是一个小决策树）。\\\n",
    "每一步拟合上一步模型的残差（即预测错误），从而不断纠正错误。\\\n",
    "多个弱模型加权组合形成强模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84ce78b-9081-44f8-ae36-14da8407d8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier,GradientBoostingRegressor\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred = gb.predict(X_test)\n",
    "\n",
    "特点：\n",
    "1.每轮学习残差（误差），强力提升性能\n",
    "2.支持回归、分类、多类分类\n",
    "3.适合结构化数据（比随机森林慢但效果更好）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae58a218-be55-4af9-90d8-e28d3a5f6f13",
   "metadata": {},
   "source": [
    "### 二、重要参数解释\n",
    "| 参数名                 | 说明                                                          |\n",
    "| ------------------- | ----------------------------------------------------------- |\n",
    "| `n_estimators`      | 基学习器（树）的数量，越多越复杂，默认 100                                     |\n",
    "| `learning_rate`     | 学习率（每棵树对结果的贡献权重），默认 0.1                                     |\n",
    "| `max_depth`         | 每棵树的最大深度（控制过拟合）                                             |\n",
    "| `subsample`         | 每棵树训练时使用的数据占比（默认1.0，设置 <1.0 可防过拟合）                          |\n",
    "| `criterion`         | \\[\"friedman\\_mse\", \"squared\\_error\", \"mse\", \"mae\"] 决定分裂时的标准 |\n",
    "| `loss`（分类器）         | \\[\"log\\_loss\", \"exponential\"]，默认是 log\\_loss（对数损失）           |\n",
    "| `loss`（回归器）         | \\[\"squared\\_error\", \"absolute\\_error\", \"huber\", \"quantile\"] |\n",
    "| `min_samples_split` | 一个内部节点再划分所需最小样本数                                            |\n",
    "| `min_samples_leaf`  | 一个叶子节点上最小样本数                                                |\n",
    "| `max_features`      | 每次分裂所考虑的最大特征数                                               |\n",
    "| `random_state`      | 随机种子，保证实验复现性                                                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726a09a0-541e-4662-8a24-630831b84b97",
   "metadata": {},
   "source": [
    "### 三、优缺点简述\n",
    "优点：\\\n",
    "准确率高  \\\n",
    "可处理不同类型的特征  \\\n",
    "内置特征选择 \\\n",
    "可处理非线性关系\n",
    "\n",
    "缺点：  \\\n",
    "训练慢（逐棵训练） \\\n",
    "参数多，调参难  \\\n",
    "对异常值敏感（可通过 huber loss 缓解）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9ed4a4-f83d-46de-9aab-dbffd5267303",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828845c6-f400-4877-a896-fa98a2c532ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "197f0a73-19c1-48c5-92c1-f0e67709b8f4",
   "metadata": {},
   "source": [
    "## 6.3. AdaBoostClassifier / Regressor\n",
    "AdaBoost 的核心思想是：\n",
    "通过多轮迭代训练弱分类器（通常是决策树桩），每一轮根据上一次的分类结果调整样本权重，使模型逐步关注难以分类的样本。\n",
    "\n",
    "### 1️⃣ AdaBoostClassifier\n",
    "📌 作用： \\\n",
    "用于分类任务。通过加权组合多个弱分类器（默认是 DecisionTreeClassifier(max_depth=1)），形成强分类器。\n",
    "\n",
    "#### ✅ 适用场景：\n",
    "二分类和多分类任务 \\\n",
    "基学习器为弱分类器（如浅层树桩）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dd2b68-d494-4294-ab19-5bfef9ebe6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier  # 决策树分类器 \n",
    "from sklearn.datasets import make_classification  # 自动生成 数据集 模块\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 构造数据\n",
    "X, y = make_classification(n_samples=1000, n_features=20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# 创建模型\n",
    "clf = AdaBoostClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=50,\n",
    "    learning_rate=1.0\n",
    ")\n",
    "\n",
    "# 训练和评估\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "特点：\n",
    "1.对错误样本加权强化学习\n",
    "2.通常结合简单弱分类器（如深度为1的树）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ccc294-bf5c-470b-9d4d-87ed8ab80eb0",
   "metadata": {},
   "source": [
    "| 参数名              | 说明                                           |\n",
    "| ---------------- | -------------------------------------------- |\n",
    "| `base_estimator` | 弱学习器，默认是决策树桩（深度1）                            |\n",
    "| `n_estimators`   | 弱学习器个数（默认50）                                 |\n",
    "| `learning_rate`  | 学习率，控制每个弱学习器的贡献（默认1.0）                       |\n",
    "| `random_state`   | 随机种子，确保实验可重复                                 |\n",
    "| `loss`（仅回归）      | `linear`（默认）、`square`、`exponential`，控制损失函数形式 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67461962-021b-4fdc-bd03-ce7ab2e6bd62",
   "metadata": {},
   "source": [
    "### 2️⃣ AdaBoostRegressor\n",
    "📌 作用：\\\n",
    "用于回归任务，基于多个弱回归器加权组合（默认是 DecisionTreeRegressor(max_depth=3)）。\n",
    "\n",
    "#### ✅ 适用场景：\n",
    "回归问题  \\\n",
    "目标值具有一定波动性，适合迭代提升预测精度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c944ff-e560-4496-9049-4d2e866abc69",
   "metadata": {},
   "source": [
    "### 3️⃣ 优缺点总结\n",
    "| 优点        | 缺点               |\n",
    "| --------- | ---------------- |\n",
    "| 简单易用，理论扎实 | 对噪声和异常值敏感        |\n",
    "| 提升弱模型性能明显 | 难以并行训练           |\n",
    "| 分类和回归都适用  | 模型解释性较差（与线性模型相比） |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462680fd-6db3-4ee3-8e0e-0507f414c348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d001e3f-5f5b-4de0-98aa-e7adf2807a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d55c928a-0d11-4e87-9fb7-c11f4a0f6a28",
   "metadata": {},
   "source": [
    "## 6.4. BaggingClassifier / Regressor\n",
    "### ✅ 一、Bagging 方法简介\n",
    "Bagging（Bootstrap Aggregating） 是一种集成学习方法，通过对原始数据进行有放回的采样（Bootstrap），构造多个不同的数据子集，在每个子集上训练一个基础学习器，最终对预测结果进行投票（分类）或平均（回归），以降低模型的方差，提高稳定性和鲁棒性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bb8410-7a9c-431f-8fc2-e65e8584662d",
   "metadata": {},
   "source": [
    "### 🧠 二、BaggingClassifier & BaggingRegressor 基本介绍\n",
    "| 项目       | BaggingClassifier  | BaggingRegressor |\n",
    "| -------- | ------------------ | ---------------- |\n",
    "| 用途       | 分类任务               | 回归任务             |\n",
    "| 基础模型     | 可指定，如决策树、SVM、KNN 等 | 同上               |\n",
    "| 集成策略     | 多个模型并行训练 → 多数投票决策  | 多个模型并行训练 → 结果取平均 |\n",
    "| 是否支持并行训练 | 是                  | 是                |\n",
    "| 是否降低方差   | 是（防止过拟合）           | 是                |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d0c78c-4568-490c-853e-5890496e45d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier , BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(),\n",
    "    n_estimators=100,\n",
    "    max_samples=0.8,\n",
    "    bootstrap=True,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "print(\"Accuracy:\", bag_clf.score(X_test, y_test))\n",
    "\n",
    "特点：\n",
    "1.与随机森林相似，但不随机选特征\n",
    "2.可用于组合任何模型（如 SVM）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a6bf59-0407-41df-a904-bdd2ae32b77a",
   "metadata": {},
   "source": [
    "| 参数名                            | 说明                          |\n",
    "| ------------------------------ | --------------------------- |\n",
    "| `base_estimator` / `estimator` | 基础学习器，默认是 `DecisionTree`    |\n",
    "| `n_estimators`                 | 子模型的数量，默认 10                |\n",
    "| `max_samples`                  | 每个子模型训练用样本数（相对比例或整数），默认 1.0 |\n",
    "| `max_features`                 | 每个子模型训练用特征数（比例或整数），默认 1.0   |\n",
    "| `bootstrap`                    | 是否使用 Bootstrap 采样（对样本）      |\n",
    "| `bootstrap_features`           | 是否对特征也进行采样                  |\n",
    "| `n_jobs`                       | 并行运行的作业数，-1 表示使用全部核心        |\n",
    "| `random_state`                 | 随机种子，确保可复现性                 |\n",
    "| `oob_score`                    | 是否使用 OOB（袋外）数据评估性能          |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ec09f0-d6c4-4a40-b90d-697a8ce0ef29",
   "metadata": {},
   "source": [
    "### 📌 三、优缺点对比\n",
    "| 优点         | 缺点                     |\n",
    "| ---------- | ---------------------- |\n",
    "| 降低方差、减轻过拟合 | 不一定提升偏差（对偏差大的模型效果有限）   |\n",
    "| 易于并行化      | 模型训练时间相对较长             |\n",
    "| 可适用于各种基础模型 | 不如 Boosting 在提升准确率方面显著 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851373f8-1ce9-4032-9dc2-2d4de944e25b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e427114-6a82-4bf6-9166-a4af4bf58d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1ee7d74-f8a6-4ce6-a9a5-9de29fbe3fc0",
   "metadata": {},
   "source": [
    "## 6.5. VotingClassifier（投票集成）\n",
    "是 Scikit-learn 中一个集成学习方法，用于将多个不同的分类器组合成一个“投票式”的模型，以提高整体的预测性能。\n",
    "\n",
    "### ✅ VotingClassifier 简介\n",
    "属于： 集成学习中的软/硬投票法  \\\n",
    "主要作用： 组合多个不同的基础分类器，对预测结果进行“投票”，以提高模型泛化能力。\n",
    "\n",
    "### 🧠 工作原理\n",
    "1. 硬投票（voting='hard'，默认）\\\n",
    "每个子模型预测一个类别标签  \\\n",
    "最终预测为出现最多的类别\n",
    "\n",
    "2. 软投票（voting='soft'）\\\n",
    "每个子模型输出类别概率  \\\n",
    "将概率加权平均，预测概率最大的类作为最终输出  \\\n",
    "要求子分类器支持 predict_proba （预测每个样本属于各个类别的概率）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35d057d-9b15-4774-bad2-c4a65a45f11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "vote = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', LogisticRegression()),\n",
    "        ('dt', DecisionTreeClassifier()),\n",
    "        ('svc', SVC(probability=True))   # 软投票需要支持概率输出\n",
    "    ],\n",
    "    voting='soft'                     # 'hard' or 'soft'\n",
    ")\n",
    "\n",
    "vote.fit(X_train, y_train)\n",
    "\n",
    "将多个模型的结果进行投票表决：\n",
    "'hard'：多数投票\n",
    "'soft'：根据概率加权投票（需支持 predict_proba()）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08dbf96-280e-482e-a93b-eb4397f0351b",
   "metadata": {},
   "source": [
    "| 参数                  | 说明                                                             |\n",
    "| ------------------- | -------------------------------------------------------------- |\n",
    "| `estimators`        | 列表形式，包含多个 (name, estimator) 对，如 `('lr', LogisticRegression())` |\n",
    "| `voting`            | `'hard'` 或 `'soft'`，控制投票方式                                     |\n",
    "| `weights`           | 各个基分类器的权重（默认相等）                                                |\n",
    "| `n_jobs`            | 并行数                                                            |\n",
    "| `flatten_transform` | 是否将每个分类器的输出合并成一个特征数组                                           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904cbcf1-e034-4bd7-97be-d52e2ef14a3a",
   "metadata": {},
   "source": [
    "#### ✅ 优点\n",
    "简单易用  \\\n",
    "可以组合不同类型的模型  \\\n",
    "提升泛化能力\n",
    "\n",
    "#### ❌ 缺点\n",
    "模型训练时间较长（多个模型训练）  \\\n",
    "软投票要求支持 predict_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1d479a-f51f-4290-afa2-46b00b9ae812",
   "metadata": {},
   "source": [
    "### 📊 VotingClassifier vs Bagging vs Boosting\n",
    "| 对比点    | Voting    | Bagging   | Boosting  |\n",
    "| ------ | --------- | --------- | --------- |\n",
    "| 模型是否并行 | ✅ 并行      | ✅ 并行      | ❌ 顺序训练    |\n",
    "| 模型是否同质 | ❌ 一般为异质   | ✅ 通常同质    | ✅ 通常同质    |\n",
    "| 训练方式   | 独立训练，投票融合 | 独立训练，平均融合 | 顺序训练，错误校正 |\n",
    "| 常用基模型  | 不限        | 决策树等      | 决策树等      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f63a3ea-dd15-4ce2-aae4-8094013c65e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86cc4c0-21cd-4044-a79d-85e27c41b888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4366fe2a-3a4a-4681-8d33-34f0ec20c3e9",
   "metadata": {},
   "source": [
    "## 6.6. StackingClassifier（模型融合）（堆叠分类器）\n",
    "#### ✳️ 核心思想： \\\n",
    "将多个模型的输出作为元模型的输入，自动学习如何加权融合。\n",
    "### 🧠 原理：\n",
    "第一层：多个基础模型（可以是不同算法）  \\\n",
    "第二层：一个元学习器（通常为简单模型如逻辑回归），输入为第一层模型的输出预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20833a06-cc03-4078-a6ba-0151c0903dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "estimators = [\n",
    "    ('knn', KNeighborsClassifier()),\n",
    "    ('svc', SVC(probability=True))\n",
    "]\n",
    "\n",
    "stack = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression()\n",
    ")\n",
    "\n",
    "stack.fit(X_train, y_train)\n",
    "\n",
    "特点：\n",
    "1.将多个模型的输出作为新特征，送入最终模型学习\n",
    "2.比 Voting 更强大，但易过拟合，训练更慢"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3685c3b-8e8a-400a-9d16-bdafdf929666",
   "metadata": {},
   "source": [
    "| 参数名               | 说明                                       |\n",
    "| ----------------- | ---------------------------------------- |\n",
    "| `estimators`      | 第一层的模型列表                                 |\n",
    "| `final_estimator` | 第二层的元学习器（默认 `LogisticRegression`）        |\n",
    "| `cv`              | 第一层模型的交叉验证方式，防止过拟合                       |\n",
    "| `stack_method`    | 使用 `predict_proba` 或 `decision_function` |\n",
    "| `passthrough`     | 是否把原始特征传给元学习器（默认 `False`）                |\n",
    "\n",
    "#### ✅ 优点：\n",
    "自动学习如何融合多个模型  \\\n",
    "可以提升泛化能力  \\\n",
    "支持分类与回归（StackingRegressor）\n",
    "\n",
    "#### ⚠️ 缺点：\n",
    "训练和预测开销大  \\\n",
    "构建更复杂，调参较多"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa249de4-b7ec-4239-8c3f-b09706d498bc",
   "metadata": {},
   "source": [
    "### 🔍 Voting vs Stacking 对比表：\n",
    "| 特征      | VotingClassifier     | StackingClassifier   |\n",
    "| ------- | -------------------- | -------------------- |\n",
    "| 模型融合方式  | 投票 / 平均              | 学习融合                 |\n",
    "| 是否有元学习器 | 否                    | 是                    |\n",
    "| 融合策略    | 硬投票 / 概率平均           | 学习加权                 |\n",
    "| 表现      | 简单有效，但有限             | 通常优于 Voting          |\n",
    "| 支持回归任务  | ❌（用 VotingRegressor） | ✅（StackingRegressor） |\n",
    "| 实现复杂度   | 低                    | 中-高                  |\n",
    "| 适合场景    | 快速提升，模型效果差不多时        | 模型差异大，需要自动加权         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932c6a58-87b9-4fbb-9146-e1718fd58585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "941c892c-25dd-40ae-a35e-1ce220ed59dd",
   "metadata": {},
   "source": [
    "## 🧠 特征重要性（以树模型为例）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649f4b3a-c1c3-4706-aaab-f979112428dc",
   "metadata": {},
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7c08ba-5c1f-42d5-a6ef-e69287b396cf",
   "metadata": {},
   "source": [
    "## 📌 小结对照表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9804e2-12ac-4f19-81d9-49e278a3748b",
   "metadata": {},
   "source": [
    "| 模型                   | 类型    | 原理              | 是否支持特征重要性  |\n",
    "| -------------------- | ----- | --------------- | ---------- |\n",
    "| `RandomForest`       | 分类/回归 | Bagging + 决策树   | ✅          |\n",
    "| `GradientBoosting`   | 分类/回归 | Boosting + 决策树  | ✅          |\n",
    "| `AdaBoost`           | 分类/回归 | Boosting + 弱学习器 | ✅          |\n",
    "| `BaggingClassifier`  | 分类    | 装袋法             | 取决于基模型     |\n",
    "| `VotingClassifier`   | 分类    | 投票              | ❌（不提供特征权重） |\n",
    "| `StackingClassifier` | 分类    | 模型融合            | ❌（复杂模型结构）  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11760158-2d7f-429c-b878-0c34930c0ca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19e2bcaa-da60-4411-8a2a-a17fc5070bbc",
   "metadata": {},
   "source": [
    "# 7.sklearn.svm \n",
    "是 scikit-learn 中实现**支持向量机（SVM, Support Vector Machine）**的模块，支持用于分类（包括二分类、多分类）、回归、概率估计等任务。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1d03e9-a752-4433-9b17-359ef03c9d7e",
   "metadata": {},
   "source": [
    "## 🧠 什么是 SVM？\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07c9f032-269b-491e-b423-f6a916431c2a",
   "metadata": {},
   "source": [
    "支持向量机 : 是一种边界最大化分类器，通过在样本间寻找最优分隔超平面，达到分类或回归目的。\n",
    "分类：尽可能拉开正负样本的间距（最大间隔）\n",
    "回归：拟合在允许误差范围内的函数（如 ε-insensitive loss）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bca43b3-e4b3-439c-9d1e-cf930d24d1b6",
   "metadata": {},
   "source": [
    "## 🎯 sklearn.svm 常用模型一览"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f4c608-2e83-49bb-b777-179ffb9d4a1d",
   "metadata": {},
   "source": [
    "| 模型               | 任务    | 用途说明              |\n",
    "| ---------------- | ----- | ----------------- |\n",
    "| `SVC`            | 分类    | 支持非线性、核函数分类       |\n",
    "| `LinearSVC`      | 分类    | 快速线性 SVM，适合大规模数据  |\n",
    "| `SVR`            | 回归    | 支持向量回归，支持核函数      |\n",
    "| `LinearSVR`      | 回归    | 线性支持向量回归，效率更高     |\n",
    "| `NuSVC`, `NuSVR` | 分类/回归 | ν 参数替代 C 的 SVM 变体 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645e51ee-9ee3-42dd-bea8-a70c893142fb",
   "metadata": {},
   "source": [
    "## 7.1. SVC：支持向量分类器（非线性）\n",
    "是 Scikit-Learn 中用于支持向量机分类（SVM）的实现之一，属于监督学习中强大而常用的二分类模型 \\\n",
    "使用核函数映射数据到高维空间，使得在高维空间中可以找到最优超平面进行分类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd95ba6-16b1-4f04-b2af-9dab42e19966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(\n",
    "    C=1.0,\n",
    "    kernel='rbf',\n",
    "    degree=3,\n",
    "    gamma='scale',\n",
    "    coef0=0.0,\n",
    "    probability=False,\n",
    "    shrinking=True,\n",
    "    tol=1e-3,\n",
    "    cache_size=200,\n",
    "    class_weight=None,\n",
    "    verbose=False,\n",
    "    max_iter=-1,\n",
    "    decision_function_shape='ovr',\n",
    "    random_state=None\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28be77-f166-4b6c-ac97-152426830358",
   "metadata": {},
   "source": [
    "\n",
    "| 参数名                       | 说明                                                   |\n",
    "| ------------------------- | ---------------------------------------------------- |\n",
    "| `C`                       | 惩罚系数，默认 1.0。值越大，对误分类惩罚越大（可能过拟合）                      |\n",
    "| `kernel`                  | 核函数类型，常见有 `'linear'`, `'poly'`, `'rbf'`, `'sigmoid'` |\n",
    "| `degree`                  | 多项式核函数的次数（仅 `kernel='poly'` 时有效）                     |\n",
    "| `gamma`                   | 核函数系数，'scale'（默认） or 'auto' 或数值。值越大，越容易过拟合           |\n",
    "| `coef0`                   | 核函数中的常数项，适用于 `'poly'` 和 `'sigmoid'` 核                |\n",
    "| `probability`             | 是否启用概率估计（会增加计算量）                                     |\n",
    "| `shrinking`               | 是否使用启发式收缩技术，加速训练                                     |\n",
    "| `tol`                     | 收敛的阈值（容忍度），越小越精确但耗时                                  |\n",
    "| `class_weight`            | 类别权重设定，适合样本不平衡问题                                     |\n",
    "| `max_iter`                | 最大迭代次数，默认 `-1` 表示无限制                                 |\n",
    "| `decision_function_shape` | `'ovr'`（一对其余） 或 `'ovo'`（一对一），用于多分类                   |\n",
    "| `random_state`            | 随机种子                                                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b58f7c-cf59-49fe-a70d-25c77fdeabf9",
   "metadata": {},
   "source": [
    "### 🔍 常见核函数对比\n",
    "| kernel 类型   | 特点                  |\n",
    "| ----------- | ------------------- |\n",
    "| `'linear'`  | 线性可分问题，速度快          |\n",
    "| `'poly'`    | 多项式核，适合非线性但维度不太高的数据 |\n",
    "| `'rbf'`（默认） | 高斯核，常用于非线性、复杂边界问题   |\n",
    "| `'sigmoid'` | 类似神经网络的激活函数         |\n",
    "\n",
    "### 📊 应用场景\n",
    "文本分类（如垃圾邮件识别）  \\\n",
    "图像识别（如人脸识别）\\\n",
    "生物信息学（如蛋白质分类）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eb3e9e-2357-4398-bcf0-2844db1293a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845c6602-c828-479f-9a0c-aec13accd2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b5e0743-c0b7-4f0c-bc52-bfcda5bddc33",
   "metadata": {},
   "source": [
    "## 7.2. LinearSVC：线性 SVM（更快）\n",
    "是 scikit-learn 提供的用于线性支持向量分类（Support Vector Classification）的模型。与 SVC(kernel='linear') 类似，但它使用了 liblinear 库，效率更高，适用于大规模线性问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c4c076-1015-41f0-960d-7e5f5f33a474",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 创建数据\n",
    "X, y = make_classification(n_samples=100, n_features=4, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# 模型训练\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# 预测\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n",
    "⚠️\n",
    "1.不支持 kernel='rbf' 等核函数\n",
    "2.训练速度远快于 SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a768825-7d7d-4c8a-919e-e0941f78eb5d",
   "metadata": {},
   "source": [
    "| 参数名                 | 作用说明                                                      |\n",
    "| ------------------- | --------------------------------------------------------- |\n",
    "| `penalty`           | 正则项，默认 `'l2'`，只支持 `'l1'` 和 `'l2'`，`dual=False` 时支持 `'l1'` |\n",
    "| `loss`              | 损失函数，默认 `'squared_hinge'`，也可选 `'hinge'`                   |\n",
    "| `dual`              | 是否求解对偶问题。样本数 > 特征数时建议设为 `False`                           |\n",
    "| `C`                 | 正则化强度（惩罚系数），默认 `1.0`，越小代表正则化越强                            |\n",
    "| `max_iter`          | 最大迭代次数，默认 `1000`，可调大以避免收敛警告                               |\n",
    "| `class_weight`      | 类别权重，`'balanced'` 可自动平衡样本不均衡                              |\n",
    "| `multi_class`       | 多分类策略：`'ovr'`（一对其余，默认）或 `'crammer_singer'`                |\n",
    "| `fit_intercept`     | 是否计算截距项，默认 `True`                                         |\n",
    "| `intercept_scaling` | 截距项缩放系数，默认 `1`，通常不需更改                                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3b66d4-43c3-4558-b395-86cb97d88903",
   "metadata": {},
   "source": [
    "### ⚖️ 与 SVC(kernel='linear') 的区别 \n",
    "| 特点                       | `LinearSVC` | `SVC(kernel='linear')` |\n",
    "| ------------------------ | ----------- | ---------------------- |\n",
    "| 核函数                      | 不支持核函数（仅线性） | 支持核函数（可扩展非线性）          |\n",
    "| 底层库                      | `liblinear` | `libsvm`               |\n",
    "| 速度                       | 快，适合大样本     | 慢，适合小数据集               |\n",
    "| 支持 `probability=True` 吗？ | ❌ 不支持概率输出   | ✅ 支持概率输出               |\n",
    "| 支持 `coef_` 属性            | ✅ 是         | ✅ 是                    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2fbbe6-7442-4bb9-a7b0-58168b44221c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cf5059-fa4e-4341-903d-4f80e64494ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90c0f0b8-53aa-4d99-9c20-11f741401fe5",
   "metadata": {},
   "source": [
    "## 7.3. SVR：支持向量回归（非线性）\n",
    "### ✅ 一、SVR 简介\n",
    "SVR 是支持向量机（SVM）在回归任务中的应用。 \\\n",
    "它与支持向量分类器（SVC）的原理类似，不同点在于： \\\n",
    "SVC 寻找一个分界超平面最大化分类间隔； \\\n",
    "SVR 寻找一个函数，使得最多数据点落在允许的误差范围（ε-tube）内，并且模型尽可能平滑。\n",
    "\n",
    "### ✅ 二、SVR 的基本原理\n",
    "SVR 寻找的不是通过所有点的直线，而是： \\\n",
    "容忍一部分样本的偏差，只要在 ±ε 的范围内就不惩罚。 \\\n",
    "超出 ε 的误差才会被加入损失函数中（hinge-like loss）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57724cd0-8b0f-4152-803a-5e472b11aaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 构造数据\n",
    "X = np.sort(5 * np.random.rand(100, 1), axis=0)\n",
    "y = np.sin(X).ravel()\n",
    "\n",
    "# 添加噪声\n",
    "y[::5] += 3 * (0.5 - np.random.rand(20))\n",
    "\n",
    "# 训练 SVR\n",
    "svr_rbf = SVR(kernel='rbf', C=100, epsilon=0.1)\n",
    "svr_rbf.fit(X, y)\n",
    "\n",
    "# 可视化\n",
    "plt.scatter(X, y, color='darkorange', label='data')\n",
    "plt.plot(X, svr_rbf.predict(X), color='navy', lw=2, label='SVR model')\n",
    "plt.legend()\n",
    "plt.title('Support Vector Regression')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41149048-38f0-4733-926b-4d13aa7501fd",
   "metadata": {},
   "source": [
    "| 参数名         | 含义                                                                          |\n",
    "| ----------- | --------------------------------------------------------------------------- |\n",
    "| `kernel`    | 核函数类型，常用有：`'linear'`, `'poly'`, `'rbf'`, `'sigmoid'`。默认 `'rbf'`             |\n",
    "| `C`         | 惩罚系数，控制对异常点的容忍程度（大 C 更少容忍）                                                  |\n",
    "| `epsilon`   | ε-不敏感区间：在 ±ε 以内误差不计入损失                                                      |\n",
    "| `degree`    | 多项式核函数的次数（只在 `kernel='poly'` 时用）                                            |\n",
    "| `gamma`     | `rbf`、`poly` 和 `sigmoid` 核函数的系数。默认为 `'scale'`（1 / (n\\_features \\* X.var())） |\n",
    "| `shrinking` | 是否使用启发式收缩算法，默认 `True`，加速                                                    |\n",
    "| `tol`       | 停止训练的容差                                                                     |\n",
    "| `max_iter`  | 最大迭代次数。`-1` 表示不限制                                                           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4d1f9f-c761-4fb6-b9fa-dcaeb3f2becc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### ✅ 三、SVR 的优缺点\n",
    "| 优点                 | 缺点                  |\n",
    "| ------------------ | ------------------- |\n",
    "| 可处理非线性问题（通过核函数）    | 训练复杂度较高，尤其是大样本      |\n",
    "| 有较好的泛化能力           | 对参数（C, ε, gamma）较敏感 |\n",
    "| 对异常值不敏感（通过 ε-tube） | 不适合大规模数据（相比 GBDT）   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e90702-815f-4d22-904f-d2f8b1a33933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd62baa-af48-4a99-bba0-4252662eeced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec2edef2-658d-4754-bbb8-933880d9be10",
   "metadata": {},
   "source": [
    "## 7.4. LinearSVR：线性 SVM 回归（快速）\n",
    "是基于线性核的支持向量回归模型，适用于大规模线性回归问题。与 SVR(kernel='linear') 类似，但 LinearSVR 使用 liblinear 库实现，训练速度更快，尤其适合特征维度较高或样本量较大的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee18f50-ebde-4a61-84cd-b94dc3b7bc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "model = LinearSVR(epsilon=0.1, C=1.0, loss='epsilon_insensitive', dual=True, max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "⚠️性能类似 SVR(kernel='linear')，速度更快"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfd2db1-c643-4fa3-a707-9143fc15abf4",
   "metadata": {},
   "source": [
    "| 参数              | 说明                                                                |\n",
    "| --------------- | ----------------------------------------------------------------- |\n",
    "| `epsilon`       | ε-不敏感区间，误差在 \\[-ε, +ε] 内不计入损失（即“容忍”一定误差）                           |\n",
    "| `C`             | 正则化参数，防止过拟合。越大，模型越拟合训练数据                                          |\n",
    "| `loss`          | 损失函数：`'epsilon_insensitive'`（默认）或 `'squared_epsilon_insensitive'` |\n",
    "| `dual`          | 是否求解对偶问题。若样本数 > 特征数，建议设为 `False`                                  |\n",
    "| `max_iter`      | 最大迭代次数                                                            |\n",
    "| `fit_intercept` | 是否计算截距项                                                           |\n",
    "| `random_state`  | 随机数种子，便于结果复现                                                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06420ff4-203e-4e92-a62f-1f7cc1468fbf",
   "metadata": {},
   "source": [
    "## 🔍 核函数选项一览"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af256ede-ce49-4b78-acc4-4582b4d2acc3",
   "metadata": {},
   "source": [
    "| kernel      | 说明                | 适用数据类型     |\n",
    "| ----------- | ----------------- | ---------- |\n",
    "| `'linear'`  | 线性分隔              | 高维稀疏数据，如文本 |\n",
    "| `'poly'`    | 多项式核（需调 `degree`） | 图像数据       |\n",
    "| `'rbf'`     | 高斯径向基核（默认）        | 非线性问题      |\n",
    "| `'sigmoid'` | S 型核              | 类似神经网络     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d1f3ac-4c99-4c7a-b238-dc09b13761e8",
   "metadata": {},
   "source": [
    "## 📌 SVM 模型属性"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6404aef4-1afa-484e-b1a9-745b3f112cb4",
   "metadata": {},
   "source": [
    "| 属性                     | 含义             |\n",
    "| ---------------------- | -------------- |\n",
    "| `clf.support_`         | 支持向量在原始数据中的索引  |\n",
    "| `clf.support_vectors_` | 实际的支持向量        |\n",
    "| `clf.dual_coef_`       | 支持向量的系数（仅非线性核） |\n",
    "| `clf.coef_`            | 特征权重（仅限线性核）    |\n",
    "| `clf.intercept_`       | 截距项            |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae65503-85ef-48e2-a793-e571a4336035",
   "metadata": {},
   "source": [
    "## ⚠️ 注意事项"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cadd92b-bdc5-45fc-a30c-3d65aae416db",
   "metadata": {},
   "source": [
    "| 项    | 说明                                        |\n",
    "| ---- | ----------------------------------------- |\n",
    "| 特征缩放 | **SVM 对特征尺度敏感**，推荐使用 `StandardScaler` 预处理 |\n",
    "| 内存占用 | 非线性 SVM（尤其 `rbf`）在大数据上训练会非常慢、耗内存          |\n",
    "| 多分类  | `SVC` 内部使用“一对一”策略实现多分类                    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83985006-1634-4a15-bb40-aafaa006934e",
   "metadata": {},
   "source": [
    "## ✅ 模型选择建议"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57007707-43c1-4b15-b800-913d7ddd9f07",
   "metadata": {},
   "source": [
    "| 情况        | 推荐模型                    |\n",
    "| --------- | ----------------------- |\n",
    "| 线性问题，数据量大 | `LinearSVC`             |\n",
    "| 非线性小数据集   | `SVC(kernel='rbf')`     |\n",
    "| 回归问题，非线性  | `SVR(kernel='rbf')`     |\n",
    "| 回归问题，线性   | `LinearSVR`             |\n",
    "| 要获取概率预测   | `SVC(probability=True)` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cad5eb-f7ec-4acf-b45b-738dba8f307a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9bdb0a01-6469-4cf1-9d73-8a4c0ef9a573",
   "metadata": {},
   "source": [
    "# 8.sklearn.neighbors \n",
    "是 scikit-learn 中实现 K-近邻算法（KNN, K-Nearest Neighbors） 和 基于邻居的学习方法 的模块，适用于分类、回归、聚类以及最近邻搜索等任务。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4d1752-cb52-40f0-9854-ec58e308875c",
   "metadata": {},
   "source": [
    "## 🎯 模块功能概览"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167eb936-8794-4ef4-bc11-8190d02b52c6",
   "metadata": {},
   "source": [
    "| 类名                          | 类型    | 描述            |\n",
    "| --------------------------- | ----- | ------------- |\n",
    "| `KNeighborsClassifier`      | 分类    | KNN 分类器（最常用）  |\n",
    "| `KNeighborsRegressor`       | 回归    | KNN 回归器       |\n",
    "| `RadiusNeighborsClassifier` | 分类    | 半径邻居分类（以距离为准） |\n",
    "| `RadiusNeighborsRegressor`  | 回归    | 半径邻居回归        |\n",
    "| `NearestNeighbors`          | 最近邻查找 | 不用于监督学习，仅做搜索  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b16438-d4d8-422f-8ee8-5a864da80d90",
   "metadata": {},
   "source": [
    "## 8. 1. KNeighborsClassifier：KNN 分类器\n",
    "是一种基于实例的监督学习分类算法，属于K 最近邻（K-Nearest Neighbors, KNN）算法，由 sklearn.neighbors 模块提供. \\\n",
    "核心思想是：根据样本之间的“距离”关系进行投票分类。\n",
    "\n",
    "### 📌 基本原理\n",
    "给定一个训练集，当有新样本需要预测类别时： \\\n",
    "计算它与训练集中所有样本的距离；\\\n",
    "选出距离最近的 k 个样本；\\\n",
    "查看这 k 个样本所属的类别；\\\n",
    "采用多数投票（majority vote）决定新样本的类别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa54a66-0ed4-4a9b-926b-aa1a74df0a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier(\n",
    "    n_neighbors=5,           # 邻居数量 k，默认为5\n",
    "    weights='uniform',       # 权重计算方式：'uniform'（等权）或 'distance'（距离越近权重越大）\n",
    "    algorithm='auto',        # 用于计算邻居的算法（'auto', 'ball_tree', 'kd_tree', 'brute'（大数据优化））\n",
    "    leaf_size=30,            # 构建树的叶子大小（对 'ball_tree' 和 'kd_tree' 有影响）\n",
    "    p=2,                     # 距离度量的幂参数，p=2表示欧氏距离，p=1表示曼哈顿距离\n",
    "    metric='minkowski',      # 距离度量方式，默认是 'minkowski'（p=2 即欧氏距离）\n",
    "    n_jobs=None              # 并行运行数，设为-1可使用所有CPU核\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754e1fcd-3e76-4504-9ff7-1132fcdd7822",
   "metadata": {},
   "source": [
    "### 🔍 模型优缺点总结\n",
    "| 优点          | 缺点                 |\n",
    "| ----------- | ------------------ |\n",
    "| 简单直观、无需训练过程 | 预测时计算量大（需计算所有样本距离） |\n",
    "| 可处理多分类问题    | 对高维数据效果差（“维度灾难”）   |\n",
    "| 适合对小数据集分类   | 不具备模型解释性           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8209c0ba-029c-4558-83fa-6b1135d43861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e3f6be-750b-4da8-8cfb-7c31c1e94321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08735d30-f277-49c4-9352-6f0e13a686e8",
   "metadata": {},
   "source": [
    "## 8.2. KNeighborsRegressor：KNN 回归器\n",
    "是一种基于 K 近邻思想的 回归模型，其核心思想是：对于一个待预测样本，找到训练集中距离其最近的 \n",
    "𝐾个邻居，取它们的 目标变量（label）平均值或加权平均值，作为预测结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417ec29b-5299-4503-b045-cb6a86c1c4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "reg = KNeighborsRegressor(n_neighbors=3, weights='distance')\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "⚠️ 与分类器类似，但预测值为 K 个邻居的 加权平均"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfb77a4-ed45-472e-aea3-7792c0083d3e",
   "metadata": {},
   "source": [
    "| 参数            | 说明                                                          |\n",
    "| ------------- | ----------------------------------------------------------- |\n",
    "| `n_neighbors` | 邻居数量 $K$，默认为 5                                              |\n",
    "| `weights`     | 距离加权方式：<br>`'uniform'`: 所有邻居等权重 <br>`'distance'`: 距离越近，权重越大 |\n",
    "| `algorithm`   | 搜索最近邻的算法：`'auto'`, `'ball_tree'`, `'kd_tree'`, `'brute'`    |\n",
    "| `p`           | 距离度量的幂参数：<br>`p=2` 为欧氏距离（默认）<br>`p=1` 为曼哈顿距离                |\n",
    "| `metric`      | 距离度量函数，默认 `'minkowski'`，可自定义                                |\n",
    "| `leaf_size`   | `BallTree` 和 `KDTree` 的叶子大小，影响搜索速度与内存使用                     |\n",
    "| `n_jobs`      | 并行数：`-1` 表示使用所有 CPU 核心                                      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8146840d-a147-4ac8-a24c-1e141c9fdc27",
   "metadata": {},
   "source": [
    "### 📌 模型特点：\n",
    "| 特点      | 描述                            |\n",
    "| ------- | ----------------------------- |\n",
    "| ✅ 非参数模型 | 没有训练参数，预测阶段计算量大               |\n",
    "| ✅ 易于理解  | 基于“多数投票”或“平均”的思想              |\n",
    "| ⚠️ 缺点   | 对大样本、高维数据性能较差；对异常值敏感；没有“模型结构” |\n",
    "| ✅ 适合小数据 | 小样本下精度表现优异                    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ad2766-ead7-42df-910a-543b0377e37d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa1862-d04f-47e3-a99d-ef5fee4927de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28cb338c-0a2f-44cf-938a-d54cdf4407dd",
   "metadata": {},
   "source": [
    "## 8.3. RadiusNeighborsClassifier / Regressor\n",
    " 是基于“半径邻域”的 KNN 模型，与传统的 基于固定数量的邻居不同，它们根据指定的半径范围内的所有邻居来进行预测。\n",
    "\n",
    "### 📌 一、主要思想\n",
    "KNeighbors：找“固定个数 K”个最近邻。\\\n",
    "RadiusNeighbors：找“距离小于指定半径 r”的所有邻居。\n",
    "\n",
    "### 🧠 使用场景\n",
    "适用于样本密度不均匀的情况，尤其是：\\\n",
    "样本稀疏处不适合使用固定的 k。 \\\n",
    "希望控制影响范围，避免远处噪声对预测产生干扰。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee20b52e-e36b-438b-afdb-219ef7fc39dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import RadiusNeighborsClassifier,RadiusNeighborsRegressor\n",
    "\n",
    "clf = RadiusNeighborsClassifier(radius=1.0,weights='distance')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "特点：\n",
    "1.与 KNN 不同，它使用“半径”范围内的邻居\n",
    "2.如果某样本周围没有邻居，则可能抛出错误或标记为缺失"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cde7bc3-6137-4d8a-b3f3-47ba37edd0b5",
   "metadata": {},
   "source": [
    "| 参数名             | 说明                                            |\n",
    "| --------------- | --------------------------------------------- |\n",
    "| `radius`        | 半径大小，决定哪些样本是“邻居”。                             |\n",
    "| `weights`       | 权重类型：`'uniform'`（默认）或 `'distance'`（距离越近权重越大）。 |\n",
    "| `outlier_label` | 如果没有邻居，预测值填什么，默认抛出错误，可设定为特定类别。                |\n",
    "\n",
    "#### 特别说明：\n",
    "当某个测试样本在指定半径内找不到任何邻居时，默认会报错。\\\n",
    "可通过 outlier_label 或 outlier_prediction 参数处理。\\\n",
    "weights='distance' 可增强预测平滑性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d54380-3cac-4811-b4d6-81e977e52b2f",
   "metadata": {},
   "source": [
    "### ✅ 优点\n",
    "更自然地处理密度差异；\\\n",
    "可以避免“固定邻居数”引入的偏差；\\\n",
    "对异常值更鲁棒。\\\n",
    "\n",
    "### ⚠️ 缺点\n",
    "如果半径设定不合理，可能出现：\\\n",
    "没有邻居（报错）；\\\n",
    "邻居太多（计算慢）；\\\n",
    "半径调参难度比 k 值更高一些。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bd6dfc-a75b-4466-8b16-9c47fc577f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a1ae1a-60bc-4bae-9465-439ccd84e817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31d23e57-72d3-4530-be9c-3c3fa1211863",
   "metadata": {},
   "source": [
    "## 8.4. NearestNeighbors：非监督最近邻搜索\n",
    " 是 sklearn.neighbors 模块中的一个无监督模型，用于执行最近邻搜索（Nearest Neighbor Search）\\\n",
    "适用于如下任务：\\\n",
    "给定一个样本，查找其最近的点（无监督检索） \\\n",
    "构建索引结构以加速最近邻查找（如 KDTree、BallTree）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a9c47f-1e3c-4bbc-b7ae-b9b066f5cefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nn = NearestNeighbors(n_neighbors=3,algorithm='auto')\n",
    "nn.fit(X)   # 无标签 y\n",
    "distances, indices = nn.kneighbors([[1.0, 2.0]])\n",
    "\n",
    "用途：\n",
    "1.聚类前的近邻查找\n",
    "2.找相似商品 / 用户（推荐系统）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680255dd-4126-47b0-979f-a04b6bebe217",
   "metadata": {},
   "source": [
    "| 参数名           | 含义                                                            |\n",
    "| ------------- | ------------------------------------------------------------- |\n",
    "| `n_neighbors` | 要查找的最近邻个数，默认是 5                                               |\n",
    "| `radius`      | 查找半径邻居（用于 `radius_neighbors()` 方法）                            |\n",
    "| `algorithm`   | 构建索引使用的算法，可选值：`'auto'`, `'ball_tree'`, `'kd_tree'`, `'brute'` |\n",
    "| `metric`      | 距离度量，默认 `'minkowski'`，也支持 `'euclidean'`, `'manhattan'` 等      |\n",
    "\n",
    "### ✅ 常用方法说明\n",
    "| 方法名                   | 说明                                  |\n",
    "| --------------------- | ----------------------------------- |\n",
    "| `fit(X)`              | 训练模型，构建索引结构                         |\n",
    "| `kneighbors(X)`       | 查找每个样本最近的 `n_neighbors` 个邻居，返回距离和索引 |\n",
    "| `radius_neighbors(X)` | 查找每个样本一定半径内的邻居                      |\n",
    "| `kneighbors_graph(X)` | 返回最近邻连接的图结构（稀疏矩阵）                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d654946e-7c64-437c-9880-80e79cddf401",
   "metadata": {},
   "source": [
    "### 📘 典型应用场景\n",
    "无监督聚类辅助（如 DBSCAN 依赖邻居密度） \\\n",
    "推荐系统中的基于邻居的协同过滤  \\\n",
    "图像识别、文本检索等任务的快速匹配  \\\n",
    "高维数据下近似最近邻检索（可与 faiss 等库结合）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90bfeb9-9dd4-45c7-bb1c-d8aaf6f8162a",
   "metadata": {},
   "source": [
    "# 📌 KNN 特性小结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce57cc00-6531-45c6-aa79-610431623627",
   "metadata": {},
   "source": [
    "| 特性       | 描述                                     |\n",
    "| -------- | -------------------------------------- |\n",
    "| 训练速度     | 极快（无需建模）                               |\n",
    "| 预测速度     | 慢（需要计算所有距离）                            |\n",
    "| 是否易过拟合   | 是，尤其是在高维数据中                            |\n",
    "| 是否需标准化数据 | 是，**KNN对距离敏感，强烈建议使用 `StandardScaler`** |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0785f858-df2c-4d8f-acaf-1d48e4ed21ee",
   "metadata": {},
   "source": [
    "## 📈 超参数调优建议\n",
    "1、n_neighbors 越大：更平滑、抗噪声强，但可能欠拟合\n",
    "\n",
    "2、weights = 'distance'：通常效果更好（邻近样本权重更高）\n",
    "\n",
    "3、使用交叉验证：选择最佳 n_neighbors\n",
    "\n",
    "4、数据标准化很关键：特征值量级差异大 → 误导距离判断"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b55cba2-7f43-445d-bf23-0c70503290aa",
   "metadata": {},
   "source": [
    "## 🔍 可视化决策边界（仅限2D）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef74470-aa34-4fd7-8359-15c7317bd00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X 为 2D 特征\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_clusters_per_class=1, random_state=42)\n",
    "clf = KNeighborsClassifier(n_neighbors=3).fit(X, y)\n",
    "\n",
    "# 绘制边界略过代码细节，支持绘制决策边界"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0eb673-6c62-47e5-8b8d-c7fe7b686d68",
   "metadata": {},
   "source": [
    "## ✅ 模型对照表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9b7583-719a-44b5-bd4e-78fc5f3c2fbc",
   "metadata": {},
   "source": [
    "| 类名                          | 任务   | 距离标准 | 是否监督学习 |\n",
    "| --------------------------- | ---- | ---- | ------ |\n",
    "| `KNeighborsClassifier`      | 分类   | 支持多种 | 是      |\n",
    "| `KNeighborsRegressor`       | 回归   | 支持多种 | 是      |\n",
    "| `RadiusNeighborsClassifier` | 分类   | 基于半径 | 是      |\n",
    "| `RadiusNeighborsRegressor`  | 回归   | 基于半径 | 是      |\n",
    "| `NearestNeighbors`          | 查找邻居 | 支持多种 | 否      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7e40bf-9bf1-4205-b723-5baeea8fc185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19fc6b4e-8b30-4a51-bad5-075151c1240a",
   "metadata": {},
   "source": [
    "# 9.sklearn.cluster \n",
    "是 scikit-learn 中专门用于**聚类分析（Clustering）**的模块，提供了多种无监督聚类算法，如：K-Means、DBSCAN、MeanShift、Agglomerative 等。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7718276a-0b91-482a-a055-512803015b86",
   "metadata": {},
   "source": [
    "## ✅ 模块功能速查表"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f877fd7-0fd1-4bbb-8d84-ae216dde75c3",
   "metadata": {},
   "source": [
    "| 类名                        | 方法类型    | 特点 / 说明              |\n",
    "| ------------------------- | ------- | -------------------- |\n",
    "| `KMeans`                  | 分区聚类    | 最常用，基于欧几里得距离，速度快     |\n",
    "| `MiniBatchKMeans`         | 分区聚类    | 适用于大数据的 KMeans 小批量版本 |\n",
    "| `DBSCAN`                  | 密度聚类    | 可自动发现簇个数，适合不规则簇      |\n",
    "| `OPTICS`                  | 密度聚类    | 类似 DBSCAN，但可发现不同密度的簇 |\n",
    "| `MeanShift`               | 均值漂移聚类  | 不需提前设置簇个数，慢          |\n",
    "| `AgglomerativeClustering` | 层次聚类    | 自底向上的层次聚类            |\n",
    "| `Birch`                   | 层次聚类    | 可扩展到大规模数据集           |\n",
    "| `SpectralClustering`      | 谱聚类     | 适合复杂形状、图结构数据         |\n",
    "| `AffinityPropagation`     | 相似度传播聚类 | 不需指定簇个数，耗内存大         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510e9fd2-6955-4e86-adef-34e64d219050",
   "metadata": {},
   "source": [
    "## 9.1️⃣ KMeans（K 均值聚类）⭐最常用\n",
    "KMeans（K-均值）是一种无监督学习算法，广泛应用于**聚类分析（Clustering）**任务。\n",
    "### 🔶 一、KMeans 简介 \\\n",
    "KMeans 试图将数据划分为 K个簇（clusters），使得每个簇中的点到该簇“中心”的距离总和最小。\n",
    "\n",
    "### 🔶 二、基本原理（工作流程）\n",
    "KMeans 的步骤如下：\\\n",
    "1.初始化：随机选择 K 个数据点作为初始簇中心（centroids）。\\\n",
    "2.分配阶段（Assignment step）：计算每个数据点到 K 个中心的距离；把每个点分配给最近的中心，形成 K 个簇。 \\\n",
    "3.更新阶段（Update step）：对每个簇，重新计算所有点的均值作为新的簇中心。 \n",
    "\n",
    "重复步骤 2 和 3，直到： 簇分配不再变化（或）,达到最大迭代次数（或）,中心点移动小于一个阈值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f022dd-db35-437e-9948-1ea737d5f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成简单二维数据\n",
    "X = np.array([[1, 2], [1, 4], [1, 0],\n",
    "              [10, 2], [10, 4], [10, 0]])\n",
    "# 建立模型\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# 聚类结果\n",
    "print(\"簇标签：\", kmeans.labels_)\n",
    "print(\"簇中心：\", kmeans.cluster_centers_)\n",
    "\n",
    "# 可视化\n",
    "plt.scatter(X[:, 0], X[:, 1], c=kmeans.labels_)\n",
    "plt.scatter(*kmeans.cluster_centers_.T, s=200, c='red', marker='X')\n",
    "plt.title('KMeans Clustering')\n",
    "plt.show()\n",
    "\n",
    "🔹 特点：\n",
    "1.输入参数 n_clusters 需指定聚类数量\n",
    "2.对异常值敏感，适合“球状”簇\n",
    "3.适用于数值型数据，需标准化"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e01ada-f2b0-4eb3-b58b-d7f9a9766fb1",
   "metadata": {},
   "source": [
    "| 参数名            | 说明                                |\n",
    "| -------------- | --------------------------------- |\n",
    "| `n_clusters`   | 要分成的簇的数量（K）                       |\n",
    "| `init`         | 初始化方式（如 `'k-means++'`，`'random'`） |\n",
    "| `n_init`       | 算法运行的次数，选择最优结果                    |\n",
    "| `max_iter`     | 最大迭代次数                            |\n",
    "| `random_state` | 随机种子                              |\n",
    "| `tol`          | 收敛容差，中心点变化小于这个值就停止                |\n",
    "\n",
    "### 🔶 三、KMeans 的优缺点\n",
    "✅ 优点：\\\n",
    "实现简单，收敛速度快 \\\n",
    "可扩展性强，适用于大数据集 \\\n",
    "聚类结果直观可解释\n",
    "\n",
    "❌ 缺点：\\\n",
    "必须提前指定簇的个数 K  \\\n",
    "对初始中心敏感（可能陷入局部最优） \\\n",
    "对异常值和噪声敏感 \\\n",
    "只适用于凸形簇（例如球形簇）\n",
    "\n",
    "### 🔶 四、如何选择最优的 K 值？\n",
    "常用方法：\\\n",
    "Elbow Method（肘部法）：\\\n",
    "绘制不同 K 值对应的 SSE（簇内平方误差）；\\\n",
    "观察“肘部”位置，就是最佳 K。 \\\n",
    "Silhouette Score（轮廓系数）：\\\n",
    "评价每个样本的聚类合理性；\\\n",
    "取值范围为 [-1, 1]，越大越好。\n",
    "\n",
    "### 🔶 五、适合应用场景\n",
    "客户分群（Customer Segmentation）\\\n",
    "图像压缩  \\\n",
    "文本聚类 \\\n",
    "城市区域划分 \\\n",
    "社交网络中的社群检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07212968-b960-48db-b0cd-1d2fb01db950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ecce56-379e-4354-bb9a-356ac2cd04da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bb9a044-4d1b-4547-985a-79eb211f43ff",
   "metadata": {},
   "source": [
    "## 9.2️⃣ DBSCAN（基于密度的聚类）\n",
    "### 🔷 一、DBSCAN 是什么？\n",
    "DBSCAN 是一种基于密度的无监督聚类算法，适用于具有任意形状的簇和带噪声的数据。\n",
    "### 🔷 二、基本思想\n",
    "DBSCAN 利用两个参数定义“密度”：\n",
    "| 参数            | 含义                |\n",
    "| ------------- | ----------------- |\n",
    "| `eps`         | 邻域的最大半径（ε）        |\n",
    "| `min_samples` | 邻域中最少的数据点数（包含点本身） |\n",
    "\n",
    "基于这两个参数，数据点被分为三类：\\\n",
    "1.✅ 核心点（Core Point）：在半径 eps 内至少包含 min_samples 个点。\\\n",
    "2.⭕ 边界点（Border Point）：本身不满足核心点条件，但在某个核心点的邻域内。\\\n",
    "3.❌ 噪声点（Noise Point / Outlier）：既不是核心点，也不是边界点。\n",
    "\n",
    "### 🔷 三、算法流程\n",
    "1.对每个未访问的数据点：若是核心点，则创建一个新簇，并将密度可达的所有点加入。\\\n",
    "2.重复上一步，直到所有点都被处理。\\\n",
    "3.不属于任何簇的点，被标记为“噪声”。\n",
    "### 🔷 四、DBSCAN 的优缺点\n",
    "✅ 优点：\\\n",
    "不需要指定聚类数量 K（vs. KMeans）\\\n",
    "可以发现任意形状的簇（vs. KMeans 只适合球形）\\\n",
    "对异常值/噪声鲁棒性强\n",
    "\n",
    "❌ 缺点：\\\n",
    "对 eps 和 min_samples 的选择敏感\\\n",
    "高维数据中效果可能较差（维度灾难）\\\n",
    "不适合密度差异很大的簇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a97fd2-042c-4206-8cb2-7a06087055d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "# 生成数据（有弯月形状）\n",
    "X, _ = make_moons(n_samples=300, noise=0.05, random_state=0)\n",
    "\n",
    "# 建立 DBSCAN 模型\n",
    "db = DBSCAN(eps=0.2, min_samples=5)\n",
    "labels = db.fit_predict(X)\n",
    "\n",
    "# 可视化\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.show()\n",
    "\n",
    "🔹 特点：\n",
    "1.可发现任意形状的簇\n",
    "2.eps 为“邻域半径”\n",
    "3.可自动识别噪声（labels == -1）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a0fe04-98a6-4cc9-bdab-a83278cc9f6c",
   "metadata": {},
   "source": [
    "### 五、参数选择建议\n",
    "| 参数            | 如何调                                  |\n",
    "| ------------- | ------------------------------------ |\n",
    "| `eps`         | 使用 K 距离图法（K-distance plot）找到转折点作为合适值 |\n",
    "| `min_samples` | 一般取值为 `2 * 数据维度`；常用范围：5 \\~ 10        |\n",
    "\n",
    "📌 K 距离图：对每个点，找出其第 k 近邻的距离，排序后画图。找到“拐点”作为 eps。\n",
    "\n",
    "### 🔷 六、与 KMeans 的对比总结\n",
    "| 特性        | KMeans    | DBSCAN |\n",
    "| --------- | --------- | ------ |\n",
    "| 是否需指定簇数   | ✅ 是       | ❌ 否    |\n",
    "| 是否能发现任意形状 | ❌ 否（只能球形） | ✅ 是    |\n",
    "| 是否对异常值敏感  | ✅ 敏感      | ❌ 不敏感  |\n",
    "| 对密度变化的适应性 | ❌ 差       | ❌ 差    |\n",
    "| 易于理解和实现   | ✅ 简单      | ❌ 稍复杂  |\n",
    "\n",
    "### 🔷 七、应用场景 \n",
    "异常检测（如网络攻击检测、信用卡欺诈）\\\n",
    "图像处理（图像分割）\\\n",
    "空间数据分析（如地理数据聚类）\\\n",
    "社交网络关系聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c4f7b9-e1b7-4fdd-8960-6cb6d69ee14f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015c8aa8-1a91-48f6-8182-caefd87d53e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61151e3b-8325-4e26-8841-856777d18b0b",
   "metadata": {},
   "source": [
    "## 9.3️⃣ AgglomerativeClustering（层次聚类）\n",
    "### 一、🔍 什么是 Agglomerative Clustering？\n",
    "Agglomerative Clustering 是一种层次聚类算法（Hierarchical Clustering），属于自底向上的方式。\\\n",
    "它的基本思路是：\\\n",
    "一开始把每个数据点当作一个单独的簇； \\\n",
    "然后逐步将最相似的两个簇合并，直到满足某个停止条件（如合并成固定数量的簇）。\n",
    "\n",
    "### 二、📌 核心概念\n",
    "1. 距离度量（用于衡量两个簇之间的距离） \\\n",
    "聚类时必须定义“簇与簇”的距离，这里有多种选择：\n",
    "| linkage（连接方式） | 说明                              |\n",
    "| ------------- | ------------------------------- |\n",
    "| `ward`        | 最小化簇内平方误差（类似最小方差准则）✅ 推荐用于欧几里得距离 |\n",
    "| `average`     | 两簇间所有点对的平均距离                    |\n",
    "| `complete`    | 两簇间所有点对的最大距离（最大连接）              |\n",
    "| `single`      | 两簇间所有点对的最小距离（最小连接）              |\n",
    "\n",
    "2. 距离函数（metric）\\\n",
    "常见的有欧几里得距离（默认）、曼哈顿距离、余弦距离等。\n",
    "\n",
    "### 三、📘 算法流程（Agglomerative）\n",
    "1.将每个点初始化为一个簇；\\\n",
    "2.计算所有簇之间的距离；\\\n",
    "3.合并距离最近的两个簇；\\\n",
    "4.更新距离矩阵；\\\n",
    "5.重复步骤 2–4，直到满足条件（如簇数达到 n_clusters）。\n",
    "\n",
    "### 四、✅ 优缺点分析\n",
    "✅ 优点：\\\n",
    "不需要指定初始中心（不像 KMeans）\\\n",
    "能处理任意形状的簇（依赖于 linkage 选择）\\\n",
    "可生成聚类的层次结构（树状图 / 树形图）\n",
    "\n",
    "❌ 缺点：\\\n",
    "算法复杂度高：O(n²)，不适合超大数据集  \\\n",
    "聚类不可回退，一旦合并不能撤销  \\\n",
    "对噪声不太鲁棒(对噪声敏感， 鲁棒 ==不敏感 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ebfe83-d61d-4e4d-ba1a-c99a5d7930b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "agg = AgglomerativeClustering(n_clusters=3, linkage='ward')\n",
    "labels = agg.fit_predict(X)\n",
    "\n",
    "🔹 特点：\n",
    "1.不支持 .predict()（不能对新样本预测）\n",
    "2.支持 linkage='ward', 'average', 'complete'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61dbffe-a900-48e9-9b38-baa32ed5f314",
   "metadata": {},
   "source": [
    "### 五、🌲 可视化层次结构：树状图（Dendrogram）\n",
    "虽然 AgglomerativeClustering 模型本身不能直接画树状图，但可以借助 scipy 的 dendrogram 来实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd875f56-fa54-4736-8ab5-b015fb7ec027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 计算层次聚类链接矩阵\n",
    "Z = linkage(X, method='ward')\n",
    "\n",
    "# 绘制树状图\n",
    "plt.figure(figsize=(10, 5))\n",
    "dendrogram(Z)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Data Point Index')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d6125a-7427-4739-a923-3a36c6cc7cb8",
   "metadata": {},
   "source": [
    "### 六、📊 Agglomerative vs KMeans vs DBSCAN\n",
    "| 特性       | KMeans | DBSCAN | Agglomerative   |\n",
    "| -------- | ------ | ------ | --------------- |\n",
    "| 是否需指定簇数  | ✅ 是    | ❌ 否    | ✅ 是（可选）         |\n",
    "| 噪声处理     | ❌ 不擅长  | ✅ 很好   | ❌ 不擅长           |\n",
    "| 形状限制     | ❌ 球形为主 | ✅ 任意   | ✅ 任意（视 linkage） |\n",
    "| 是否支持层次结构 | ❌ 否    | ❌ 否    | ✅ 是             |\n",
    "| 复杂度      | ⬇ 快    | ⬆ 中    | ⬆ 慢（O(n²)）      |\n",
    "\n",
    "### 七、📌 应用场景\n",
    "生物信息学中的基因聚类  \\\n",
    "社会网络中的用户关系图分析  \\\n",
    "文档聚类与主题建模  \\\n",
    "图像分割任务（如医学图像）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1214e65-1c6e-4b32-8337-8523bc720b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd764ac0-adac-427d-91a9-505cb707724e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae8b9339-8595-4bec-ac67-f7a41397efb1",
   "metadata": {},
   "source": [
    "## 9.4️⃣ MeanShift（均值漂移）\n",
    "是一种基于密度的聚类算法，它不需要预先指定簇的数量，而是通过不断向数据密度上升的方向“漂移”来寻找簇的中心。\n",
    "\n",
    "### 🔍 一、核心思想\n",
    "MeanShift 试图在数据分布中找到**“高密度区域”**（即模式的峰值），通过不断更新中心点向密度梯度上升方向移动，直到收敛。\\\n",
    "它的基本过程是：\\\n",
    "对于每个点，找到它周围的邻域（带宽内的点），计算这些邻域点的均值，然后将该点向这个均值移动 —— 不断迭代，直到到达局部密度最大值。\n",
    "\n",
    "最终，所有移动到相同“峰值”的点归为一簇。\n",
    "\n",
    "### 🧮 二、关键参数\n",
    "| 参数            | 说明                       |\n",
    "| ------------- | ------------------------ |\n",
    "| `bandwidth`   | 核函数的带宽（决定邻域范围）           |\n",
    "| `kernel`      | 默认使用高斯核（Gaussian kernel） |\n",
    "| `bin_seeding` | 是否使用网格加速算法（默认 False）     |\n",
    "\n",
    "### 📘 三、算法流程\n",
    "1.对每个点以 bandwidth 为半径找出邻域；\n",
    "2.计算邻域点的均值（质心）；\n",
    "3.将当前点移动到这个均值位置；\n",
    "4.重复步骤 1-3，直到收敛（移动距离小于阈值）；\n",
    "5.所有收敛到相同点的点归为同一簇。\n",
    "\n",
    "### ✅ 四、优缺点\n",
    "✅ 优点：\n",
    "--不需要预设簇数（vs KMeans）\\\n",
    "--能发现任意形状簇（vs KMeans 只能发现球形）\\\n",
    "--对噪声有一定鲁棒性  \\\n",
    "--适合用于图像平滑、边界检测等任务\n",
    "\n",
    "❌ 缺点：\n",
    "--对 bandwidth 参数敏感 \\\n",
    "--高维数据中计算量大（速度慢）\\\n",
    "--适合小规模或低维数据集 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241c48ea-836a-4e61-b0cc-350f4464f5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成数据\n",
    "X, _ = make_blobs(n_samples=300, centers=3, cluster_std=0.7, random_state=42)\n",
    "\n",
    "# 自动估算 bandwidth\n",
    "bandwidth = estimate_bandwidth(X, quantile=0.2, n_samples=100)\n",
    "\n",
    "# 建立 MeanShift 模型\n",
    "ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "ms.fit(X)\n",
    "\n",
    "# 获取聚类结果\n",
    "labels = ms.labels_\n",
    "cluster_centers = ms.cluster_centers_\n",
    "\n",
    "# 可视化\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')\n",
    "plt.scatter(cluster_centers[:, 0], cluster_centers[:, 1], s=200, c='red', marker='X')\n",
    "plt.title(\"MeanShift Clustering\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "🔹 特点：\n",
    "1.动估计簇数，无需指定 n_clusters\n",
    "2.慢，适合小数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39619b23-9f9a-4c60-ba27-447d4659337c",
   "metadata": {},
   "source": [
    "### 📊 五、MeanShift 与其他聚类方法的对比\n",
    "| 特性       | KMeans | DBSCAN | Agglomerative | MeanShift |\n",
    "| -------- | ------ | ------ | ------------- | --------- |\n",
    "| 是否需要预设簇数 | ✅ 是    | ❌ 否    | ✅ 可选          | ❌ 否       |\n",
    "| 形状适应性    | ❌ 球形   | ✅ 任意   | ✅ 任意          | ✅ 任意      |\n",
    "| 噪声处理     | ❌ 差    | ✅ 好    | ❌ 一般          | ✅ 一般      |\n",
    "| 可扩展性（速度） | ✅ 快    | ⬆ 中    | ❌ 慢           | ❌ 慢       |\n",
    "| 支持层次结构   | ❌ 否    | ❌ 否    | ✅ 是           | ❌ 否       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75a33f8-518c-4cc8-af65-18ca5013b9c4",
   "metadata": {},
   "source": [
    "### 🧠 六、适用场景\n",
    "图像分割（如 OpenCV 中用 MeanShift 做颜色分割）\\\n",
    "模式识别 \\\n",
    "人群行为分析 \\\n",
    "数据中自动发现聚类数量的任务\n",
    "\n",
    "## 📌 七、注意事项和实用技巧\n",
    "使用 sklearn.cluster.estimate_bandwidth 自动选取 bandwidth\\\n",
    "如果数据量大，可以使用 bin_seeding=True 加速计算\\\n",
    "数据需归一化处理以保证带宽一致性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd231798-886d-4681-8f0b-28bbd15e1e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e9faf8-d2bd-4d72-a872-8d17ce934a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a21e0b2-9e9f-43bd-a1c2-f5274cdb96e8",
   "metadata": {},
   "source": [
    "## 9.5️⃣ SpectralClustering（谱聚类）\n",
    "### ✅ 一、谱聚类是什么？\n",
    "谱聚类（Spectral Clustering）是一种基于图论的聚类算法，它将聚类问题转化为图划分问题（Graph Partitioning），再通过**谱分解（特征值分解）**进行降维，并使用传统聚类算法（如 KMeans）在降维空间中完成聚类。\n",
    "\n",
    "### 🧠 二、核心思想\n",
    "构造相似度矩阵（Affinity Matrix）：衡量每对样本之间的相似度，形成一个图。\\\n",
    "构建图的拉普拉斯矩阵（Laplacian Matrix）\\\n",
    "计算拉普拉斯矩阵的前 k 个特征向量\\\n",
    "将数据映射到这些特征向量构成的低维空间\\\n",
    "在新空间中用 KMeans 进行聚类\n",
    "\n",
    "### 📐 三、与 KMeans 的关键区别\n",
    "| 特性        | KMeans | Spectral Clustering |\n",
    "| --------- | ------ | ------------------- |\n",
    "| 适合聚类形状    | 球形     | 任意形状（如弯月形、环形）       |\n",
    "| 算法类型      | 距离最小化  | 图论划分                |\n",
    "| 是否需预设簇数   | ✅ 是    | ✅ 是                 |\n",
    "| 是否易陷入局部最优 | ✅ 容易   | ❌ 更稳定               |\n",
    "| 算法复杂度     | ⬇ 快    | ⬆ 慢（O(n³)）          |\n",
    "\n",
    "### 🧮 四、相似度矩阵（Affinity Matrix）\n",
    "谱聚类中需要构造一个 n × n 的相似度矩阵，表示每对点之间的“边权重”。\\\n",
    "常用方法：\\\n",
    "1.RBF（高斯核）相似度：\\\n",
    "2.最近邻（Nearest Neighbors）相似度：仅连接每个点的 k 个近邻点，其余置为 0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d892df1-6f53-4cba-ac37-a7d8617523d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.datasets import make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成非球形数据\n",
    "X, _ = make_moons(n_samples=300, noise=0.05, random_state=42)\n",
    "\n",
    "# 使用谱聚类\n",
    "sc = SpectralClustering(n_clusters=2, affinity='rbf', assign_labels='kmeans', random_state=42)\n",
    "labels = sc.fit_predict(X)\n",
    "\n",
    "# 可视化结果\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')\n",
    "plt.title(\"Spectral Clustering\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "🔹 特点：\n",
    "1.适合处理非凸形状、图结构数据\n",
    "2.构造相似度矩阵，适用于复杂结构数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebebf9a-de50-4b24-aa3e-27bfe8b62c9c",
   "metadata": {},
   "source": [
    "| 参数              | 说明                                                       |\n",
    "| --------------- | -------------------------------------------------------- |\n",
    "| `n_clusters`    | 聚类数量                                                     |\n",
    "| `affinity`      | 相似度计算方式： `'rbf'`, `'nearest_neighbors'`, `'precomputed'` |\n",
    "| `assign_labels` | 使用哪种聚类方式： `'kmeans'`, `'discretize'`                     |\n",
    "| `gamma`         | RBF 核函数的 gamma 值                                         |\n",
    "| `n_neighbors`   | 当 affinity='nearest\\_neighbors' 时使用                      |\n",
    "\n",
    "\n",
    "### ✅ 五、优缺点总结\n",
    "✅ 优点：\\\n",
    "能识别任意形状的簇（尤其是非凸簇）\\\n",
    "对初始化不敏感（相比 KMeans 更稳定）\\\n",
    "适合于图结构数据或关系数据\n",
    "\n",
    "❌ 缺点：\\\n",
    "对计算资源要求高（特征分解是 O(n³) 级）\\\n",
    "相似度矩阵和拉普拉斯矩阵较难构造和调参\\\n",
    "不适合大规模样本数据（>10,000）\n",
    "\n",
    "### 📊 六、与其他聚类方法对比\n",
    "| 特性      | KMeans | DBSCAN | Agglomerative | MeanShift | SpectralClustering |\n",
    "| ------- | ------ | ------ | ------------- | --------- | ------------------ |\n",
    "| 是否需预设簇数 | ✅ 是    | ❌ 否    | ✅ 是（可选）       | ❌ 否       | ✅ 是                |\n",
    "| 处理非凸形状  | ❌ 差    | ✅ 好    | ✅ 中等          | ✅ 好       | ✅ 非常好              |\n",
    "| 支持噪声检测  | ❌ 无    | ✅ 有    | ❌ 无           | ✅ 有       | ❌ 无                |\n",
    "| 可扩展性    | ✅ 强    | ⬆ 中    | ❌ 差           | ❌ 差       | ❌ 差                |\n",
    "| 基本原理    | 距离最小化  | 密度     | 层次树           | 均值漂移      | 图划分 + 特征值分解        |\n",
    "\n",
    "### 🔍 七、适合应用场景\n",
    "图像分割（如处理像素图）\\\n",
    "社交网络分析（如社群检测）\\\n",
    "非欧式数据（如基因组数据、谱图数据）\\\n",
    "图结构数据或“点之间关系”强的任务\n",
    "## 🔚 八、扩展方向\n",
    "拉普拉斯矩阵有三种：普通 Laplacian、对称归一化、随机归一化\\\n",
    "可结合图神经网络、图嵌入（如 DeepWalk、Node2Vec）做更强大聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb122924-c5cf-4901-922b-d729a96eec18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b8762d-3c83-4b63-bb76-8f87a347034b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77b9ea69-fc1c-4c50-8141-9584841ee7f9",
   "metadata": {},
   "source": [
    "## 9.6️⃣ Birch（大规模聚类）\n",
    "### ✅ 一、BIRCH 是什么？\n",
    "BIRCH 是一种面向大数据集的层次型聚类算法，能够在内存有限的条件下有效进行聚类。它特别适合大规模、连续输入的数据流。\\\n",
    "它的核心优势是：\\\n",
    "一次性扫描数据即可完成聚类（单遍算法）\\\n",
    "内存友好型设计\\\n",
    "支持增量学习（Incremental Learning）\n",
    "\n",
    "### 🧠 二、核心思想\n",
    "BIRCH 的核心是构建一个 CF Tree（Clustering Feature Tree），它是一种高度压缩的聚类结构，可以用来表示海量数据的统计特征。\\\n",
    "📌 Clustering Feature（CF 聚类特征）：\\\n",
    "每个聚类簇用一个三元组来表示：\n",
    "\n",
    "CF = (𝑁,∑𝑥𝑖,∑𝑥𝑖2)\n",
    "\n",
    "其中：\\\n",
    "N：聚类中的点数\\\n",
    "∑x_i：点的线性和\\\n",
    "∑x_i²：点的平方和\\\n",
    "这样可以快速计算簇的：均值、方差、半径、直径等信息，而无需保留所有点！\n",
    "\n",
    "### 🧱 三、CF Tree（聚类特征树）\n",
    "CF Tree 是一个平衡树结构：\\\n",
    "每个非叶子节点 代表一个簇的摘要（多个子簇）\\\n",
    "每个叶子节点 存储簇的 CF 条目（实际簇）\\\n",
    "🌟 BIRCH通过不断地将新样本插入 CF Tree，动态更新已有簇或生成新簇，逐步压缩数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06935dda-38f0-47f8-88db-e7b6f14963a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import Birch\n",
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 创建数据\n",
    "X, _ = make_blobs(n_samples=1000, centers=4, cluster_std=0.5, random_state=0)\n",
    "\n",
    "# 使用 BIRCH 聚类\n",
    "birch = Birch(n_clusters=4)\n",
    "birch.fit(X)\n",
    "labels = birch.predict(X)\n",
    "\n",
    "# 可视化\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')\n",
    "plt.title('BIRCH Clustering')\n",
    "plt.show()\n",
    "\n",
    "🔹 特点：\n",
    "1.适合大数据\n",
    "2.可在线学习，内存消耗小"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e5d3c2-be3e-41dd-a3d0-af58452f8040",
   "metadata": {},
   "source": [
    "| 参数                 | 说明                           |\n",
    "| ------------------ | ---------------------------- |\n",
    "| `threshold`        | 每个簇的最大半径（聚合的紧密程度）            |\n",
    "| `branching_factor` | 每个节点最大子簇数量（默认 50）            |\n",
    "| `n_clusters`       | 最终的簇数（如果为 None，则只构建 CF Tree） |\n",
    "| `compute_labels`   | 是否计算标签（默认 True）              |\n",
    "\n",
    "### ✅ 四、优缺点总结\n",
    "✅ 优点：\\\n",
    "单次扫描即可完成聚类（适合大数据）\\\n",
    "可以增量训练（partial_fit）\\\n",
    "可作为其他聚类算法（如 KMeans）的预处理步骤\\\n",
    "能有效处理内存受限环境\n",
    "\n",
    "❌ 缺点：\n",
    "只适用于数值型特征\\\n",
    "对参数 threshold 和 branching_factor 较敏感\\\n",
    "不适合非凸形状簇（如弯月形）\n",
    "\n",
    "### 📊 五、与其他聚类算法对比\n",
    "| 特性      | KMeans | DBSCAN | Spectral | MeanShift | BIRCH   |\n",
    "| ------- | ------ | ------ | -------- | --------- | ------- |\n",
    "| 是否需预设簇数 | ✅ 是    | ❌ 否    | ✅ 是      | ❌ 否       | ✅ 可选    |\n",
    "| 适合大数据   | ❌ 较差   | ❌ 较差   | ❌ 差      | ❌ 差       | ✅ 非常好   |\n",
    "| 支持增量学习  | ❌ 否    | ❌ 否    | ❌ 否      | ❌ 否       | ✅ 支持    |\n",
    "| 聚类形状适应性 | ❌ 差    | ✅ 好    | ✅ 非凸     | ✅ 非凸      | ❌ 球形为主  |\n",
    "| 时间复杂度   | ⬇ 快    | ⬆ 中    | ⬆ 慢      | ⬆ 慢       | ✅ 快（线性） |\n",
    "\n",
    "### 🎯 六、BIRCH 的典型应用场景\n",
    "大规模文本向量聚类（如新闻聚类） \\\n",
    "流式数据处理（实时系统）\\\n",
    "初步压缩数据后再聚类（结合 KMeans）\\\n",
    "内存受限环境下的数据聚类\n",
    "\n",
    "### 🌟 七、补充建议\n",
    "你可以使用 Birch(n_clusters=None) 来只构建 CF Tree，再手动调用其他聚类算法（如 KMeans）处理叶子节点聚类。\\\n",
    "threshold 和 branching_factor 是调优性能与效果的关键。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b75264a-5b58-4517-84ec-23ed104f0e58",
   "metadata": {},
   "source": [
    "## 📌 常用 API 说明"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40d1182-89e5-48f4-ba52-7ccb74b43f42",
   "metadata": {},
   "source": [
    "| 属性 / 方法             | 说明             |\n",
    "| ------------------- | -------------- |\n",
    "| `.fit(X)`           | 训练模型           |\n",
    "| `.predict(X)`       | 预测（非所有模型都支持）   |\n",
    "| `.fit_predict(X)`   | 训练并返回每个样本的簇标签  |\n",
    "| `.labels_`          | 聚类结果（每个样本的簇编号） |\n",
    "| `.cluster_centers_` | 聚类中心（如支持）      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd4f7f1-b481-49cb-91eb-7ffc4fc893a7",
   "metadata": {},
   "source": [
    "## 📈 聚类效果评估指标（来自 sklearn.metrics）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdd6149-073c-4c77-a25a-72028f0e647f",
   "metadata": {},
   "source": [
    "| 指标函数                           | 描述        |\n",
    "| ------------------------------ | --------- |\n",
    "| `adjusted_rand_score`          | 调整后的兰德系数  |\n",
    "| `normalized_mutual_info_score` | 归一化互信息    |\n",
    "| `silhouette_score`             | 轮廓系数（最常用） |\n",
    "| `completeness_score`           | 聚类结果完整性   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e0722f-ad7b-41a6-a664-b4158f5094d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe79672d-9a83-4ca8-a20d-1a64f56c21e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0adef2bf-d35c-4998-886e-5867916c77b1",
   "metadata": {},
   "source": [
    "# 10.sklearn.metrics \n",
    "是 scikit-learn 中用于 模型评估与性能度量 的模块，支持分类、回归、聚类、排序、推荐系统、距离函数等多种评估方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87389092-953a-4c30-b75b-caa24faa0d51",
   "metadata": {},
   "source": [
    "## ✅ 模块功能总览"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01e46bb-471e-4687-b9e8-eedd7227b282",
   "metadata": {},
   "source": [
    "| 任务类型       | 常用评估函数                                                                                                                        |\n",
    "| ---------- | ----------------------------------------------------------------------------------------------------------------------------- |\n",
    "| 📊 分类任务    | `accuracy_score`, `precision_score`, `recall_score`, `f1_score`, `confusion_matrix`, `roc_auc_score`, `classification_report` |\n",
    "| 📈 回归任务    | `mean_squared_error`, `mean_absolute_error`, `r2_score`, `explained_variance_score`                                           |\n",
    "| 📎 聚类任务    | `adjusted_rand_score`, `silhouette_score`, `normalized_mutual_info_score`                                                     |\n",
    "| 📏 距离度量    | `euclidean_distances`, `pairwise_distances`                                                                                   |\n",
    "| 🔢 排序/推荐系统 | `ndcg_score`, `dcg_score`, `precision_recall_curve`, `average_precision_score`                                                |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b026816-6a99-49ba-aede-b6545391415a",
   "metadata": {},
   "source": [
    "## 🎯 分类评估函数详解（最常用）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36e9368-7ca0-49a3-8236-dba1e50fbda5",
   "metadata": {},
   "source": [
    "## 10.1️⃣ accuracy_score  （准确率）\n",
    "### ✅ 一、什么是 accuracy_score？\n",
    "accuracy_score 是 分类问题中最常用的评估指标之一，用于衡量预测值与真实值之间有多少是正确的。\n",
    "其定义为：\\\n",
    "Accuracy= （TP+TN）/（TP+TN+FP+FN） \\\n",
    "即：正确预测的样本数 ÷ 总样本数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2f0775b-20bf-48fd-95a8-dbd3fe83ee50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.60\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 示例\n",
    "y_true = [1, 0, 1, 1, 0]\n",
    "y_pred = [1, 0, 0, 1, 1]\n",
    "\n",
    "score = accuracy_score(y_true, y_pred)\n",
    "print(f\"Accuracy: {score:.2f}\")\n",
    "\n",
    "# 输出：0.60  表示：5 个样本中有 3 个预测正确，准确率为 60%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4ff875-d51e-472b-83bf-ec257dbffac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true, y_pred, normalize=True, sample_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b8daf2-7c49-49df-98ed-0355ad2125bd",
   "metadata": {},
   "source": [
    "### 📌 二、常用参数\n",
    "| 参数              | 说明                                      |\n",
    "| --------------- | --------------------------------------- |\n",
    "| `y_true`        | 真实标签                                    |\n",
    "| `y_pred`        | 预测标签                                    |\n",
    "| `normalize`     | 是否返回比例（默认 True）；若设为 False，则返回“正确预测的样本数” |\n",
    "| `sample_weight` | 各样本的权重（用于加权准确率）                         |\n",
    "\n",
    "### 🧠 三、适用场景\n",
    "二分类（如：是否患病、是否点击）\\\n",
    "多分类（如：手写数字识别）\\\n",
    "用于分类模型的初步评估\n",
    "\n",
    "### ⚠️ 四、准确率的局限性\n",
    "尽管准确率很直观，但它并不总是可靠的指标，特别是在以下情况下：\\\n",
    "❌ 不适合类别不平衡的数据！\n",
    "\n",
    "举例："
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a9716cc-ef04-463b-b336-8dfc93f7a14a",
   "metadata": {},
   "source": [
    "# 非平衡样本\n",
    "y_true = [0]*95 + [1]*5       # 真实只有5%是正类\n",
    "y_pred = [0]*100              # 模型预测全部为负类\n",
    "\n",
    "accuracy_score(y_true, y_pred)  # 输出 0.95\n",
    "\n",
    "虽然准确率是 95%，但模型根本没有识别出正类 —— 这时应使用：\n",
    "Precision（精确率）\n",
    "Recall（召回率）\n",
    "F1-score（综合指标）\n",
    "confusion_matrix（混淆矩阵）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc09906d-9b31-400f-892d-60695685808e",
   "metadata": {},
   "source": [
    "### 📊 五、准确率 vs 其他评估指标\n",
    "| 指标                  | 含义                       | 适用场景        |\n",
    "| ------------------- | ------------------------ | ----------- |\n",
    "| **accuracy**        | 正确预测的比例                  | 类别均衡        |\n",
    "| **precision**       | 正类预测中有多少是真的              | 注重“假阳性”影响   |\n",
    "| **recall**          | 真正类中有多少被预测中              | 注重“假阴性”影响   |\n",
    "| **f1\\_score**       | precision 与 recall 的调和平均 | 类别不平衡、需综合评估 |\n",
    "| **roc\\_auc\\_score** | 不同阈值下的分类能力               | 二分类任务效果整体   |\n",
    "\n",
    "### ✅ 六、小结\n",
    "accuracy_score 简单直观，是初步评估模型性能的好工具。\\\n",
    "但在类别不均衡数据上不能单独依赖准确率。\\\n",
    "实际工作中常与 precision, recall, f1_score, confusion_matrix 一起综合评估模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f3a3ca-a71d-431f-b254-ba72ad23ed83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e152fc-fa1a-49e6-a825-69cde6927c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19b7f134-2076-4c16-91c1-7c5c7e9f34a8",
   "metadata": {},
   "source": [
    "## 10.2️⃣ precision_score / recall_score / f1_score\n",
    "### 🔹 1. precision_score（精确率）\n",
    "定义：预测为正类的样本中，有多少是真正的正类。\\\n",
    "公式：\n",
    "\n",
    "Precision = 𝑇𝑃 / (𝑇𝑃+𝐹𝑃)\n",
    " \n",
    "TP（True Positive）：真正例，预测为正，实际为正 \\\n",
    "FP（False Positive）：假正例，预测为正，实际为负 \\\n",
    "适用场景：对“假阳性（误判为正）”更敏感的场景，如垃圾邮件识别、肿瘤检测等。\n",
    "\n",
    "### 🔹 2. recall_score（召回率）\n",
    "定义：所有正类样本中，有多少被正确预测为正类。\\\n",
    "公式：\n",
    "\n",
    "Recall = 𝑇𝑃 / (TP+FN)\n",
    "\n",
    "FN（False Negative）：假负例，预测为负，实际为正 \\\n",
    "适用场景：对“假阴性（漏判为负）”更敏感的场景，如疾病筛查、客户流失预警等。\n",
    "\n",
    "### 🔹 3. f1_score（F1 分数）\n",
    "定义：精确率和召回率的调和平均，用于在两者之间平衡。\\\n",
    "公式：\n",
    "\n",
    "F1 = (2 × Precision × Recall) / (Precision + Recall) \n",
    "\n",
    "适用场景：当你希望平衡“误判”和“漏判”的影响时，尤其在类别不平衡的数据集上更有效。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1e4ff1-5160-4acf-9baa-eb5bb7ed717f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "y_true = [0, 1, 1, 1, 0, 1, 0]\n",
    "y_pred = [0, 1, 0, 1, 0, 1, 1]\n",
    "\n",
    "print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fe4c5d-003f-4170-911f-2fba5ee51a82",
   "metadata": {},
   "source": [
    "| 指标            | 含义           |\n",
    "| ------------- | ------------ |\n",
    "| 精确率 Precision | 正类中预测对的比例    |\n",
    "| 召回率 Recall    | 所有正类中被预测对的比例 |\n",
    "| F1-score      | 精确率与召回率的调和平均 |\n",
    "\n",
    "\n",
    "### 🔹 多分类 / 多标签支持\n",
    "可使用参数：\\\n",
    "average='macro'：对每一类分别计算，再取平均（不考虑类别不平衡）\\\n",
    "average='micro'：统计全局的 TP / FP / FN，再计算整体值（适合多标签任务）\\\n",
    "average='weighted'：根据每类样本数加权平均（考虑类别不平衡）\\\n",
    "average='binary'：只针对二分类（默认）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8396522-5370-4c74-a324-ee9d31a53192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654f4de4-339e-4306-9adb-b0e43e046bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a830c47b-a703-455f-8989-3cf2992d3e39",
   "metadata": {},
   "source": [
    "## 10.3️⃣ confusion_matrix（混淆矩阵）\n",
    "#### ✅ 作用：\n",
    "confusion_matrix 用于评估分类模型的性能，统计预测值与真实值的 对应关系，是精度、召回率、F1 等指标的基础。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5580854d-8f72-4033-9246-01ca93458de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "# 1. 设置中文字体（推荐使用 SimHei 黑体，支持中文）\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']  # 支持中文的字体\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 解决负号 '-' 显示为方块的问题\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# 绘图\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,   # 每个格子中会显示数字\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[0, 1],\n",
    "    yticklabels=[0, 1],\n",
    "    linewidths=1,            # 网格线宽度\n",
    "    linecolor='black',       # 网格线颜色\n",
    "    cbar=False               # 不显示右侧颜色条（可选）\n",
    ")\n",
    "plt.xlabel(\"预测标签\")\n",
    "plt.ylabel(\"真实标签\")\n",
    "plt.title(\"混淆矩阵\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c1bf09-037c-458e-b433-c5eab1e85a68",
   "metadata": {},
   "source": [
    "|           | 预测为正类 (1) | 预测为负类 (0) |\n",
    "| --------- | --------- | --------- |\n",
    "| 实际为正类 (1) | TP（真正）    | FN（假负）    |\n",
    "| 实际为负类 (0) | FP（假正）    | TN（真负）    |\n",
    "\n",
    "📌 参数详解：\\\n",
    "y_true: 真实标签列表或数组。\\\n",
    "y_pred: 模型预测的标签。\\\n",
    "labels: 可选，指定分类的标签顺序。\\\n",
    "sample_weight: 各样本权重。\\\n",
    "normalize: 归一化方式：(None: 返回原始计数)；('true': 每行归一化)；('pred': 每列归一化)；('all': 整体归一化)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f7d5b1-400d-4d7a-b0be-70ffb63c9882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b600bf2d-5adc-4be3-8a44-75306a0c05fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9edc0c78-f3fe-42f7-8201-5815ecb84649",
   "metadata": {},
   "source": [
    "## 10.4️⃣ classification_report（报告）\n",
    "#### ✅ 作用：\n",
    "classification_report 用于评估分类模型的表现，一行一类地列出每个类别的 precision（精度）、recall（召回率）、f1-score 以及支持度（support），也会输出宏平均和加权平均。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cba56be-73d3-4987-a693-3dc3d3533f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    labels=None,\n",
    "    target_names=None,\n",
    "    sample_weight=None,\n",
    "    digits=2,\n",
    "    output_dict=False,\n",
    "    zero_division='warn'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dbf854-80a4-4928-8bbc-0d236a7f94db",
   "metadata": {},
   "source": [
    "| 类别               | precision | recall  | f1-score    | support |\n",
    "| ---------------- | --------- | ------- | ----------- | ------- |\n",
    "| 0                | ...       | ...     | ...         | ...     |\n",
    "| 1                | ...       | ...     | ...         | ...     |\n",
    "| **accuracy**     |           |         | overall acc | 总数      |\n",
    "| **macro avg**    | 所有类平均精度   | 所有类平均召回 | 所有类平均F1     | 总数      |\n",
    "| **weighted avg** | 按支持度加权平均  | ...     | ...         | 总数      |\n",
    "\n",
    "📌 参数说明：\n",
    "y_true: 真实标签。\\\n",
    "y_pred: 预测标签。\\\n",
    "target_names: 类别的名称（默认用数字）。\\\n",
    "output_dict=True: 返回字典而不是字符串格式。\\\n",
    "digits: 小数点保留位数。\\\n",
    "zero_division: 遇到除0时的处理方式（如设为0避免报错）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee0cf3e-c3e9-46a7-9de6-930971b7e736",
   "metadata": {},
   "source": [
    "### ✅ 常用于：\n",
    "多分类模型评估（尤其比 accuracy 更能反映表现）。\\\n",
    "二分类/不平衡分类时，检查 recall 是否达标（如疾病预测中的假阴性）。\\\n",
    "搭配 confusion_matrix 使用效果更佳。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e084d1fd-609e-404c-a274-cb7f5a0fc541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1816dc-6169-492e-bb64-10cefcf323da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4637e086-e586-4cc8-a9df-20b5676e66fe",
   "metadata": {},
   "source": [
    "## 10.5️⃣ roc_auc_score + ROC 曲线\n",
    "### 🧠 一、概念解释\n",
    "✅ 1. ROC 曲线（Receiver Operating Characteristic Curve）\\\n",
    "ROC 曲线是一种评估 二分类模型性能 的工具，反映模型在各种分类阈值（threshold）下的表现。\\\n",
    "横轴：FPR（假阳率） = FP / (FP + TN)  \\\n",
    "纵轴：TPR（真正率 / Recall） = TP / (TP + FN)\n",
    "\n",
    "✅ 2. AUC（Area Under the Curve）\\\n",
    "AUC 表示 ROC 曲线下的面积，取值范围为 [0, 1]：\n",
    "| AUC 值 | 意义            |\n",
    "| ----- | ------------- |\n",
    "| 1.0   | 完美分类器         |\n",
    "| 0.9+  | 极好模型          |\n",
    "| 0.8+  | 良好模型          |\n",
    "| 0.7+  | 一般模型          |\n",
    "| 0.5   | 随机猜测          |\n",
    "| < 0.5 | 模型性能极差（比随机还差） |\n",
    "\n",
    "\n",
    "# roc_auc_score \n",
    "是 ROC 曲线下面积（AUC, Area Under Curve） 的计算函数，常用于二分类模型（也可以扩展到多分类）性能评估，来自 scikit-learn 库。\n",
    "\n",
    "## 1. 作用\n",
    "它衡量的是 $ .. 模型区分正负样本的能力 ..  $ ，取值范围 [0, 1]：\\\n",
    "1.0 → 完美分类器（能完全区分正负样本）\\\n",
    "0.5 → 随机猜测（没有预测能力）\\\n",
    "<0.5 → 比随机还差（可能预测方向反了）\\\n",
    "相比直接用准确率（accuracy），AUC 更关注排序能力而不是固定阈值下的预测结果，适合正负样本不均衡的情况。\n",
    "\n",
    "## 2. 计算原理\n",
    "ROC 曲线：以 假阳性率 (FPR) 为横轴，真正率 (TPR) 为纵轴绘制的曲线。\\\n",
    "roc_auc_score 的值就是这条曲线下的面积，越大越好。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fea93d1-fbbc-4511-aa90-6863d385f01f",
   "metadata": {},
   "source": [
    "### 🛠️ 二、roc_auc_score 使用\n",
    "✅ 语法：\n",
    "\n",
    "from sklearn.metrics import roc_auc_score  \\\n",
    "roc_auc_score(y_true, y_score)  \\\n",
    "\n",
    "y_true：真实标签（二分类，0 或 1） \\\n",
    "y_score：预测得分（概率或置信度，而不是标签）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0eb7ff-397e-4206-88bb-afcbc7dbc2f2",
   "metadata": {},
   "source": [
    "### 📈 三、绘制 ROC 曲线\n",
    "✅ 示例代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6839541a-c5fe-411b-8d02-a8fc514dfcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取 FPR 和 TPR\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores)\n",
    "\n",
    "# 绘图\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guessing\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbd7cfe-1f03-482d-a4e7-eadb8519283c",
   "metadata": {},
   "source": [
    "### ✅ 四、注意事项\n",
    "roc_auc_score 需要的是 概率得分或置信度，不是 predict() 输出的分类标签。\\\n",
    "对于多分类，需使用 multi_class='ovr' 或 multi_class='ovo' 参数。\\\n",
    "对于极度不平衡的数据集，AUC 是比 accuracy 更稳定的评价指标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce8945c-d0fc-4aa0-814f-ff4fc66c3c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fd8107-a232-4ca4-90e2-0a676da40b67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57a1d515-95b6-407d-8454-22f41ba9eaf2",
   "metadata": {},
   "source": [
    "## 🎯 回归评估函数\n",
    "### 📌 一、常见回归评估指标（sklearn.metrics）\n",
    "| 指标名         | 函数                                       | 说明                        |\n",
    "| ----------- | ---------------------------------------- | ------------------------- |\n",
    "| **平均绝对误差（MAE）**  | `mean_absolute_error`                    | 预测值与真实值的绝对误差平均值           |\n",
    "| **均方误差（MSE）**    | `mean_squared_error`                     | 预测误差的平方再求平均，放大大误差的影响      |\n",
    "| **均方根误差**   | `mean_squared_error(..., squared=False)` | 均方误差开方，单位与目标值一致，更易解释      |\n",
    "| **中位绝对误差**  | `median_absolute_error`                  | 绝对误差的中位数，对异常值更鲁棒          |\n",
    "| **R² 决定系数** | `r2_score`                               | 表示模型对目标变量变异的解释程度，越接近 1 越好 |\n",
    "| **最大残差误差**  | `max_error`                              | 所有样本中最大绝对误差，用于衡量最坏情况      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d8eaa0-b74e-4088-ae1b-0b02a3e1ae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    median_absolute_error,\n",
    "    r2_score,\n",
    "    max_error\n",
    ")\n",
    "\n",
    "# 假设真实值 y_true 和预测值 y_pred 如下\n",
    "y_true = [3.0, -0.5, 2.0, 7.0]\n",
    "y_pred = [2.5, 0.0, 2.0, 8.0]\n",
    "\n",
    "# 计算各项指标\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "mse = mean_squared_error(y_true, y_pred)\n",
    "rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "med_ae = median_absolute_error(y_true, y_pred)\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "max_e = max_error(y_true, y_pred)\n",
    "\n",
    "print(f\"MAE : {mae:.3f}\")\n",
    "print(f\"MSE : {mse:.3f}\")\n",
    "print(f\"RMSE: {rmse:.3f}\")\n",
    "print(f\"Median AE: {med_ae:.3f}\")\n",
    "print(f\"R²: {r2:.3f}\")\n",
    "print(f\"Max Error: {max_e:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e0d454-e944-4bf3-b7cf-452e7a68de69",
   "metadata": {},
   "source": [
    "### 🧠 二、R² 决定系数（重点）\n",
    "𝑅2=1−（RSS/TSS）\n",
    "\n",
    "RSS：残差平方和（预测值和真实值之差的平方和）\\\n",
    "TSS：总平方和（真实值和平均值之差的平方和）\n",
    "\n",
    "解释性：\n",
    "R² = 1：模型完美预测\\\n",
    "R² = 0：模型和简单平均值预测一样差\\\n",
    "R² < 0：模型比“全靠平均值预测”还差"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c1a3f6-99a5-4a0e-9456-46fababf650e",
   "metadata": {},
   "source": [
    "### 📊 三、如何选择回归指标？\n",
    "| 情况          | 推荐指标            |\n",
    "| ----------- | --------------- |\n",
    "| 惩罚大误差       | MSE / RMSE      |\n",
    "| 更稳健，不受离群点影响 | MAE / Median AE |\n",
    "| 全面衡量拟合优度    | R²              |\n",
    "| 需要单位一致性     | RMSE            |\n",
    "| 对最坏情况敏感     | Max Error       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a18eba-d6ad-4ee5-b9e0-a63f472684cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4999104f-b249-4f82-baba-ea4257e768c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5ed17fd-1f67-4195-af12-cb82e3a13ff2",
   "metadata": {},
   "source": [
    "## 🎯 聚类评估函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad56fbe-6c79-44c3-8b60-b263a389dc6a",
   "metadata": {},
   "source": [
    "| 函数名                            | 含义           |\n",
    "| ------------------------------ | ------------ |\n",
    "| `adjusted_rand_score`          | 调整兰德系数（0\\~1） |\n",
    "| `normalized_mutual_info_score` | 归一化互信息（0\\~1） |\n",
    "| `silhouette_score`             | 轮廓系数，越高越好    |\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c2bf903f-0ece-4c1c-bd83-237985117f9d",
   "metadata": {},
   "source": [
    "示例：\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "score = silhouette_score(X, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd7d591-2c95-4a0f-a7cd-456d4b1cb3f9",
   "metadata": {},
   "source": [
    "## 🎯 距离度量函数（可用于 KNN/聚类等）"
   ]
  },
  {
   "cell_type": "raw",
   "id": "65f2e808-d4f9-4e06-9551-3b03d6403040",
   "metadata": {},
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_similarity\n",
    "\n",
    "euclidean_distances(X1, X2)\n",
    "cosine_similarity(X1, X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09215d76-cbf9-44dd-b7cf-7cca1a7328f4",
   "metadata": {},
   "source": [
    "## 🎯 排序 / 推荐系统指标"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72879323-a51f-4ef0-80ce-43a136e16f18",
   "metadata": {},
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "\n",
    "ndcg_score(y_true, y_score)\n",
    "\n",
    "常见指标包括：\n",
    "1.dcg_score, ndcg_score：评估推荐列表\n",
    "2.average_precision_score：mAP 计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48553f0-13e3-4448-85fc-643424d86b1c",
   "metadata": {},
   "source": [
    "## 📌 示例：完整二分类报告"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a34d987f-191e-4dad-8b55-220f0989e381",
   "metadata": {},
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_true = [0, 1, 1, 0, 1, 1, 0]\n",
    "y_pred = [0, 1, 0, 0, 1, 1, 1]\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "\n",
    "输出结果：\n",
    "              precision    recall  f1-score   support\n",
    "           0       0.67      0.67      0.67         3\n",
    "           1       0.75      0.75      0.75         4\n",
    "\n",
    "    accuracy                           0.71         7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be56b5b1-7d50-461b-b349-02beb6fbaa39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51a23263-b640-437f-bd7f-0ea305a92a28",
   "metadata": {},
   "source": [
    "# 11.sklearn.pipeline \n",
    "是 scikit-learn 中用于构建 数据预处理 + 模型训练的工作流（Workflow） 的模块，它能将多个步骤封装为一个整体对象，便于复用、调参、交叉验证等操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03003b11-b587-49da-afab-e7d8e0d1d90a",
   "metadata": {},
   "source": [
    "## 11.1. Pipeline 的作用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce630de-e327-4576-85ed-b0e6d5f04df7",
   "metadata": {},
   "source": [
    "| 传统方式              | 使用 `Pipeline` |\n",
    "| ----------------- | ------------- |\n",
    "| 手动逐步：清洗 → 编码 → 训练 | 一步完成          |\n",
    "| 各步骤参数分散、代码臃肿      | 统一管理          |\n",
    "| 交叉验证时需单独处理数据转换    | 自动完成          |\n",
    "| 网格搜索调参需单独处理预处理步骤  | 全流程调参         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e50075-eb15-4c8e-8a02-b0ef3ebfa691",
   "metadata": {},
   "source": [
    "## 11.2. Pipeline 的创建语法\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda304d5-0b59-4e4d-a7e8-cd2be38c9b42",
   "metadata": {},
   "source": [
    "### 🧱 Pipeline 基本结构\n",
    "Pipeline(steps: List[ Tuple[str, TransformerOrEstimator]])\n",
    "\n",
    "steps：一个步骤列表，每步是 (名称, 实例) 二元组，名称可以自定义，但必须唯一。\\\n",
    "所有步骤中：\\\n",
    "前 n-1 步必须是“转换器”Transformer（有 fit 和 transform 方法）；\\\n",
    "最后一步可以是 Estimator（如模型），也可以是 Transformer。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f9a380-01a6-400e-93a2-79a7a49d7d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),     # 第一步：标准化\n",
    "    ('clf', LogisticRegression())     # 第二步：模型\n",
    "])\n",
    "\n",
    "🔹 每一步是一个二元组 (名称, 对象)，名称可自定义，不能重复。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0a6fe2-34ff-4e90-b25f-ee348ab54a15",
   "metadata": {},
   "source": [
    "## 11.3. 使用方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562cb0cb-b6b6-40a0-81ef-be8a6b934879",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)     # 拟合所有步骤\n",
    "y_pred = pipe.predict(X_test)  # 自动执行所有步骤后预测\n",
    "\n",
    "等价于：\n",
    "\n",
    "# 手动版（更复杂）\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1612a21c-99b9-4033-bfb9-023a1280c57a",
   "metadata": {},
   "source": [
    "## 11.4. make_pipeline() 快速创建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddde5ad5-a38f-4872-956b-ac3b0e87f21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "✅ 自动生成名称，如：standardscaler, logisticregression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e38690e-38f1-4a1a-8a9a-032f22770218",
   "metadata": {},
   "source": [
    "## 11.5. 与 GridSearchCV 联合使用（核心优势！）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004433c2-0749-4736-ada3-730f1f63453c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'clf__C': [0.1, 1.0, 10.0]   # 注意参数名前缀：<步骤名>__<参数名>\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "\n",
    "✅ Pipeline 支持将预处理步骤的参数和模型参数同时调优！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dc0798-2660-46c4-b216-9e2aa59ebc17",
   "metadata": {},
   "source": [
    "## 11.6. 示例：完整分类流程\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d73f49-143b-46c3-81f7-680d596fa7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline  \n",
    "from sklearn.preprocessing import StandardScaler  # 数据标准化处理器\n",
    "from sklearn.linear_model import LogisticRegression  # 逻辑回归 模型 常用于 二分类问题\n",
    "from sklearn.model_selection import train_test_split  # 数据拆分器\n",
    "from sklearn.datasets import load_iris  # sklearn内部的数据\n",
    "\n",
    "# 加载数据\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# 构建流程\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # 数据 标准化\n",
    "    ('clf', LogisticRegression())  # 选择使用的模型\n",
    "])\n",
    "\n",
    "# 训练 + 预测\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_test)\n",
    "\n",
    "# 评估\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5931b6c-29c9-4ed6-b6e3-4e8199cd8603",
   "metadata": {},
   "source": [
    "## 11.7. 高级：ColumnTransformer + Pipeline 联合使用（数值+类别混合特征）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c7a524-fa29-4bef-a4d1-ad31e8b2ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), ['age', 'income']),\n",
    "    ('cat', OneHotEncoder(), ['gender', 'job'])\n",
    "])\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('clf', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07e2d84-6007-426d-80c3-164a870f6cd6",
   "metadata": {},
   "source": [
    "# 🔚 总结：何时用 Pipeline？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720aa4cb-f7ed-4f0a-a0e4-e377db4b3519",
   "metadata": {},
   "source": [
    "| 场景                       | 是否适合使用 Pipeline |\n",
    "| ------------------------ | --------------- |\n",
    "| 多步骤组合：预处理 + 训练           | ✅ 非常适合          |\n",
    "| 网格搜索 GridSearchCV + 特征转换 | ✅ 必须用           |\n",
    "| 保证训练集与测试集处理流程一致          | ✅ 强烈建议          |\n",
    "| 简化部署（可保存为 joblib/pkl 文件） | ✅ 很方便           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ce5bfc-7130-4554-87d5-982d5b0fc323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4896a6a-ac2b-4bd9-8dc2-162b08e124d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9cdba821-3387-41de-8f83-6ab44d0617c4",
   "metadata": {},
   "source": [
    "# ColumnTransformer模块\n",
    "### 🧠 一句话理解\n",
    "ColumnTransformer 可以让我们对 不同数据列 应用 不同的变换方法，比如对数值列做标准化，对类别列做独热编码。\n",
    "\n",
    "### 🧱 基本结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4606d273-83d3-4b30-a199-74ea5af4afc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ColumnTransformer(\n",
    "    transformers: List[Tuple[str, Transformer, Column(s)]],\n",
    "    remainder: str = 'drop',   # 'drop' or 'passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b328d1-2acd-4ffd-b6f4-fc95c6fb77b3",
   "metadata": {},
   "source": [
    "| 参数             | 说明                                              |\n",
    "| -------------- | ----------------------------------------------- |\n",
    "| `transformers` | 列表，每个元素是三元组 `(name, transformer, columns)`      |\n",
    "| `name`         | 自定义步骤名（用于后续调参等）                                 |\n",
    "| `transformer`  | 对应的预处理器，如 `StandardScaler()`、`OneHotEncoder()`  |\n",
    "| `columns`      | 指定处理的列，可以是列名、列名列表、列索引、布尔掩码或 callable            |\n",
    "| `remainder`    | 未被选择的列如何处理：`'drop'`（默认：丢弃）或 `'passthrough'`（保留） |\n",
    "\n",
    "### ✅ 示例一：对数值列和分类列分别处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ffaef0-f594-467a-978d-764c637626cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# 假设数据如下\n",
    "data = pd.DataFrame({\n",
    "    'age': [25, 32, 47],\n",
    "    'income': [50000, 64000, 120000],\n",
    "    'gender': ['M', 'F', 'F'],\n",
    "    'city': ['Tokyo', 'Paris', 'London']\n",
    "})\n",
    "\n",
    "# 列分类\n",
    "numeric_features = ['age', 'income']\n",
    "categorical_features = ['gender', 'city']\n",
    "\n",
    "# 构造 ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 拟合并转换数据\n",
    "X_transformed = preprocessor.fit_transform(data)\n",
    "\n",
    "print(X_transformed)\n",
    "\n",
    "📌 输出说明\n",
    "结果是一个经过处理后的 NumPy 矩阵：\n",
    "数值列被标准化\n",
    "分类列被独热编码\n",
    "原始列顺序可能改变（以 transformers 的顺序为主）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403e980b-6b30-477d-a6c9-4eb31b0f3585",
   "metadata": {},
   "source": [
    "### ✅ 示例二：保留未处理列 (remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da002af-c51b-41dd-aa26-4e5d4aa9314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), ['age']),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "这将对 age 做标准化处理，其他列原样保留。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0c6c5b-3cb6-4691-8967-ef2b9f611b54",
   "metadata": {},
   "source": [
    "### ✅ 示例三：搭配 Pipeline 构造完整流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f39a41-be9b-4051-9cf9-9ce7038a179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c9f27f-60ff-4b9c-b25e-9aa4d2afdf9a",
   "metadata": {},
   "source": [
    "### ✅ 示例四：与 GridSearchCV 联动调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75350f8a-20c2-4e3d-9032-63b49a7623ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'pre__num__with_mean': [True, False],  # 调整 ColumnTransformer 内部步骤\n",
    "}\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, cv=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5968f781-9b89-4bc9-98c2-c68985094872",
   "metadata": {},
   "source": [
    "### 🧠 进阶技巧\n",
    "| 技巧                              | 说明                                                                |\n",
    "| ------------------------------- | ----------------------------------------------------------------- |\n",
    "| `transformers` 中的列支持 lambda 表达式 | 可动态选择列，比如 `lambda df: df.select_dtypes(include='object').columns` |\n",
    "| 可以嵌套多个 `Pipeline`               | 每个 transformer 都可以是 `Pipeline`，实现复杂处理                             |\n",
    "| 与 `FunctionTransformer` 搭配      | 可进行自定义转换逻辑                                                        |\n",
    "\n",
    "### ❗注意事项\n",
    "\n",
    "| 点                                       | 说明                                   |\n",
    "| --------------------------------------- | ------------------------------------ |\n",
    "| 返回值是 NumPy 数组                           | 如果你希望保留列名，请配合 `sklearn-pandas` 或自行包装 |\n",
    "| 所有子 transformer 都要有 `fit` + `transform` | 模型不能出现在 ColumnTransformer 中          |\n",
    "| 输出顺序按 transformers 顺序排列                 | 与原始 DataFrame 的列顺序无关                 |\n",
    "| 特别适用于混合特征数据                             | 如分类 + 连续变量同时存在的结构                    |\n",
    "\n",
    "### 🔚 总结表格\n",
    "| 特征    | ColumnTransformer                                                    |\n",
    "| ----- | -------------------------------------------------------------------- |\n",
    "| 作用    | 不同列使用不同处理方法                                                          |\n",
    "| 支持操作  | 缩放、编码、缺失值填充、自定义函数等                                                   |\n",
    "| 输出    | NumPy array（可以配合保留列名工具）                                              |\n",
    "| 典型用途  | 混合类型数据的建模                                                            |\n",
    "| 可嵌套   | 支持和 `Pipeline` 组合                                                    |\n",
    "| 常配合模块 | `Pipeline`, `OneHotEncoder`, `StandardScaler`, `FunctionTransformer` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc856c3-ecc0-4271-a4a3-309995f338f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d2e2eff-4e99-4985-ae6a-34020d4be4e7",
   "metadata": {},
   "source": [
    "# ColumnTransformer + Pipeline + GridSearchCV 搭建一个机器学习工作流。\n",
    "### ✅ 示例目标\n",
    "我们使用的是一个合成的数据集，假设如下结构：\n",
    "| age | income | gender | city   | target |\n",
    "| --- | ------ | ------ | ------ | ------ |\n",
    "| 25  | 50000  | M      | Tokyo  | 0      |\n",
    "| 32  | 64000  | F      | Paris  | 1      |\n",
    "| 47  | 120000 | F      | London | 1      |\n",
    "| ... | ...    | ...    | ...    | ...    |\n",
    "\n",
    "--对 age 和 income 做标准化（StandardScaler）\\\n",
    "--对 gender 和 city 做独热编码（OneHotEncoder）\\\n",
    "--使用逻辑回归进行分类\\\n",
    "--用 GridSearchCV 调参逻辑回归中的 C 参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4e9882-94cb-458f-b048-467f7017802d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# 构造数据\n",
    "data = pd.DataFrame({\n",
    "    'age': [25, 32, 47, 52, 23, 40],\n",
    "    'income': [50000, 64000, 120000, 110000, 40000, 90000],\n",
    "    'gender': ['M', 'F', 'F', 'M', 'M', 'F'],\n",
    "    'city': ['Tokyo', 'Paris', 'London', 'Paris', 'Tokyo', 'London'],\n",
    "    'target': [0, 1, 1, 0, 0, 1]\n",
    "})\n",
    "\n",
    "# 特征和标签分离\n",
    "X = data.drop(columns='target')\n",
    "y = data['target']\n",
    "\n",
    "# 分类与数值列\n",
    "num_features = ['age', 'income']\n",
    "cat_features = ['gender', 'city']\n",
    "\n",
    "# 构建 ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_features),\n",
    "        ('cat', OneHotEncoder(), cat_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 构建 Pipeline：预处理 + 分类器\n",
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# 构建参数网格（注意命名格式：步骤名__参数名）\n",
    "param_grid = {\n",
    "    'classifier__C': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# 划分训练/测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 构建 GridSearchCV\n",
    "grid_search = GridSearchCV(pipe, param_grid, cv=3, scoring='accuracy')\n",
    "\n",
    "# 训练模型\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 输出结果\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best CV Score:\", grid_search.best_score_)\n",
    "print(\"Test Score:\", grid_search.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c3a8aa-008d-4991-b453-fa0056a29e14",
   "metadata": {},
   "source": [
    "### ✅ 工作流结构图示\n",
    "Raw Data \\\n",
    "  ↓ \\\n",
    "ColumnTransformer  \\\n",
    "  ├── 'num' → StandardScaler → ['age', 'income']  \\\n",
    "  └── 'cat' → OneHotEncoder → ['gender', 'city']  \\\n",
    "  ↓  \\\n",
    "Concatenated features  \\\n",
    "  ↓  \\\n",
    "LogisticRegression(C=调参中)  \\\n",
    "\n",
    "\n",
    "### 🧠 总结技巧\n",
    "| 操作      | 方法                                                  |\n",
    "| ------- | --------------------------------------------------- |\n",
    "| 给每步命名   | `'preprocessor'`, `'classifier'`                    |\n",
    "| 调参前缀    | `<步骤名>__<参数名>`                                      |\n",
    "| 分类列自动检测 | 可用 `make_column_selector()` 替代手动列名                  |\n",
    "| 模型替换    | 可将逻辑回归替换成其他模型（如 `RandomForestClassifier`）           |\n",
    "| 模型接口统一  | `.fit()`, `.predict()`, `.score()` 都用在 `Pipeline` 上 |\n",
    "\n",
    "#### 如需进一步支持（如多种处理器嵌套、特征选择、自定义转换器等），可以扩展 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffdfb32-2b3f-4fc2-a0ad-9064600268e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e12d2a7b-0c23-481d-af2f-4d0e9847fe50",
   "metadata": {},
   "source": [
    "## make_column_selector() \n",
    "是 scikit-learn 中的一个列选择器工具函数，用于在 ColumnTransformer 中自动选择列，按数据类型（如数值型、分类型）进行选择，无需手动写出列名。\n",
    "\n",
    "from sklearn.compose import make_column_selector\n",
    "\n",
    "### 🎯 一句话理解\n",
    "make_column_selector() 帮你按规则自动筛选列，比如“所有的 object 类型” 或 “所有的 numeric 类型”，常与 ColumnTransformer 搭配使用，构建更灵活的流水线。\n",
    "### 🧱 基本语法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247f3a6b-e5db-4af9-8b70-2c911b6f35ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_column_selector(dtype_include=None, dtype_exclude=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ab0fcb-c349-4630-8cec-fb3804bec1d9",
   "metadata": {},
   "source": [
    "| 参数              | 说明                                   |\n",
    "| --------------- | ------------------------------------ |\n",
    "| `dtype_include` | 需要包含的数据类型（如 `np.number`, `'object'`） |\n",
    "| `dtype_exclude` | 需要排除的数据类型                            |\n",
    "\n",
    "📌 二者只能设置一个，不能同时使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edab882-adf4-41c9-85c3-44a7d8c8a33d",
   "metadata": {},
   "source": [
    "### ✅ 示例：自动选择数值列和分类列 + Pipeline + GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8a7a31-5e06-42a3-902e-124c1c786d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 示例数据\n",
    "df = pd.DataFrame({\n",
    "    'age': [25, 30, 45],\n",
    "    'income': [50000, 60000, 80000],\n",
    "    'gender': ['M', 'F', 'F'],\n",
    "    'city': ['Tokyo', 'Paris', 'London']\n",
    "})\n",
    "\n",
    "# 创建 ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), make_column_selector(dtype_include=np.number)),  # 自动选择数值列\n",
    "    ('cat', OneHotEncoder(), make_column_selector(dtype_include=object))       # 自动选择字符串/分类列\n",
    "])\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'clf__C': [0.1, 1.0, 10.0]\n",
    "}\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "\n",
    "grid.fit(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe8a578-e254-4bee-8599-a336aa96a11d",
   "metadata": {},
   "source": [
    "### 🧠 使用建议\n",
    "| 场景     | 是否推荐使用          |\n",
    "| ------ | --------------- |\n",
    "| 列非常多   | ✅ 非常推荐，省事省力     |\n",
    "| 列名频繁变化 | ✅ 自动检测更鲁棒       |\n",
    "| 小数据、列少 | ✅ 也可以用，但手写列名更直观 |\n",
    "### 🔚 总结表格\n",
    "| 功能   | make\\_column\\_selector               |\n",
    "| ---- | ------------------------------------ |\n",
    "| 作用   | 根据 dtype 自动选列                        |\n",
    "| 常用配合 | ColumnTransformer                    |\n",
    "| 替代什么 | 手动写列名                                |\n",
    "| 常用设置 | `dtype_include=object` / `np.number` |\n",
    "| 使用门槛 | 非常低，推荐                               |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b069997b-6183-44d1-bb68-a969e07d249f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29d81406-155e-4e09-a201-7c5a32b9a1e7",
   "metadata": {},
   "source": [
    "# 上采样器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872a84b1-77c4-4222-b814-a88b71f5132b",
   "metadata": {},
   "source": [
    "## resample 是一个用于自助采样（bootstrap sampling）的工具\n",
    "可以有放回地从数据中随机抽取样本。\\\n",
    "常用于数据重采样，比如上采样少数类或下采样多数类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f5bbda-6d77-4bea-acda-d28c576322ca",
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc32a1d-7fc9-4822-9bbf-0f94085e07d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592c00fe-3749-4b60-a340-bf6cafc89ab3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6bc5ee4-e250-4b00-8e77-bd5679603adf",
   "metadata": {},
   "source": [
    "## 优于简单 resample 的主流采样技术\n",
    "# 1. SMOTE（Synthetic Minority Over-sampling Technique）\n",
    "### 概念与直观理解\n",
    "SMOTE 的核心想法很简单：不是简单复制少数类样本，而是在少数类样本之间“插值”生成新的合成样本，以增加少数类的多样性、降低重复带来的过拟合风险。\\\n",
    "对于某个少数类样本 X𝑖，SMOTE 找出它的 k 个最近少数类邻居，随机选一个邻居 X𝑛𝑛，在两者连线上按比例插值生成新样本：\n",
    "\n",
    "Xnew = X𝑖 + 𝜆(X𝑛𝑛−X𝑖),𝜆∼𝑈(0,1)\n",
    "\n",
    "这么做会在少数类局部区域内“扩展”样本密度，帮助分类器学习到更连续的决策边界。\n",
    "\n",
    "### 算法步骤（逐步）\n",
    "对每个少数类样本 X𝑖：用 k-NN（只在少数类样本中）找出 k 个最近邻。\\\n",
    "根据要生成的样本数，从这 k 个邻居中随机选一个邻居 X𝑛𝑛  \\\n",
    "生成新样本 Xnew = X𝑖 + 𝜆(X𝑛𝑛−X𝑖)，𝜆∈(0,1) 随机取。\\\n",
    "重复直到达到目标的少数类样本数量。\n",
    "\n",
    "### 关键参数与含义\n",
    "1、sampling_strategy：指定采样目标（非常重要）\\\n",
    "float (0,1]：表示合成后 少数类数量 / 多数类数量 的目标比例 \\\n",
    "例：若多数类有 1000 个，sampling_strategy=0.5 → 目标少数类为 500。\n",
    "\n",
    "int：指定少数类在 resample 后的绝对样本数（适用于二分类时指定最终少数数）。\n",
    "\n",
    "dict：显式指定每个类别在 resample 后的目标样本数，例如 {0:1000, 1:300}。\n",
    "\n",
    "'auto'：默认，通常把所有少数类采样到与多数类平衡（取决于实现）。\n",
    "\n",
    "2、k_neighbors：用于寻找最近邻的 k（默认 5）。注意：k_neighbors 必须小于 n_minority（通常要求 n_minority >= k_neighbors+1），否则会报错或行为不稳定。\n",
    "\n",
    "3、random_state：随机种子，保证可复现。\n",
    "\n",
    "4、n_jobs：并行加速 kNN 计算（取决于实现版本是否支持）。\n",
    "\n",
    "此外，k_neighbors 在 imblearn 中可以是一个 NearestNeighbors 对象，允许自定义距离度量（比如用 metric='manhattan'、或 metric='cosine' 等）。\n",
    "\n",
    "### SMOTE 的数学/直观后果\n",
    "在少数类样本连接的“线段”上生成新样本，使得少数类形成更连续的簇。\n",
    "\n",
    "优点：相较于简单复制，能提高少数类多样性，常能降低过拟合。\n",
    "\n",
    "风险：如果少数类靠近多数类边界或存在噪声，SMOTE 可能把合成样本生成到多数类区域，反而增加类混淆（尤其在类别边界处或数据高维稀疏时）。\n",
    "\n",
    "### 典型 Python 实现（imblearn）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3158dad0-1169-4c4a-b523-aef4c57d25d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装： pip install imbalanced-learn\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(sampling_strategy=0.5, k_neighbors=5, random_state=42, n_jobs=-1)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af2ac6d-783f-4d81-b08a-dc62dbc82591",
   "metadata": {},
   "source": [
    "示例说明：\n",
    "\n",
    "如果原始多数类 = 1000，少数类 = 100，sampling_strategy=0.5 会把少数类扩增到 500（最终少:多 = 500:1000）。\n",
    "\n",
    "| 参数                      | 类型 / 默认值                               | 作用说明                                                                                                                                                               |\n",
    "| ----------------------- | -------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| **`sampling_strategy`** | float / dict / str / callable，默认 `1.0` | 控制少数类样本扩充的比例。<br>• **float**：表示少数类样本数 / 多数类样本数的目标比例。例如 `0.5` 表示少数类样本数变为多数类样本数的一半。<br>• **dict**：指定每个类别采样后的样本数。<br>• **str**：如 `\"minority\"`、`\"not majority\"` 等快捷设置。 |\n",
    "| **`k_neighbors`**       | int，默认 `5`                             | 用于合成新少数类样本时的最近邻个数。值越大，生成的新样本更分散，但可能引入噪声；值小则更贴近原样本。                                                                                                                 |\n",
    "| **`random_state`**      | int / None，默认 `None`                   | 随机种子，保证结果可复现。设置为固定整数（如 `42`）可以在多次运行时生成一致的数据。                                                                                                                       |\n",
    "| **`n_jobs`**            | int，默认 `None`                          | 并行计算的 CPU 核心数。<br>• `-1` 表示使用全部可用核心，加快处理速度。<br>• 设为正整数表示使用指定数量的核心。                                                                                                 |\n",
    "\n",
    "\n",
    "## 在 pipeline / CV 中正确使用（避免数据泄露）\n",
    "非常重要：只在训练集上做 SMOTE。常见做法是把 SMOTE 放进 imblearn.pipeline.Pipeline 并在 cross-validation 的每个 fold 内执行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ce756e-6d1a-44df-92fa-a069b160dd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # 如果有数值特征且要用 SMOTE（依赖距离），先缩放\n",
    "    ('smote', SMOTE(sampling_strategy=0.1, random_state=42)),\n",
    "    ('clf', LGBMClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipeline, X_train, y_train, scoring='average_precision', cv=cv)  # PR-AUC 常用\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea7fed2-c1a8-4750-91ff-b81d9243243f",
   "metadata": {},
   "source": [
    "这样每个 fold 的 scaler/SMOTE 都只fit在训练折上，避免泄露到验证折。\n",
    "\n",
    "## 关于类别特征（混合数值+类别）\n",
    "SMOTE 原生只适用数值特征（因为基于距离和向量插值）。\n",
    "\n",
    "对于数值+类别混合数据，可以用 SMOTENC（SMOTE for Nominal and Continuous）：需要传入 categorical_features 的索引，SMOTENC 在处理类别时不做线性插值，而是用最近邻的类别值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08375a4-4c9c-4cd6-ba86-c413e29d9cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "sm = SMOTENC(categorical_features=[0,2], sampling_strategy='auto', random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7764a1-71a8-4ad6-9887-935bd1dea1a5",
   "metadata": {},
   "source": [
    "另一种做法是对类别做 embedding 或 target-encoding，把其转为数值再 SMOTE —— 但需谨慎，编码方式会影响距离计算的合理性。\n",
    "\n",
    "## 常见的 SMOTE 变体（简要）\n",
    "Borderline-SMOTE：只在靠近多数类边界的少数样本周围生成样本（关注边界样本）。\n",
    "\n",
    "ADASYN：根据少数样本“难度”自适应生成更多样本，靠近多数类或稀疏区的少数样本会得到更多合成样本。\n",
    "\n",
    "SMOTENC：用于混合数值+类别特征。\n",
    "\n",
    "SMOTE + 清洗（SMOTEENN / SMOTETomek）：先上采样再用 TomekLinks 或 ENN 清理边界/噪点。常见组合以提升边界质量。\n",
    "\n",
    "KMeans-SMOTE / SVM-SMOTE：先聚类或基于 SVM 支持向量定位再生成，目标是减少跨类合成。\n",
    "\n",
    "### 优点与缺点（实践角度）\n",
    "优点\n",
    "\n",
    "生成“新”少数样本，增加多样性，通常比直接复制效果好。\n",
    "\n",
    "简单直观，易于和 pipeline 集成。\n",
    "\n",
    "缺点 / 风险\n",
    "\n",
    "可能在类边界或噪音处生成“错误”样本，导致类混淆。\n",
    "\n",
    "对高维、稀疏或类别特征表现差（距离度量失效或生成不合理的向量）。\n",
    "\n",
    "如果少数类样本非常少（比如 < 6），默认 k=5 会失败，需要降低 k 或慎重使用。\n",
    "\n",
    "如果想把少数扩到非常大的数量（比如从 500 扩到几十万），可能会产生大量人工合成且不真实的数据，导致过拟合或训练时间/内存问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf5d810-30dc-461e-84a3-6d40e9417ea1",
   "metadata": {},
   "source": [
    "## 常见误区（避免）\n",
    "在整个数据集（train+test）上做 SMOTE → 导致测试集与训练集“相关”，评估结果虚高。\n",
    "\n",
    "认为 SMOTE 总能提升模型：如果原问题是噪声、标签错误、或特征本身不可区分，SMOTE 反而会放大问题。\n",
    "\n",
    "忽视类别特征与高维问题：把 SMOTE 当作“万能”手段而不处理特征工程。\n",
    "\n",
    "## 小结（操作步骤推荐）\n",
    "1、先 baseline（class weights / scale_pos_weight）。\n",
    "\n",
    "2、若需采样：在训练集内先下采多数到合理规模（如果原始多数非常大），然后用 SMOTE 把少数扩到一个合理比例（比如少/多 1:20 ~ 1:5），或使用 EasyEnsemble。\n",
    "\n",
    "3、把整个流程做成 imblearn.pipeline.Pipeline 且在 StratifiedKFold 中做 CV。\n",
    "\n",
    "4、多试几种 k_neighbors 与 sampling_strategy，并用 PR-AUC、recall/precision 等指标做选择。\n",
    "\n",
    "5、若有类别特征，优先用 SMOTENC 或专门的类别增强方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1c610-805e-4c3f-a364-77e3fc1e6549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c348cd89-1d84-42a2-99e8-72d5a3329d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40cc0fa7-272d-4513-b0cc-bb6e1541aa76",
   "metadata": {},
   "source": [
    "# 下采样"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40b3a12-7f02-45ab-be9d-cb7c4eba7856",
   "metadata": {},
   "source": [
    "## 1、 随机下采样（Random Undersampling）\n",
    "原理：随机删除多数类样本到目标数量。\n",
    "\n",
    "优点：简单、训练速度快、减少不均衡带来的偏差；适用于数据量巨大的场景。\n",
    "\n",
    "缺点：可能丢失重要信息、导致欠拟合。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd4bb00-7caa-46f6-b89f-48b532050a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96c7c54-0dea-4743-a238-07bbf13c6762",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417488cd-4a45-46e6-88ae-8cedd1db0291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27166b1d-d02f-4020-8920-254c1a1b6572",
   "metadata": {},
   "outputs": [],
   "source": [
    "2) 基于距离/规则的下采样（NearMiss、ClusterCentroids 等）\n",
    "NearMiss：选择那些与少数类距离更接近的多数类样本（以保持决策边界信息）。有多种版本（NearMiss-1/2/3）。\n",
    "\n",
    "ClusterCentroids：用 k-means 聚类多数类，并用聚类中心代替原始样本，达到数据压缩同时保留分布信息。\n",
    "\n",
    "优点：比随机下采样更有可能保留判别信息。\n",
    "\n",
    "缺点：计算复杂度高，选错规则也会损失信息。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15748cb7-5de4-4bc2-97ef-24086e637d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3005455-395d-42af-8440-d100863ba3bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf788b8-b075-41b6-a3b9-04143222bfdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e8dbb2-8602-4af0-9254-5b5c4d46768f",
   "metadata": {},
   "outputs": [],
   "source": [
    "3) 清洗类方法（TomekLinks、Edited Nearest Neighbours (ENN)）\n",
    "Tomek Links：若样本对（a,b）是互为最近邻且属于不同类，则该对可能是“重叠/噪声”样本。通常删除多数类样本以清理边界。\n",
    "\n",
    "ENN：删除那些与大多数最近 k 邻居类别不一致的样本（噪声剔除）。\n",
    "\n",
    "用途：在下采样前后用来清理噪声、减少类间重叠；常与上采样结合使用（见下）。\n",
    "\n",
    "组合方法（推荐用于多数场景）\n",
    "SMOTE + TomekLinks（SMOTETomek）：上采样合成少数样本，然后用 TomekLinks 清理边界和重叠。\n",
    "\n",
    "SMOTE + ENN（SMOTEENN）：上采样后用 ENN 删除噪声。\n",
    "\n",
    "优点：上采样补足少数类、下采样 / 清洗减少类间重叠，效果通常优于单独方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ede249-9b3e-4732-86e2-c265d22fa829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fa4971-4794-49a5-b947-4ac9c0edb499",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23027be-850a-4025-9774-aecab1780b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6787cd6b-d1c9-4082-b0a6-d565efa9f6ac",
   "metadata": {},
   "source": [
    "# ✅ 二、组合采样方法（过采样 + 欠采样）\n",
    "SMOTE + Tomek Links / SMOTE + ENN  \\\n",
    "原理：\\\n",
    "先用 SMOTE 上采样少数类。\\\n",
    "再用 Tomek Links 或 Edited Nearest Neighbours (ENN) 去除噪声或边界模糊的样本。\n",
    "\n",
    "优点：\\\n",
    "清理样本空间，提升数据质量\\\n",
    "比单独 SMOTE 效果更好"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df982ed0-ef26-4cc4-bddb-747ed69e7968",
   "metadata": {},
   "source": [
    "## 概念速览\n",
    "SMOTE：对少数类进行插值生成合成样本（基于最近邻）。重要参数：sampling_strategy（目标比例）、k_neighbors（用于合成的邻居数）。\n",
    "\n",
    "Tomek Links：一种下采样清洗方法。若两个样本互为最近邻且类别不同，则它们构成一个 Tomek pair，通常会删除多数类那一侧样本，用来清除类边界上的噪声/重叠。\n",
    "\n",
    "ENN（Edited Nearest Neighbours）：另一种下采样清洗。对每个样本找其 k 个最近邻，若该样本的标签与邻居多数标签不一致，则删除该样本（可设置只删除多数类或全部）。比 Tomek 更“激进”，会删除更多疑似噪声样本。\n",
    "\n",
    "组合目的：先用 SMOTE 增加少数类样本，再用 Tomek/ENN 清除边界噪声，得到既平衡又较干净的训练集。\n",
    "\n",
    "## 什么时候用哪种组合\n",
    "SMOTE + Tomek：比较温和，适合类边界有少量重叠，想做基本清洗的场景。保留信息较多。\n",
    "\n",
    "SMOTE + ENN：更激进清洗，适合噪声较多或希望决策边界更清晰的场景，但可能丢弃有用样本（需小心评估）。\n",
    "\n",
    "注意：对多分类、类别极少样本（very small minority）或含类别特征的情况，要选特殊方法（如 SMOTENC）或仔细设置 k_neighbors。\n",
    "\n",
    "## 操作步骤（推荐流程 + 代码示例）\n",
    "### 1) 基本准备（只在训练集上做重采样）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff092aaa-45c9-47d6-bdfe-adabe1c555cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    stratify=y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "print(\"Before:\", Counter(y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c84a21-640e-4ac2-9047-57e4aa0b7fa6",
   "metadata": {},
   "source": [
    "原则：只对训练集做重采样，切忌对验证集/测试集做重采样以免数据泄露。\n",
    "\n",
    "### 2) 简单用法：直接用 combine 类（最快上手）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91394951-1daf-411d-8fe9-a3a4dc9ecdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "# SMOTE + Tomek\n",
    "smt = SMOTETomek(random_state=42)            # 可传入 smote=SMOTE(...), tomek=TomekLinks(...)\n",
    "X_res, y_res = smt.fit_resample(X_train, y_train)\n",
    "\n",
    "# SMOTE + ENN\n",
    "sr = SMOTEENN(random_state=42)               # 可传入 smote=SMOTE(...), enn=EditedNearestNeighbours(...)\n",
    "X_res2, y_res2 = sr.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c33c00-7185-4b12-b24f-13b4149b3ca9",
   "metadata": {},
   "source": [
    "这两类是 imbalanced-learn 提供的方便组合：一行完成过采样 + 下采样清洗。\n",
    "\n",
    "### 3) 更可控：使用 imblearn.pipeline.Pipeline 显式写出步骤（推荐）\n",
    "重要：如果使用距离相关方法（SMOTE/ENN/Tomek），请在做这些操作之前进行特征缩放（StandardScaler/MinMax），因为 SMOTE 基于距离产生样本。\\\n",
    "示例：Scaler -> SMOTE -> ENN/Tomek -> 分类器（放在管道里，便于 CV/搜索参数且防止数据泄露）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fff0aa-dea2-4ce8-852e-21b47d07b15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline  # \n",
    "from imblearn.over_sampling import SMOTE,  # SMOTENC可以直接替代 SMOTE\n",
    "from imblearn.under_sampling import TomekLinks, EditedNearestNeighbours\n",
    "from sklearn.preprocessing import StandardScaler  # 归一化器\n",
    "from sklearn.ensemble import RandomForestClassifier   # 集成算法（基于大量的决策树）\n",
    "\n",
    "pipeline_tomek = Pipeline([\n",
    "    ('scaler', StandardScaler()), \n",
    "    ('smote', SMOTE(sampling_strategy=0.5, k_neighbors=5, random_state=42, n_jobs=-1)),\n",
    "    ('tomek', TomekLinks(n_jobs=-1)),\n",
    "    ('clf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipeline_enn = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(sampling_strategy='minority', k_neighbors=5, random_state=42, n_jobs=-1)),\n",
    "    ('enn', EditedNearestNeighbours(n_neighbors=3, kind_sel='all', n_jobs=-1)),\n",
    "    ('clf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit\n",
    "pipeline_tomek.fit(X_train, y_train)\n",
    "pipeline_enn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40131193-f3dc-4251-b56b-a5942d8a415c",
   "metadata": {},
   "source": [
    "### 4) 在交叉验证 / 网格搜索中使用（非常重要 —— 防止信息泄露）\n",
    "使用 imblearn.pipeline.Pipeline 把采样器放进管道内，然后把管道交给 GridSearchCV / cross_val_score。这样重采样只会在每个 CV 的训练折内进行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d52b93-fcad-4767-b1d3-f0bf82a7788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "param_grid = {\n",
    "    'smote__k_neighbors': [3,5,7],\n",
    "    'clf__n_estimators': [100,200],\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid = GridSearchCV(pipeline_enn, param_grid, cv=cv, scoring='f1', n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\", grid.best_params_)\n",
    "best_model = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b147665-b7bb-40db-891a-b50272f0ad4e",
   "metadata": {},
   "source": [
    "### 5) 评估（示例）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70e2782-11cc-4968-9b96-78d1f52bece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a087919-7f4e-4404-a25a-add8912c5417",
   "metadata": {},
   "source": [
    "## 参数与调参建议（实践经验）\n",
    "sampling_strategy（SMOTE/组合类）：可以是 float（目标为 n_minority / n_majority = float），或 'minority', 'not majority', 或 dict（为每个类指定目标数）。\n",
    "\n",
    "经验：先试 sampling_strategy='minority' 或 0.5，根据模型表现再调整。\n",
    "\n",
    "k_neighbors（SMOTE）：默认 5。若少数类样本数很少，要设小（例如 minority 类只有 6 个样本，则 k_neighbors ≤ 4）。\n",
    "\n",
    "值太大 → 合成样本更“平滑”但可能越过类边界造成错合成（引入噪音）。\n",
    "\n",
    "n_neighbors（ENN）：默认通常为 3。增大会更严格地删除边界样本（更激进）。\n",
    "\n",
    "kind_sel（ENN）：决定如何判定删除（实现细节不同版本可能有不同选项），常见为 'all'、'mode' 等。\n",
    "\n",
    "n_jobs：多数采样/清洗器支持并行，-1 使用全部核心（加速）。\n",
    "\n",
    "顺序：Scaler -> SMOTE -> ENN/Tomek -> Classifier（缩放放在 SMOTE 之前）。\n",
    "\n",
    "## 风险与注意事项\n",
    "1、不要在测试集上做任何重采样。只在训练集或训练折内做重采样。\n",
    "\n",
    "2、过度清洗（特别是 ENN）可能删除有用样本，导致欠拟合或偏差，需评估（precision/recall/f1/ROC-AUC）。\n",
    "\n",
    "3、类间重叠严重时，SMOTE 可能会生成在多数类区域内的样本（错误合成），这时要谨慎或尝试改进方法（如聚类后在簇内做 SMOTE）。\n",
    "\n",
    "4、类别特征：若数据含分类特征，考虑 SMOTENC（SMOTE for Nominal + Continuous）或先做合适编码（但注意编码后的数值可能影响距离度量）。\n",
    "\n",
    "5、小样本极少：当 minority 类非常少（如 < 6），SMOTE 效果有限甚至不可用；可能需要数据收集或其他方法（基于规则的、聚类等）。\n",
    "\n",
    "## 可视化（推荐）\n",
    "用 PCA / t-SNE 可视化采样前后样本分布，快速判断合成样本是否合理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d028ae-f48d-4e6c-9a15-9b805466f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pca = PCA(2)\n",
    "Xp = pca.fit_transform(X_train)\n",
    "Xr = pca.transform(X_res)\n",
    "# 画出原始少数/多数 vs 合成后的位置（颜色/标记区分）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fab4d1-5327-4dd0-9b89-00dd026b448e",
   "metadata": {},
   "source": [
    "## 简短建议清单（Checklist）\n",
    "1、划分 train/test（分层）。\n",
    "\n",
    "2、在 Pipeline 中先 scale，再 SMOTE，再 Tomek/ENN，再 classifier。\n",
    "\n",
    "3、在 CV（GridSearch）中包含采样步骤（即不要在 Grid 外先 fit_resample）。\n",
    "\n",
    "4、先用 SMOTE+Tomek（较保守），若仍有噪声/边界问题尝试 SMOTE+ENN（更激进）。\n",
    "\n",
    "5、可视化与多种评估指标（precision/recall/F1/AUC）一起判断效果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7248feb5-eac3-4428-9d33-db2e0215c79e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ffecd2-9ee0-4bb8-ba34-fcb26a768c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6eb34ad5-92ae-4e4a-8f9b-864934e02af6",
   "metadata": {},
   "source": [
    "## 实战细节与注意事项（非常重要）\n",
    "#### 1、只在训练集上做采样！\n",
    "\n",
    "严禁在整个数据集上先上/下采样再划分 train/test，会导致数据泄露（test 与 train 有重复/合成关系），评估失真。\n",
    "\n",
    "#### 2、把采样放到 pipeline 里并在交叉验证（CV）内执行：\n",
    "\n",
    "使用 imblearn.pipeline.Pipeline，把 Scaler -> Sampler -> Classifier 放一起，这样在 CV 中每个 fold 都是在训练折上拟合 scaler/采样，避免泄露。\n",
    "\n",
    "#### 3、缩放（scaling）的顺序：\n",
    "\n",
    "如果用 SMOTE（基于距离），先做数值特征缩放（StandardScaler/MinMaxScaler），再 SMOTE；但缩放的 fit 必须只用训练数据（因此放在 pipeline 的前面）。\n",
    "\n",
    "对树模型（如 RandomForest、LightGBM）通常不需要缩放，但 SMOTE 仍依赖距离，所以常建议缩放后再 SMOTE。\n",
    "\n",
    "#### 4、类别特征：\n",
    "\n",
    "若有类别特征，优先考虑 SMOTENC；或者对类别做 embedding/数值化后再用生成方法，但要小心距离意义。\n",
    "\n",
    "文本/图像类别通常用领域增强（data augmentation）而非 SMOTE。\n",
    "\n",
    "#### 5、参数与边界条件：\n",
    "\n",
    "SMOTE 的 k_neighbors 要小于少数类样本数。\n",
    "\n",
    "选择采样比例（balance ratio）时要谨慎：完全平衡有时并非最好，尝试不同目标比例（如 1:1、1:2）。\n",
    "\n",
    "#### 6、对模型的替代方案：\n",
    "\n",
    "对于很多模型（尤其树模型），可以设置 class_weight 或 scale_pos_weight（如 LightGBM、XGBoost）来处理不均衡，常与采样结合使用或作为基线方法。\n",
    "\n",
    "#### 7、评估指标：\n",
    "\n",
    "不要只看 accuracy！推荐使用：Precision/Recall/F1、ROC AUC、PR AUC（对强不平衡更有意义）、confusion matrix、per-class recall。\n",
    "\n",
    "在 CV 中使用 StratifiedKFold 保持类比例。\n",
    "\n",
    "#### 8、过拟合风险：\n",
    "\n",
    "随机复制（oversampling）会放大过拟合；SMOTE 在少数样本极少时也可能生成“重复”或不可靠样本。可结合正则化、集成方法或数据增强降低风险。\n",
    "\n",
    "#### 9、时间序列 / 时序数据：\n",
    "\n",
    "不可随意 shuffle 增/减样本。若需处理稀有事件，采用时间窗口内的专门采样或仿真方法（保持时间顺序）。\n",
    "\n",
    "#### 10、多类别问题：\n",
    "\n",
    "可对多类中每个少数类分别上采样或设定 sampling_strategy 为 dict 指定每类目标样本数。imblearn 支持多类采样。\n",
    "\n",
    "## 典型代码示例（完整流程）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feca167-ac52-4a9e-99bc-4c7f91322f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 X, y 是原始数据\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 1. 划分（测试集保持原始分布）\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# 2. 建 pipeline：缩放 -> SMOTE -> 分类器\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('clf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# 3. CV 评估（采样会在每个训练 fold 内执行）\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=cv)\n",
    "print(\"CV ROC AUC:\", scores.mean(), scores.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ea6ad4-8e8d-4381-a392-c6812fccf487",
   "metadata": {},
   "source": [
    "# 何时选上采样 / 下采样 / 组合 / 其他策略（实用决策表）\n",
    "少数类样本非常少（但样本总量不大）：试 SMOTE/ADASYN（上采样） + 正则化，避免下采样丢信息。\n",
    "\n",
    "数据量极大，少数类极少：优先下采样多数类（可能配合多次采样或集成方法，如 BalancedBagging）来节省训练时间。\n",
    "\n",
    "类别边界重叠严重/噪声多：考虑先清洗（TomekLinks/ENN），再上采样；或用组合方法（SMOTEENN）。\n",
    "\n",
    "混合数值+类别特征：优先使用 SMOTENC 或对类别做合适编码/embedding。\n",
    "\n",
    "图像/文本：优先用领域数据增强（旋转/裁剪/同义替换/回译）而不是 SMOTE。\n",
    "\n",
    "# 常见误区（避免踩坑）\n",
    "在全数据上先上采样再划分 → 导致信息泄露，评估虚高。\n",
    "\n",
    "只看 accuracy → 在不平衡任务下会严重误导。\n",
    "\n",
    "盲目把所有类别都平衡到 1:1 → 有时会降低总体性能，应该基于业务需求调整目标比例。\n",
    "\n",
    "忘记 pipeline 中缩放与采样的顺序 → 影响 SMOTE 的距离计算结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c47b1c-5359-4e46-ac63-b0a6465d18f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f8a9db-e6bb-4c96-b4ac-29a365f36328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepseek_env]",
   "language": "python",
   "name": "conda-env-deepseek_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
