{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ff47d34-bb5b-4a35-8112-b049fb489c22",
   "metadata": {},
   "source": [
    "# tf.device \n",
    "是 TensorFlow 提供的一个设备上下文管理器，用来手动指定某个操作或变量运行在哪个设备上，例如：\\\n",
    "CPU（中央处理器）\\\n",
    "GPU（图形处理器）\\\n",
    "TPU（云端专用张量处理器）\n",
    "\n",
    "### 🔧 一、语法格式：\n",
    "with tf.device('/device:DEVICE_TYPE:DEVICE_INDEX'):\\\n",
    "    # 放在该设备上执行的操作或变量定义\n",
    "    \n",
    "DEVICE_TYPE: \"CPU\" 或 \"GPU\"（大小写不敏感）\\\n",
    "DEVICE_INDEX: 通常是 0，表示第一个设备（多个设备从0编号）\n",
    "\n",
    "### ✅ 二、常见示例\n",
    "1. 指定使用 CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc879740-83cf-4c1b-a5de-3a5c33146d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    a = tf.constant([[1.0, 2.0]])\n",
    "    b = tf.constant([[3.0], [4.0]])\n",
    "    result = tf.matmul(a, b)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ec92ca-fa64-4c3c-8361-f0f29eb50e1a",
   "metadata": {},
   "source": [
    "2. 指定使用 GPU（如果可用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9274ac6f-2403-4eb7-8aca-64967c7fe745",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    a = tf.constant([[1.0, 2.0]])\n",
    "    b = tf.constant([[3.0], [4.0]])\n",
    "    result = tf.matmul(a, b)\n",
    "    \n",
    "❗ 如果系统没有 GPU，/GPU:0 会报错或被忽略。可以添加容错：\n",
    "\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    device = '/GPU:0'\n",
    "else:\n",
    "    device = '/CPU:0'\n",
    "\n",
    "with tf.device(device):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973998b2-d3ff-47b5-a36f-15863f48868e",
   "metadata": {},
   "source": [
    "### 📋 三、查看设备信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcf0670-f305-4763-9ab7-8c532cd899d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 列出所有物理设备\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "# 列出所有 GPU\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# 是否有可用的 GPU\n",
    "print(\"GPU Available:\", tf.test.is_gpu_available())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a2acef-2e6e-41e3-8a11-ba6dc9fbdcc5",
   "metadata": {},
   "source": [
    "### 📌 四、适用场景\n",
    "\n",
    "| 典型用途             | 说明                             |\n",
    "| ---------------- | ------------------------------ |\n",
    "| 强制某操作使用 CPU      | 如 `tf.linalg.eig()` 在 GPU 上不支持 |\n",
    "| 控制大模型分布在多个 GPU 上 | 需要手动分配资源                       |\n",
    "| 显式优化性能           | 指定部分操作放在合适设备上                  |\n",
    "| 避免 GPU 内存溢出      | 将临时变量或中间计算放在 CPU               |\n",
    "\n",
    "### 🧠 五、与自动设备分配的关系\n",
    "默认情况下，TensorFlow 会自动分配设备（优先使用 GPU），无需手动指定。\\\n",
    "但有时你希望：\\\n",
    "避免 GPU 内存被占满\\\n",
    "避免某些操作在 GPU 上失败（不支持）\\\n",
    "多 GPU 模型训练时自定义分配\\\n",
    "这时就可用 tf.device 来手动控制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9823b2-3f75-49d2-b3bf-018098eb3941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9c0b71-2878-4d56-9c48-c40e3a668de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepseek_env]",
   "language": "python",
   "name": "conda-env-deepseek_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
