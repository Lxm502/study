{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91b6779b-3588-46e9-a33c-e94fd44213ba",
   "metadata": {},
   "source": [
    "# 📊 TensorFlow 归一化方法对比表\n",
    "| 方法              | 数学公式                                                     | TensorFlow API                                                                                                                      | 主要参数                     | 输出范围 / 特性                                  | 适用场景                                   |                |                           |\n",
    "| --------------- | -------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- | ------------------------ | ------------------------------------------ | -------------------------------------- | -------------- | ------------------------- |\n",
    "| **Min-Max 归一化** | $x' = \\frac{x - x_{min}}{x_{max} - x_{min}}$             | `tf.keras.layers.Normalization(axis=..., mode=\"min_max\")`  或 手动计算： `(x - tf.reduce_min(x)) / (tf.reduce_max(x) - tf.reduce_min(x))` | `axis`（沿哪个维度计算 min、max）  | $[0,1]$ 或 $[a,b]$（可线性映射）                   | 特征范围差异较大，但分布未知时；常用于图像像素缩放到 \\[0,1]      |                |                           |\n",
    "| **Z-Score 标准化** | $x' = \\frac{x - \\mu}{\\sigma}$                            | `tf.keras.layers.Normalization(axis=..., mean=..., variance=...)` 或 `tf.nn.batch_normalization`                                     | `mean`、`variance`、`axis` | 均值 0，方差 1，数据可能为负                           | 常用于需要均值为 0、方差为 1 的模型（如神经网络输入，梯度下降收敛更快） |                |                           |\n",
    "| **L1 归一化**      | ( x' = \\frac{x}{\\|x\\|\\_1} = \\frac{x}{\\sum\\_i             | x\\_i                                                                                                                                | } )                      | `tf.math.l2_normalize(x, ord=1, axis=...)` | `ord=1`、`axis`                         | 使向量的 L1 范数等于 1 | 稀疏特征向量（如 NLP 词袋模型），减少维度影响 |\n",
    "| **L2 归一化**      | $x' = \\frac{x}{\\|x\\|_2} = \\frac{x}{\\sqrt{\\sum_i x_i^2}}$ | `tf.math.l2_normalize(x, axis=...)`                                                                                                 | `axis`                   | 使向量的 L2 范数等于 1                             | 常用于深度学习特征输入、余弦相似度计算、正则化约束              |                |                           |\n",
    "\n",
    "\n",
    "## 🔑 关键点说明\n",
    "\n",
    "- 1.`min-max` → 适合需要固定区间的情况（如图像输入网络前缩放到 [0,1]）。\n",
    "\n",
    "- 2.`z-score` → 适合机器学习中大多数输入特征的标准化。\n",
    "\n",
    "- 3.`L1` 归一化 → 常用于稀疏表示，使所有特征权重的绝对和为 `1`。\n",
    "\n",
    "- 4.`L2` 归一化 → 最常见的向量归一化方法，适合余弦相似度、神经网络输入特征。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5c4839-ea16-4fa2-9587-ea17035d0a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ce0256b-b3e6-47ad-8787-e15f46a7e8f2",
   "metadata": {},
   "source": [
    "# TensorFlow 中的归一化与标准化方法详解\n",
    "\n",
    "在机器学习和深度学习中，对数据进行适当的预处理至关重要。归一化（Normalization）和标准化（Standardization）是两种常见的预处理技术，它们可以加速模型收敛、提高模型性能并防止数值不稳定。本文介绍 TensorFlow 中常用的四种方法：L2 归一化、Min-Max 归一化、Z-score 标准化和 L1 归一化。\n",
    "\n",
    "---\n",
    "# tf.nn.l2_normalize\n",
    "## L2 归一化 (L2 Normalization)\n",
    "\n",
    "**定义**：  \n",
    "`L2 归一化`（也称为欧几里得归一化）将向量的 `L2` 范数（欧几里得长度）缩放到 `1`。即，将向量转换为单位向量。\n",
    "\n",
    "**特点**：\n",
    "*   结果向量的 L2 范数等于 1。\n",
    "*   常用于计算余弦相似度、词向量处理、特征向量归一化等。\n",
    "*   对异常值（outliers）相对敏感。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e831c-8721-46c3-a207-6178836b2385",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.l2_normalize(\n",
    "    x,              # 输入张量\n",
    "    axis=None,      # 归一化的维度\n",
    "    epsilon=1e-12,  # 防止除 0 的小常数\n",
    "    name=None       # 操作名称\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3166f4fe-0dc8-4ef6-b1db-936b9deccf02",
   "metadata": {},
   "source": [
    "| 参数名   | 类型             | 默认值  | 作用说明                                                                 | 备注                     |\n",
    "|----------|------------------|---------|--------------------------------------------------------------------------|--------------------------|\n",
    "| x        | Tensor           | 无      | 需要归一化的输入张量，可以是任意维度                                     | 必需参数                 |\n",
    "| axis     | int 或 list[int] | 无      | 指定归一化维度：<br>- axis=0：按行（跨行）归一化<br>- axis=1：按列（跨列）归一化<br>- 支持多轴如 axis=[1,2] | 必需参数                 |\n",
    "| epsilon  | float            | 1e-12   | 防止分母为零的极小值                                                     | 可选参数                 |\n",
    "| name     | string           | 无      | 操作名称                                                                 | 通常无需设置，为可选参数 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c0b79-a8b1-4229-8c6a-c7d71e0192f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9bbe80f-9a79-4493-9d22-ad297b9bb14c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0470f5de-b2ed-4063-92f4-e0389716beea",
   "metadata": {},
   "source": [
    "# 🔹 L1 归一化\n",
    "在 `TensorFlow` 中，`L1` 归一化 是通过 `tf.math.l2_normalize` 的 `p=1` 来实现的。\n",
    "\n",
    "不过官方并没有单独的 `l1_normalize` API，一般我们使用 `tf.norm` + 张量除法的方式。\n",
    "\n",
    "---\n",
    "## ✨ 使用方法 1：手动实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e768058a-e173-436a-bb19-c1b24876f55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 创建一个张量\n",
    "x = tf.constant([[1.0, -2.0, 3.0],\n",
    "                 [4.0, 5.0, -6.0]], dtype=tf.float32)\n",
    "# # ord:2代表范数，1代表L1范数，fro计算 Frobenius 范数（矩阵的 L2 范数），适用于矩阵\n",
    "# L1 归一化：每个向量除以其 L1 范数（绝对值和）\n",
    "# tf.norm()用于计算张量（tensor）的范数（norm）的函数\n",
    "x_l1 = x / tf.norm(x, ord=1, axis=1, keepdims=True) \n",
    "print(\"原始张量:\\n\", x.numpy())\n",
    "print(\"L1 归一化结果:\\n\", x_l1.numpy())\n",
    "\n",
    "输出：\n",
    "原始张量:\n",
    " [[ 1. -2.  3.uu\n",
    "  [ 4.  5. -6.]]\n",
    "L1 归一化结果:\n",
    " [[ 0.16666667 -0.33333334  0.5]\n",
    "  [ 0.26666668  0.33333334 -0.4]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4439c1-36ef-4936-be78-7d9a3b8152ba",
   "metadata": {},
   "source": [
    "## ✨ 使用方法 2：封装函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51024cc-d73b-42fa-94b0-eb8a18d339cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_normalize(x, axis=None, epsilon=1e-12):\n",
    "    return x / (tf.reduce_sum(tf.abs(x), axis=axis, keepdims=True) + epsilon)\n",
    "\n",
    "x_l1 = l1_normalize(x, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf5ec6c-e70a-458f-910a-7eec400055ef",
   "metadata": {},
   "source": [
    "| 参数/概念        | 说明                                                                        |\n",
    "| ------------ | ------------------------------------------------------------------------- |\n",
    "| **x**        | 输入张量，可以是任意维度。                                                             |\n",
    "| **ord=1**    | 在 `tf.norm` 中指定 L1 范数（绝对值和）。                                              |\n",
    "| **axis**     | 归一化的维度。<br>- `None`：对整个张量求 L1 范数。<br>- `0`：按列（跨行）归一化。<br>- `1`：按行（跨列）归一化。 |\n",
    "| **keepdims** | 是否保持维度。`True` 会保留归一化维度，便于广播。                                              |\n",
    "| **epsilon**  | 避免除零的微小数值，通常设为 `1e-12`。                                                   |\n",
    "| **返回值**      | 与输入 `x` 形状相同的归一化张量。                                                       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e37211-03c1-4620-9d0a-dded80de47cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8266ac78-992e-416a-b5c2-b4386f19942c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ec39d-a5be-42ac-a65e-ce726cc5952f",
   "metadata": {},
   "source": [
    "# 🔹 Min-Max 归一化\n",
    "### 1️⃣ 使用方法\n",
    "\n",
    "TensorFlow `没有`直接的 `tf.min_max_normalize()` 方法，通常需要手动实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ebd56-7543-4c07-b43e-cdb94412e666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 生成随机张量\n",
    "x = tf.random.uniform(shape=(5,), minval=10, maxval=100, dtype=tf.float32)\n",
    "\n",
    "# min-max归一化到 [0, 1]\n",
    "x_min = tf.reduce_min(x)\n",
    "x_max = tf.reduce_max(x)\n",
    "x_norm = (x - x_min) / (x_max - x_min)\n",
    "\n",
    "print(\"原始张量:\", x.numpy())\n",
    "print(\"归一化张量:\", x_norm.numpy())\n",
    "\n",
    "# 如果想归一化到 [-1, 1]\n",
    "x_norm_scaled = x_norm * 2 - 1\n",
    "print(\"归一化到 [-1,1]:\", x_norm_scaled.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0dcb25b-45fd-4730-ac4f-6d1ec345a30c",
   "metadata": {},
   "source": [
    "### 2️⃣ 参数详解表格\n",
    "| 参数/变量     | 说明                                | 默认值  | 是否必须 |\n",
    "| --------- | --------------------------------- | ---- | ---- |\n",
    "| `x`       | 输入张量                              | 无    | ✅    |\n",
    "| `x_min`   | 输入张量的最小值（用 `tf.reduce_min(x)` 计算） | 动态计算 | ✅    |\n",
    "| `x_max`   | 输入张量的最大值（用 `tf.reduce_max(x)` 计算） | 动态计算 | ✅    |\n",
    "| `min_val` | 归一化后目标范围的下界                       | 0    | ❌    |\n",
    "| `max_val` | 归一化后目标范围的上界                       | 1    | ❌    |\n",
    "\n",
    "---\n",
    "### 3️⃣ 归一化到任意区间的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f2979d-6dc1-4078-bc5c-21b18cf9ebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(x, min_val=0.0, max_val=1.0):\n",
    "    x_min = tf.reduce_min(x)\n",
    "    x_max = tf.reduce_max(x)\n",
    "    x_norm = (x - x_min) / (x_max - x_min)  # 归一化到 [0,1]\n",
    "    return x_norm * (max_val - min_val) + min_val\n",
    "\n",
    "# 示例：归一化到 [5, 10]\n",
    "x = tf.constant([2.0, 4.0, 6.0, 8.0])\n",
    "x_scaled = min_max_normalize(x, min_val=5, max_val=10)\n",
    "print(x_scaled.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bd84ff-8a6d-44d2-b407-803af0d50809",
   "metadata": {},
   "source": [
    "### 👉 所以，Min-Max 归一化\n",
    "在 TensorFlow 中主要依赖 `tf.reduce_min` 和 `tf.reduce_max` 来动态计算范围，然后手动缩放。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c42121e-5fb9-4b7a-b1da-f7e337c5cf72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "748740b1-06b3-4bc5-b5db-96b4d2083630",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a957ab7b-be2c-4813-878c-4711d28cc09f",
   "metadata": {},
   "source": [
    "# Z-Score 标准化\n",
    "## 📌 Z-Score 标准化公式:\n",
    "   - 𝑥′=(𝑥−𝜇)/𝜎\n",
    "\n",
    "- μ：均值\n",
    "- σ：标准差\n",
    "\n",
    "Z-Score 标准化的结果是让数据分布 均值为 0，标准差为 1，常用于机器学习的特征预处理。\n",
    "\n",
    "## ✅ 在 TensorFlow 中的实现方法\n",
    "### 方法 1：手动计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5357591e-652c-4614-b622-e5d5a1914c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 生成随机张量\n",
    "x = tf.random.uniform(shape=(5,), minval=0, maxval=10, dtype=tf.float32)\n",
    "\n",
    "# 计算均值和标准差\n",
    "mean, variance = tf.nn.moments(x, axes=[0]) # --> 返回 均值 和 方差\n",
    "std = tf.sqrt(variance)\n",
    "\n",
    "# Z-Score 标准化\n",
    "zscore = (x - mean) / std\n",
    "\n",
    "print(\"原始数据:\", x.numpy())\n",
    "print(\"均值:\", mean.numpy())\n",
    "print(\"标准差:\", std.numpy())\n",
    "print(\"Z-Score 标准化:\", zscore.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93220cad-c07e-4922-b597-48186657e706",
   "metadata": {},
   "source": [
    "### 方法 2：使用 `tf.nn.batch_normalization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9e2616-f38d-4280-bedb-178441dcff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x = tf.random.uniform(shape=(5,), minval=0, maxval=10, dtype=tf.float32)\n",
    "\n",
    "mean, variance = tf.nn.moments(x, axes=[0])\n",
    "epsilon = 1e-8  # 防止除 0\n",
    "\n",
    "zscore = tf.nn.batch_normalization(\n",
    "    x,\n",
    "    mean=mean,\n",
    "    variance=variance,\n",
    "    offset=None,\n",
    "    scale=None,\n",
    "    variance_epsilon=epsilon\n",
    ")\n",
    "\n",
    "print(\"Z-Score 标准化:\", zscore.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93685a25-91ff-4822-9486-0cead3ff9e13",
   "metadata": {},
   "source": [
    "- 这种方式其实是 批归一化（Batch Normalization） 的核心步骤之一，可以等价实现 Z-Score 标准化。\n",
    "\n",
    "#### 📋 参数表格说明（以 tf.nn.batch_normalization 为例）\n",
    "| 参数                 | 类型                 | 说明                             |\n",
    "| ------------------ | ------------------ | ------------------------------ |\n",
    "| `x`                | `Tensor`           | 输入张量（需要标准化的数据）                 |\n",
    "| `mean`             | `Tensor` (同 dtype) | 数据的均值（一般通过 `tf.nn.moments` 计算） |\n",
    "| `variance`         | `Tensor` (同 dtype) | 数据的方差（同样通过 `tf.nn.moments` 计算） |\n",
    "| `offset`           | `Tensor` 或 `None`  | 偏移值，通常设为 `None`（等价于 0）         |\n",
    "| `scale`            | `Tensor` 或 `None`  | 缩放因子，通常设为 `None`（等价于 1）        |\n",
    "| `variance_epsilon` | `float`            | 防止除 0 的极小数，默认 `1e-8`           |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a726dc4-efb3-4313-aec9-9104ce60cceb",
   "metadata": {},
   "source": [
    "## 🎯 总结\n",
    "\n",
    "- `L1`/`L2` 归一化：让向量的范数为 1。\n",
    "\n",
    "- `Min`-`Max` 归一化：映射到 [0, 1] 区间。\n",
    "\n",
    "- `Z-Score` 标准化：调整到均值为 0，方差为 1。\n",
    "\n",
    "在 TensorFlow 中，Z-Score 标准化常用 手动公式 或 `tf.nn.batch_normalization` 来实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd981ecb-3d3c-4568-a4ba-7f5a65ed0c89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepseek_env]",
   "language": "python",
   "name": "conda-env-deepseek_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
