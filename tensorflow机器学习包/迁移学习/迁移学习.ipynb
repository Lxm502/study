{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "464b2d67-1ca4-474d-90bf-7a183ead388d",
   "metadata": {},
   "source": [
    "# ğŸŒ± ä»€ä¹ˆæ˜¯è¿ç§»å­¦ä¹ ï¼Ÿ\n",
    "\n",
    "è¿ç§»å­¦ä¹ æ˜¯ä¸€ç§ `åˆ©ç”¨å·²æœ‰æ¨¡å‹çš„çŸ¥è¯†æ¥è§£å†³æ–°ä»»åŠ¡` çš„æ–¹æ³•ã€‚é€šå¸¸ç”¨åœ¨ `æ•°æ®é‡è¾ƒå°‘çš„æ–°ä»»åŠ¡` ä¸Šï¼Œæ¯”å¦‚ä½ åªæœ‰å‡ åƒå¼ çŒ«ç‹—å›¾ç‰‡ï¼Œä½†ä½ å¯ä»¥åˆ©ç”¨åœ¨ `ImageNet` ä¸Šè®­ç»ƒè¿‡çš„ å¤§è§„æ¨¡ `CNN` æ¨¡å‹ï¼ˆå¦‚ `ResNet`ã€`MobileNet`ï¼‰æ¥åŠ å¿«è®­ç»ƒå’Œæé«˜å‡†ç¡®ç‡ã€‚\n",
    "\n",
    "- æ ¸å¿ƒæ€æƒ³ï¼š\n",
    "\n",
    "    - ä¸ä»é›¶å¼€å§‹è®­ç»ƒï¼ˆé¿å…è¿‡æ‹Ÿåˆã€å‡å°‘ç®—åŠ›éœ€æ±‚ï¼‰ã€‚\n",
    "    \n",
    "    - å¤ç”¨å¤§æ¨¡å‹å­¦åˆ°çš„ ç‰¹å¾æå–èƒ½åŠ›ã€‚\n",
    "\n",
    "---\n",
    "# ğŸ”‘ è¿ç§»å­¦ä¹ å¸¸è§æ–¹å¼\n",
    "\n",
    "- 1.ç‰¹å¾æå– (Feature Extraction)\n",
    "\n",
    "    - å†»ç»“é¢„è®­ç»ƒæ¨¡å‹çš„å·ç§¯å±‚ï¼Œåªåœ¨è¾“å‡ºå±‚ä¸Šæ·»åŠ æ–°çš„åˆ†ç±»å™¨å¹¶è®­ç»ƒã€‚\n",
    "    \n",
    "    - é€‚åˆæ•°æ®é‡å°‘ã€å’ŒåŸä»»åŠ¡ç›¸ä¼¼çš„åœºæ™¯ã€‚\n",
    "\n",
    "- 2.å¾®è°ƒ (Fine-tuning)\n",
    "\n",
    "    - è§£å†»éƒ¨åˆ†é¢„è®­ç»ƒå±‚ï¼ˆé€šå¸¸æ˜¯é åçš„å±‚ï¼‰ï¼Œè¿åŒæ–°åˆ†ç±»å±‚ä¸€èµ·è®­ç»ƒã€‚\n",
    "    \n",
    "    - é€‚åˆæ•°æ®é‡ä¸­ç­‰æˆ–ä»»åŠ¡å’Œé¢„è®­ç»ƒä»»åŠ¡æœ‰ä¸€å®šå·®å¼‚æ—¶ã€‚\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de33f82-ece1-4416-8d62-fe132e3a9d30",
   "metadata": {},
   "source": [
    "## âš™ï¸ TensorFlow/Keras å®ç°è¿ç§»å­¦ä¹ \n",
    "### 1. åŠ è½½é¢„è®­ç»ƒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902c3069-6505-491f-b625-008938fdece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# ä»¥ MobileNetV2 ä¸ºä¾‹ï¼ˆImageNet é¢„è®­ç»ƒï¼‰\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,  # ä¸è¦æœ€åçš„å…¨è¿æ¥å±‚\n",
    "    weights='imagenet'  \n",
    ")\n",
    "\n",
    "# å†»ç»“é¢„è®­ç»ƒå±‚\n",
    "base_model.trainable = False "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4d6383-f4d5-4866-abe9-a557209def3c",
   "metadata": {},
   "source": [
    "1.\n",
    "`input_shape`=(224,224,3)\n",
    "    - æŒ‡å®šè¾“å…¥å›¾åƒçš„å°ºå¯¸ä¸º224Ã—224åƒç´ ï¼Œ3ä¸ªé¢œè‰²é€šé“ï¼ˆRGBï¼‰\n",
    "    - è¿™å†³å®šäº†ç½‘ç»œæ¥å—çš„è¾“å…¥å¼ é‡çš„å½¢çŠ¶\n",
    "\n",
    "2.\n",
    "`include_top` = `False`\n",
    "    - ä¸åŒ…å«æ¨¡å‹çš„é¡¶å±‚ï¼ˆå…¨è¿æ¥åˆ†ç±»å±‚ï¼‰\n",
    "    - é€šå¸¸ç”¨äºè¿ç§»å­¦ä¹ ï¼Œè¿™æ ·æˆ‘ä»¬å¯ä»¥æ·»åŠ è‡ªå·±çš„åˆ†ç±»å±‚\n",
    "    - å½“è®¾ä¸º`False`æ—¶ï¼Œè¾“å‡ºå°†æ˜¯ç‰¹å¾å›¾è€Œä¸æ˜¯ç±»åˆ«é¢„æµ‹\n",
    "\n",
    "3.\n",
    "`weights`= `'imagenet'`\n",
    "    - ä½¿ç”¨åœ¨ImageNetæ•°æ®é›†ä¸Šé¢„è®­ç»ƒçš„æƒé‡åˆå§‹åŒ–æ¨¡å‹\n",
    "    - è¿™ä½¿å¾—æ¨¡å‹å·²ç»å…·å¤‡ä»å›¾åƒä¸­æå–æœ‰ç”¨ç‰¹å¾çš„èƒ½åŠ›\n",
    "    - å¦‚æœä¸è®¾ç½®æˆ–è®¾ä¸ºNoneï¼Œæ¨¡å‹å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æƒé‡\n",
    "\n",
    "4.\n",
    "`bast_model.trainable` = `False`\n",
    "\n",
    "    - å†»ç»“åŸºç¡€æ¨¡å‹çš„æ‰€æœ‰å±‚ï¼Œä½¿å…¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ä¸å¯è®­ç»ƒ\n",
    "    - è¿™æ„å‘³ç€åœ¨`åç»­è®­ç»ƒ`ä¸­åªä¼š`æ›´æ–°æ–°æ·»åŠ çš„å±‚`çš„æƒé‡\n",
    "    - è¿™å¯ä»¥é˜²æ­¢é¢„è®­ç»ƒçš„ç‰¹å¾æå–èƒ½åŠ›è¢«ç ´åï¼ŒåŒæ—¶åŠ å¿«è®­ç»ƒé€Ÿåº¦\n",
    "---\n",
    "### 2. å†»ç»“å·ç§¯åŸºï¼ˆç‰¹å¾æå–ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a33a36a-c5bf-4452-b7e6-a9a84445154b",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# æ­å»ºæ–°æ¨¡å‹\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),  # å…¨å±€å¹³å‡æ± åŒ–\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')  # å‡è®¾æœ‰ 10 ä¸ªç±»åˆ«\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aa4b45-4379-4528-b1b3-1e7068bda6ce",
   "metadata": {},
   "source": [
    "### 3. è®­ç»ƒåˆ†ç±»å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa2cf08-6a0d-40e7-b13f-bb22efc24f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, validation_data=val_ds, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab79175b-3af3-4206-95ab-5670080cf6f8",
   "metadata": {},
   "source": [
    "### 4. å¾®è°ƒéƒ¨åˆ†å±‚\n",
    "\n",
    "å½“`åˆ†ç±»å±‚è®­ç»ƒå¥½`åï¼Œå¯ä»¥`è§£å†»`ä¸€éƒ¨åˆ†å·ç§¯å±‚è¿›è¡Œ `å¾®è°ƒ`ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967c6d65-7335-41d1-a058-24208a102445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è§£å†»éƒ¨åˆ†å±‚ï¼ˆä¾‹å¦‚æœ€å 20 å±‚ï¼‰\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# ä½¿ç”¨è¾ƒå°å­¦ä¹ ç‡ç»§ç»­è®­ç»ƒ\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_fine = model.fit(train_ds, validation_data=val_ds, epochs=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67331f1-15f4-4be0-87d4-a8083e4b6ce3",
   "metadata": {},
   "source": [
    "## ğŸ“Š è¿ç§»å­¦ä¹ çš„ä¼˜ç‚¹\n",
    "\n",
    " - å‡å°‘è®­ç»ƒæ—¶é—´ã€‚\n",
    "\n",
    " - æé«˜å°æ•°æ®é›†ä¸Šçš„è¡¨ç°ã€‚\n",
    "\n",
    " - é¿å…è¿‡æ‹Ÿåˆã€‚\n",
    "\n",
    "---\n",
    "## ğŸš€ æ¨èçš„é¢„è®­ç»ƒæ¨¡å‹ï¼ˆtf.keras.applicationsï¼‰\n",
    "\n",
    " - `VGG16` / `VGG19`\n",
    "\n",
    " - `ResNet50`\n",
    "\n",
    " - `InceptionV3`\n",
    "\n",
    " - `MobileNetV2`ï¼ˆè½»é‡çº§ï¼Œé€‚åˆç§»åŠ¨ç«¯ï¼‰\n",
    "\n",
    " - `EfficientNetB0~B7`ï¼ˆæ€§èƒ½æœ€ä¼˜ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4028c92-7dc4-4ff6-9897-803e3e285346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3b61245-7df6-445a-8817-479d14e7fe03",
   "metadata": {},
   "source": [
    "# å®Œæ•´çš„çŒ«ç‹—åˆ†ç±»è¿ç§»å­¦ä¹ é¡¹ç›®ï¼š\n",
    "æ•°æ®å‡†å¤‡ â†’ æ¨¡å‹æ„å»º â†’ è®­ç»ƒ â†’ å¯è§†åŒ–ç»“æœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cd5f18-5d3f-4a7c-9103-22e0118a89cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ä¸‹è½½æ•°æ®é›†\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "(train_ds, val_ds), ds_info = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split=['train[:80%]', 'train[80%:]'],\n",
    "    as_supervised=True,  # è¿”å› (image, label)\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "# é¢„å¤„ç†å‡½æ•°\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, (224, 224))   # è°ƒæ•´åˆ°æ¨¡å‹è¾“å…¥å¤§å°\n",
    "    image = tf.cast(image, tf.float32) / 255.0   # å½’ä¸€åŒ–\n",
    "    return image, label\n",
    "\n",
    "# åº”ç”¨é¢„å¤„ç† + æ‰¹å¤„ç†\n",
    "BATCH_SIZE = 32\n",
    "train_ds = train_ds.map(preprocess).shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(preprocess).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆä¸å«é¡¶å±‚ï¼‰\n",
    "base_model = tf.keras.applications.MobileNetV2(\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False,\n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# å†»ç»“å·ç§¯åŸº\n",
    "base_model.trainable = False\n",
    "\n",
    "# æ­å»ºå®Œæ•´æ¨¡å‹\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')  # äºŒåˆ†ç±»\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                    validation_data=val_ds,\n",
    "                    epochs=5)\n",
    "# è§£å†»éƒ¨åˆ†å·ç§¯å±‚\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_fine = model.fit(train_ds,\n",
    "                         validation_data=val_ds,\n",
    "                         epochs=3)\n",
    "\n",
    "def plot_history(history, fine_tune_history=None):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(acc, label='train_acc')\n",
    "    plt.plot(val_acc, label='val_acc')\n",
    "    plt.legend()\n",
    "    plt.title(\"Accuracy\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(loss, label='train_loss')\n",
    "    plt.plot(val_loss, label='val_loss')\n",
    "    plt.legend()\n",
    "    plt.title(\"Loss\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)\n",
    "\n",
    "## å¦‚æœåŠ äº†å¾®è°ƒ\n",
    "#plot_history(history, history_fine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepseek_env]",
   "language": "python",
   "name": "conda-env-deepseek_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
