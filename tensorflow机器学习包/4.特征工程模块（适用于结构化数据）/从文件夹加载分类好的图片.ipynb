{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9acc2460-fc8d-4fd5-a91f-9ec29ce2af61",
   "metadata": {},
   "source": [
    "# tf.keras.preprocessing.image_dataset_from_directory\n",
    "## 1. åŸºæœ¬åŠŸèƒ½\n",
    "\n",
    "å®ƒä¼šä» ç›®å½•ç»“æ„ ä¸­è‡ªåŠ¨åˆ›å»º `tf.data.Dataset`ï¼ŒåŒæ—¶ä¼šæ ¹æ® `å­æ–‡ä»¶å¤¹çš„åå­—` è‡ªåŠ¨ç”Ÿæˆç±»åˆ«æ ‡ç­¾ã€‚\n",
    "\n",
    "ğŸ“‚ ç›®å½•ç»“æ„ç¤ºä¾‹ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f073b243-3057-492e-9bf1-5558f2319a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset/\n",
    "â”œâ”€â”€ train/\n",
    "â”‚   â”œâ”€â”€ cats/\n",
    "â”‚   â”‚   â”œâ”€â”€ cat1.jpg\n",
    "â”‚   â”‚   â”œâ”€â”€ cat2.jpg\n",
    "â”‚   â””â”€â”€ dogs/\n",
    "â”‚       â”œâ”€â”€ dog1.jpg\n",
    "â”‚       â”œâ”€â”€ dog2.jpg\n",
    "â””â”€â”€ val/\n",
    "    â”œâ”€â”€ cats/\n",
    "    â””â”€â”€ dogs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200f5b9a-0409-4c7f-941f-68b5511f1efd",
   "metadata": {},
   "source": [
    "## 2. ä¸ºä»€ä¹ˆéœ€è¦ä½¿ç”¨å®ƒï¼Ÿ\n",
    "- æç®€ä»£ç ï¼šç”¨ä¸€è¡Œä»£ç æ›¿ä»£äº†ç¹ççš„å›¾åƒè¯»å–ã€è§£ç ã€è°ƒæ•´å¤§å°ã€æ ‡æ³¨å’Œæ‰¹å¤„ç†æµç¨‹ã€‚\n",
    "\n",
    "- é«˜æ€§èƒ½ï¼šç”Ÿæˆçš„æ˜¯ `tf.data.Dataset` å¯¹è±¡ï¼Œæ”¯æŒ `TensorFlow` çš„æ‰€æœ‰é«˜æ•ˆæ•°æ®ç®¡é“åŠŸèƒ½ï¼ˆé¢„å–ã€ç¼“å­˜ã€å¹¶è¡ŒåŒ–ç­‰ï¼‰ã€‚\n",
    "\n",
    "- å†…å­˜é«˜æ•ˆï¼šä¸ä¼šä¸€æ¬¡æ€§å°†æ‰€æœ‰å›¾åƒåŠ è½½åˆ°å†…å­˜ä¸­ï¼Œè€Œæ˜¯åŠ¨æ€åœ°ä»ç£ç›˜è¯»å–ï¼Œé€‚åˆå¤„ç†å¤§å‹æ•°æ®é›†ã€‚\n",
    "\n",
    "- è‡ªåŠ¨æ ‡ç­¾ï¼šæ ¹æ®ç›®å½•ç»“æ„è‡ªåŠ¨æ¨æ–­æ ‡ç­¾ï¼Œæ— éœ€æ‰‹åŠ¨åˆ›å»ºæ ‡ç­¾æ–‡ä»¶ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca50882e-8f92-4a62-bd25-5456b622b7a3",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. æ ¸å¿ƒå‚æ•°è¯¦è§£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc58032-7eea-46b5-ac7a-8680586972eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory,                   # å¿…éœ€ï¼šæ•°æ®æ‰€åœ¨ç›®å½•çš„è·¯å¾„\n",
    "    labels='inferred',           # æ ‡ç­¾æ¥æºï¼š'inferred'ï¼ˆä»ç›®å½•ç»“æ„ï¼‰ï¼Œæˆ– Noneï¼ˆæ— æ ‡ç­¾ï¼‰\n",
    "    label_mode='int',            # æ ‡ç­¾æ ¼å¼ï¼š'int'ï¼ˆæ•´æ•°æ ‡ç­¾ï¼‰ï¼Œ'categorical'ï¼ˆone-hotï¼‰ï¼Œ'binary'ï¼ˆäºŒåˆ†ç±»ï¼‰\n",
    "    class_names=None,            # æ˜¾å¼æŒ‡å®šç±»åˆ«åç§°åˆ—è¡¨ï¼Œç”¨äºæ§åˆ¶é¡ºåº\n",
    "    color_mode='rgb',            # å›¾åƒé€šé“ï¼š'rgb'ï¼ˆ3é€šé“ï¼‰ï¼Œ'grayscale'ï¼ˆ1é€šé“ï¼‰ï¼Œ'rgba'ï¼ˆ4é€šé“ï¼‰\n",
    "    batch_size=32,               # æ‰¹æ¬¡å¤§å°\n",
    "    image_size=(256, 256),       # å°†æ‰€æœ‰å›¾åƒè°ƒæ•´ä¸ºæ­¤å°ºå¯¸ï¼ˆé«˜åº¦ï¼Œå®½åº¦ï¼‰\n",
    "    shuffle=True,                # æ˜¯å¦æ‰“ä¹±æ•°æ®\n",
    "    seed=None,                   # éšæœºç§å­ï¼Œç”¨äºå¯é‡ç°çš„ shuffling\n",
    "    validation_split=None,       # åˆ†å‰²éƒ¨åˆ†æ•°æ®ä½œä¸ºéªŒè¯é›†ï¼ˆ0-1ä¹‹é—´çš„æµ®ç‚¹æ•°ï¼‰\n",
    "    subset=None,                 # å¦‚æœä½¿ç”¨ validation_splitï¼ŒæŒ‡å®šæ˜¯ 'training' è¿˜æ˜¯ 'validation'\n",
    "    interpolation='bilinear',    # å›¾åƒè°ƒæ•´å¤§å°çš„æ’å€¼æ–¹æ³•ï¼š'bilinear', 'nearest', ç­‰\n",
    "    follow_links=False,          # æ˜¯å¦è·Ÿéšå­ç›®å½•ä¸­çš„ç¬¦å·é“¾æ¥\n",
    "    crop_to_aspect_ratio=False,  # æ˜¯å¦è£å‰ªå›¾åƒä»¥ä¿æŒåŸå§‹å®½é«˜æ¯”\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f849a3e7-a9a0-4779-b21d-48b48362e3d9",
   "metadata": {},
   "source": [
    "### æœ€é‡è¦çš„å‚æ•°ï¼š\n",
    "- 1.`directory`ï¼šåŒ…å«æŒ‰ç±»åˆ«åˆ†ç»„çš„å­ç›®å½•çš„ç›®å½•è·¯å¾„ã€‚\n",
    "\n",
    "- 2.`image_size`ï¼šå¿…é¡»æŒ‡å®šã€‚æ‰€æœ‰å›¾åƒå°†è¢«è°ƒæ•´ä¸ºæ­¤å°ºå¯¸ã€‚ä¾‹å¦‚ (224, 224)ã€‚\n",
    "\n",
    "- 3.`batch_size`ï¼šæ¯ä¸ªæ‰¹æ¬¡ä¸­åŒ…å«çš„æ ·æœ¬æ•°ã€‚\n",
    "\n",
    "- 4.`label_mode`ï¼š\n",
    "\n",
    "    - `int`ï¼šæ ‡ç­¾ä¸ºæ•´æ•°ï¼ˆå¦‚ 0, 1, 2ï¼‰ã€‚é€‚ç”¨äº `sparse_categorical_crossentropy` æŸå¤±ã€‚\n",
    "    \n",
    "    - `categorical`ï¼šæ ‡ç­¾ä¸º `one-hot` ç¼–ç å‘é‡ï¼ˆå¦‚ [1, 0, 0], [0, 1, 0]ï¼‰ã€‚é€‚ç”¨äº `categorical_crossentropy` æŸå¤±ã€‚\n",
    "    \n",
    "    - `binary`ï¼šæ ‡ç­¾ä¸ºäºŒåˆ†ç±»çš„ 0 æˆ– 1ã€‚é€‚ç”¨äº `binary_crossentropy` æŸå¤±ã€‚\n",
    "\n",
    "- 5.`validation_split` å’Œ `subset`ï¼šç”¨äºä»åŒä¸€ç›®å½•åˆ›å»ºè®­ç»ƒ/éªŒè¯é›†ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f262812d-b972-48a5-bea7-bed0c9edb26b",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹\n",
    "ç¤ºä¾‹ 1ï¼šåˆ›å»ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ï¼ˆä»ä¸åŒç›®å½•ï¼‰\\\n",
    "è¿™æ˜¯æœ€æ¨èçš„æ–¹å¼ï¼Œè®­ç»ƒé›†å’ŒéªŒè¯é›†åˆ†åˆ«æ”¾åœ¨ä¸åŒçš„æ–‡ä»¶å¤¹ä¸­ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a75874-ee8a-47f2-bf5d-93c45d6c0f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# å®šä¹‰å›¾åƒå¤§å°å’Œæ‰¹æ¬¡å¤§å°\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# ä»è®­ç»ƒç›®å½•åˆ›å»ºè®­ç»ƒé›†\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory='data/train',      # è®­ç»ƒé›†ç›®å½•\n",
    "    labels='inferred',           # ä»ç›®å½•ç»“æ„æ¨æ–­æ ‡ç­¾\n",
    "    label_mode='categorical',    # ä½¿ç”¨ one-hot ç¼–ç æ ‡ç­¾\n",
    "    color_mode='rgb',            # å½©è‰²å›¾åƒ\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,         # è°ƒæ•´å›¾åƒå¤§å°\n",
    "    shuffle=True,                # æ‰“ä¹±æ•°æ®\n",
    "    seed=123,                    # éšæœºç§å­\n",
    ")\n",
    "\n",
    "# ä»éªŒè¯ç›®å½•åˆ›å»ºéªŒè¯é›†\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory='data/validation', # éªŒè¯é›†ç›®å½•\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMG_SIZE,\n",
    "    shuffle=False,               # éªŒè¯é›†é€šå¸¸ä¸éœ€è¦æ‰“ä¹±\n",
    ")\n",
    "\n",
    "# æŸ¥çœ‹æ•°æ®é›†ä¿¡æ¯\n",
    "print(f\"è®­ç»ƒé›†ç±»åˆ«: {train_ds.class_names}\")\n",
    "print(f\"è®­ç»ƒé›†æ‰¹æ¬¡å½¢çŠ¶: {next(iter(train_ds))[0].shape}\") # (32, 224, 224, 3)\n",
    "print(f\"æ ‡ç­¾å½¢çŠ¶: {next(iter(train_ds))[1].shape}\")       # (32, 2) - å‡è®¾æœ‰2ä¸ªç±»åˆ«"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579b77ad-a981-4e4c-ae03-f0256c7ee0e0",
   "metadata": {},
   "source": [
    "ç¤ºä¾‹ 2ï¼šä»åŒä¸€ç›®å½•åˆ†å‰²è®­ç»ƒ/éªŒè¯é›† \\\n",
    "å½“ä½ çš„æ‰€æœ‰æ•°æ®éƒ½åœ¨ä¸€ä¸ªç›®å½•ä¸­æ—¶ï¼Œå¯ä»¥ä½¿ç”¨ `validation_split` å‚æ•°ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd51bff0-069f-4fd6-85dc-31aa6298cf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºè®­ç»ƒé›†ï¼ˆ80%çš„æ•°æ®ï¼‰\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory='data/all_images',\n",
    "    validation_split=0.2,        # ä½¿ç”¨20%ä½œä¸ºéªŒè¯é›†\n",
    "    subset='training',           # è¿™æ˜¯è®­ç»ƒéƒ¨åˆ†\n",
    "    seed=123,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "# åˆ›å»ºéªŒè¯é›†ï¼ˆ20%çš„æ•°æ®ï¼‰\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory='data/all_images',\n",
    "    validation_split=0.2,\n",
    "    subset='validation',         # è¿™æ˜¯éªŒè¯éƒ¨åˆ†\n",
    "    seed=123,                    # å¿…é¡»ä½¿ç”¨ç›¸åŒçš„seedï¼\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83255c6a-0df3-4278-8e94-c7053bfa5db7",
   "metadata": {},
   "source": [
    "## 5 éå†æ•°æ®é›†\n",
    "ä½¿ç”¨ æ•°æ®é›† `.take(n)` ä»æ•°æ®é›†ä¸­å–å‡ºå‰ `n` ä¸ªæ‰¹æ¬¡çš„æ•°æ®ï¼ˆnæ˜¯ä½ ä¼ å…¥çš„æ•°å­—ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52673c51-0488-4966-a2be-ce217ff468b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in train_ds.take(1):\n",
    "    print(images.shape)  # (32, 224, 224, 3)\n",
    "    print(labels.numpy())  # e.g. [0, 1, 0, ...]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819d8740-a829-4d28-b72e-ec5e3575bbc1",
   "metadata": {},
   "source": [
    "## 6. æ•°æ®é¢„å¤„ç†å’Œå¢å¼º\n",
    "åˆ›å»ºæ•°æ®é›†åï¼Œä½ é€šå¸¸éœ€è¦æ·»åŠ é¢„å¤„ç†å’Œæ•°æ®å¢å¼ºã€‚\n",
    "\n",
    "æ ‡å‡†é¢„å¤„ç†ï¼ˆå½’ä¸€åŒ–ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991e7d3f-80d2-47ce-9c75-5fe0af2961c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰é¢„å¤„ç†å‡½æ•°ï¼šå°†åƒç´ å€¼ä» [0, 255] å½’ä¸€åŒ–åˆ° [0, 1] æˆ– [-1, 1]\n",
    "def preprocess(image, label):\n",
    "    # æ–¹æ³•1: å½’ä¸€åŒ–åˆ° [0, 1]\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    \n",
    "    # æ–¹æ³•2: å½’ä¸€åŒ–åˆ° [-1,  ]ï¼ˆæŸäº›é¢„è®­ç»ƒæ¨¡å‹éœ€è¦ï¼‰\n",
    "    # image = (tf.cast(image, tf.float32) / 127.5) - 1\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "# åº”ç”¨é¢„å¤„ç†\n",
    "train_ds = train_ds.map(preprocess)\n",
    "val_ds = val_ds.map(preprocess)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95b73613-3ae5-425c-ae45-5e27cebff714",
   "metadata": {},
   "source": [
    "æ•°æ®å¢å¼º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae35abcc-4bd0-4a61-b9b2-a881b1e4820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºæ•°æ®å¢å¼ºå±‚\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    # ä¼šéšæœºå¯¹è¾“å…¥å›¾åƒè¿›è¡Œæ°´å¹³ç¿»è½¬ã€å‚ç›´ç¿»è½¬ï¼Œæˆ–è€…åŒæ—¶è¿›è¡Œæ°´å¹³å’Œå‚ç›´ç¿»è½¬ï¼ˆå³å¯¹è§’çº¿ç¿»è½¬ï¼‰\n",
    "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tf.keras.layers.RandomRotation(0.2), # ç”¨äºå¯¹è¾“å…¥å›¾åƒè¿›è¡Œéšæœºæ—‹è½¬\n",
    "    tf.keras.layers.RandomZoom(0.1),     # ç”¨äºå¯¹è¾“å…¥å›¾åƒè¿›è¡Œéšæœºç¼©æ”¾ï¼ˆæ”¾å¤§æˆ–ç¼©å°ï¼‰\n",
    "    tf.keras.layers.RandomContrast(0.1), # ç”¨äºå¯¹è¾“å…¥å›¾åƒè¿›è¡Œéšæœºå¯¹æ¯”åº¦è°ƒæ•´\n",
    "])\n",
    "\n",
    "# åº”ç”¨æ•°æ®å¢å¼ºï¼ˆåªå¯¹è®­ç»ƒé›†ï¼‰\n",
    "def augment(image, label):\n",
    "    image = data_augmentation(image, training=True)\n",
    "    return image, label\n",
    "\n",
    "train_ds = train_ds.map(augment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc92e07-27ba-400c-8627-e012224104eb",
   "metadata": {},
   "source": [
    "## 6. æ€§èƒ½ä¼˜åŒ–\n",
    "ä½¿ç”¨ `tf.data` çš„æ€§èƒ½ä¼˜åŒ–æŠ€å·§æ¥åŠ é€Ÿè®­ç»ƒï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35dafaa-db19-48d6-b435-aab8ccd5540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é…ç½®æ•°æ®é›†ä»¥è·å¾—æœ€ä½³æ€§èƒ½\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000) # å°†æ•°æ®ç¼“å­˜åˆ°å†…å­˜ä¸­ï¼ˆå¦‚æœæ•°æ®é›†è¾ƒå°ï¼‰.shuffle(1000) â†’ æ‰“ä¹±\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)  # åœ¨è®­ç»ƒæ—¶é¢„å–åç»­æ‰¹æ¬¡\n",
    "\n",
    "val_ds = val_ds.cache()\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da74ac6-4348-4730-b1a3-8e163cb5d066",
   "metadata": {},
   "source": [
    "## 7. å®Œæ•´çš„å·¥ä½œæµç¨‹ç¤ºä¾‹ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56a6087-9bc8-44d0-b4b6-79befefd2714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 1. åˆ›å»ºæ•°æ®é›†\n",
    "IMG_SIZE = (180, 180)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'data/train',\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'data/train',\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    label_mode='categorical'\n",
    ")\n",
    "\n",
    "# æŸ¥çœ‹ç±»åˆ«ä¿¡æ¯\n",
    "class_names = train_ds.class_names\n",
    "print(f\"ç±»åˆ«: {class_names}\")\n",
    "print(f\"ç±»åˆ«æ•°é‡: {len(class_names)}\")\n",
    "\n",
    "# 2. æ•°æ®é¢„å¤„ç†å’Œå¢å¼º\n",
    "# å½’ä¸€åŒ–\n",
    "def preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "# æ•°æ®å¢å¼º\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "])\n",
    "\n",
    "def augment(image, label):\n",
    "    image = data_augmentation(image, training=True)\n",
    "    return image, label\n",
    "\n",
    "# åº”ç”¨é¢„å¤„ç†å’Œå¢å¼º\n",
    "train_ds = train_ds.map(augment).map(preprocess)\n",
    "val_ds = val_ds.map(preprocess)\n",
    "\n",
    "# 3. æ€§èƒ½ä¼˜åŒ–\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# 4. åˆ›å»ºå’Œè®­ç»ƒæ¨¡å‹\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(class_names), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 5. è®­ç»ƒæ¨¡å‹\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0608e018-3015-433e-b60a-16c46c12ec29",
   "metadata": {},
   "source": [
    "## 8.ä¸ ImageDataGenerator çš„åŒºåˆ«\n",
    "| `image_dataset_from_directory`  | `ImageDataGenerator` |\n",
    "| ------------------------------- | -------------------- |\n",
    "| è¿”å› `tf.data.Dataset`ï¼ˆé€‚åˆ TF 2.xï¼‰ | è¿”å› Python ç”Ÿæˆå™¨        |\n",
    "| æ›´å¿«ã€æ›´ä¼˜åŒ–                          | åŠŸèƒ½è¾ƒæ—§                 |\n",
    "| æ”¯æŒ GPU pipeline                 | æ›´å¤šä¼ ç»Ÿæ•°æ®å¢å¼º             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d0509-5114-4ca7-b61c-10a026f91219",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepseek_env]",
   "language": "python",
   "name": "conda-env-deepseek_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
